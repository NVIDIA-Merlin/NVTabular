<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Troubleshooting &mdash; NVTabular 2021 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/mystnb.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="../_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Talks and Blog Posts" href="links.html" />
    <link rel="prev" title="Cloud Integration" href="cloud_integration.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> NVTabular
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../Introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../core_features.html">Core Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training/index.html">Accelerated Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API Documentation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Additional Resources</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="support_matrix.html">Support Matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="architecture.html">Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="cloud_integration.html">Cloud Integration</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Troubleshooting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#checking-the-schema-of-the-parquet-file">Checking the Schema of the Parquet File</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reducing-memory-consumption-for-nvtabular-workflows">Reducing Memory Consumption for NVTabular Workflows</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reducing-memory-consumption-for-nvtabular-dataloaders">Reducing Memory Consumption for NVTabular Dataloaders</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="links.html">Presentations and Blog Posts</a></li>
<li class="toctree-l2"><a class="reference external" href="https://github.com/NVIDIA/NVTabular">Github Repo</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">NVTabular</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Additional Resources</a> &raquo;</li>
      <li>Troubleshooting</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="tex2jax_ignore mathjax_ignore section" id="troubleshooting">
<h1>Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permalink to this headline"></a></h1>
<div class="section" id="checking-the-schema-of-the-parquet-file">
<h2>Checking the Schema of the Parquet File<a class="headerlink" href="#checking-the-schema-of-the-parquet-file" title="Permalink to this headline"></a></h2>
<p>NVTabular expects that all input parquet files have the same schema, which includes column types and the nullable (not null) option. If you encounter the error</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ne">RuntimeError</span><span class="p">:</span> <span class="n">Schemas</span> <span class="n">are</span> <span class="n">inconsistent</span><span class="p">,</span> <span class="k">try</span> <span class="n">using</span> <span class="n">to_parquet</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="s2">&quot;infer&quot;</span><span class="p">),</span>
<span class="ow">or</span> <span class="k">pass</span> <span class="n">an</span> <span class="n">explicit</span> <span class="n">pyarrow</span> <span class="n">schema</span><span class="o">.</span> <span class="n">Such</span> <span class="k">as</span> <span class="n">to_parquet</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;column1&quot;</span><span class="p">:</span> <span class="n">pa</span><span class="o">.</span><span class="n">string</span><span class="p">()})</span>
</pre></div>
</div>
<p>when you load the dataset as shown below, one of your parquet files might have a different schema:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ds</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">PATH</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;parquet&quot;</span><span class="p">,</span> <span class="n">part_size</span><span class="o">=</span><span class="s2">&quot;1000MB&quot;</span><span class="p">)</span>
<span class="n">ds</span><span class="o">.</span><span class="n">to_ddf</span><span class="p">()</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
<p>The easiest way to fix this is to load your dataset with dask_cudf and save it again using the parquet format ( <code class="docutils literal notranslate"><span class="pre">dask_cudf.read_parquet(&quot;INPUT_FOLDER&quot;).to_parquet(&quot;OUTPUT_FOLDER&quot;)</span></code>), so that the parquet file is standardized and the <code class="docutils literal notranslate"><span class="pre">_metadata</span></code> file is generated.</p>
<p>If you want to identify which parquet files contain columns with different schemas, you can run one of these scripts:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/dask/dask/issues/6504#issuecomment-675465645">PyArrow</a></p></li>
<li><p><a class="reference external" href="https://github.com/rapidsai/cudf/pull/6796#issue-522934284">cudf=0.17</a></p></li>
</ul>
<p>These scripts check for schema consistency and generate only the <code class="docutils literal notranslate"><span class="pre">_metadata</span></code> file instead of
converting all the parquet files. If the schema is inconsistent across all files, the script will
raise an exception. For additional information, see <a class="reference external" href="https://github.com/NVIDIA/NVTabular/issues/429">this
issue</a>.</p>
</div>
<div class="section" id="reducing-memory-consumption-for-nvtabular-workflows">
<h2>Reducing Memory Consumption for NVTabular Workflows<a class="headerlink" href="#reducing-memory-consumption-for-nvtabular-workflows" title="Permalink to this headline"></a></h2>
<p>NVTabular is designed to scale to larger than GPU or host memory datasets. In our experiments, we are able to <a class="reference external" href="https://github.com/NVIDIA/NVTabular/tree/main/examples/scaling-criteo">scale to 1.3TB of uncompressed click logs</a>. However, some workflows can result in OOM errors <code class="docutils literal notranslate"><span class="pre">cudaErrorMemoryAllocation</span> <span class="pre">out</span> <span class="pre">of</span> <span class="pre">memory</span></code>, which can be addressed by small configuration changes.</p>
<div class="section" id="setting-the-row-group-size-for-the-parquet-files">
<h3>1. Setting the Row Group Size for the Parquet Files<a class="headerlink" href="#setting-the-row-group-size-for-the-parquet-files" title="Permalink to this headline"></a></h3>
<p>You can use most Data Frame frameworks to set the row group size (number of rows) for your parquet files. In the following Pandas and cuDF examples, the <code class="docutils literal notranslate"><span class="pre">row_group_size</span></code> is the number of rows that will be stored in each row group (internal structure within the parquet file):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#Pandas</span>
<span class="n">pandas_df</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="s2">&quot;/file/path&quot;</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;pyarrow&quot;</span><span class="p">,</span> <span class="n">row_group_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
<span class="c1">#cuDF</span>
<span class="n">cudf_df</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="s2">&quot;/file/path&quot;</span><span class="p">,</span> <span class="n">engine</span><span class="o">=</span><span class="s2">&quot;pyarrow&quot;</span><span class="p">,</span> <span class="n">row_group_size</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
</pre></div>
</div>
<p>The row group <strong>memory</strong> size of the parquet files should be smaller than the <strong>part_size</strong> that
you set for the NVTabular dataset such as <code class="docutils literal notranslate"><span class="pre">nvt.Dataset(TRAIN_DIR,</span> <span class="pre">engine=&quot;parquet&quot;,</span> <span class="pre">part_size=&quot;1000MB&quot;)</span></code>. To determine how much memory a row group will hold, you can slice your dataframe to a specific number of rows and use the following function to get the memory usage in bytes. You can then set the row_group_size (number of rows) accordingly when you save the parquet file. A row group memory size that is close to 128MB is recommended.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">_memory_usage</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;this function is a workaround for obtaining memory usage lists</span>
<span class="sd">    in cudf0.16. This can be deleted and replaced with `df.memory_usage(deep= True, index=True).sum()`</span>
<span class="sd">    when using cudf 0.17, which has been fixed as noted on https://github.com/rapidsai/cudf/pull/6549)&quot;&quot;&quot;</span>
    <span class="n">size</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">_data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">cudf</span><span class="o">.</span><span class="n">api</span><span class="o">.</span><span class="n">types</span><span class="o">.</span><span class="n">is_list_dtype</span><span class="p">(</span><span class="n">col</span><span class="o">.</span><span class="n">dtype</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">col</span><span class="o">.</span><span class="n">base_children</span><span class="p">:</span>
                <span class="n">size</span> <span class="o">+=</span> <span class="n">child</span><span class="o">.</span><span class="n">__sizeof__</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">size</span> <span class="o">+=</span> <span class="n">col</span><span class="o">.</span><span class="n">_memory_usage</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">size</span> <span class="o">+=</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">size</span>
</pre></div>
</div>
</div>
<div class="section" id="initializing-a-dask-cuda-cluster">
<h3>2. Initializing a Dask CUDA Cluster<a class="headerlink" href="#initializing-a-dask-cuda-cluster" title="Permalink to this headline"></a></h3>
<p>Even if you only have a single GPU to work with, it is best practice to use a distributed Dask-CUDA cluster to execute memory-intensive NVTabular workflows. If there is no distributed <code class="docutils literal notranslate"><span class="pre">client</span></code> object passed to an NVTabular <code class="docutils literal notranslate"><span class="pre">Workflow</span></code>, it will fall back on Dask’s single-threaded “synchronous” scheduler at computation time. The primary advantage of using a Dask-CUDA cluster is that the Dask-CUDA workers enable GPU-aware memory spilling.  In our experience, many OOM errors can be resolved by initializing a dask-CUDA cluster with an appropriate <code class="docutils literal notranslate"><span class="pre">device_memory_limit</span></code> setting, and by passing a corresponding client to NVTabular.  It is easy to deploy a single-machine dask-CUDA cluster using <code class="docutils literal notranslate"><span class="pre">LocalCUDACluster</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dask_cuda</span> <span class="kn">import</span> <span class="n">LocalCUDACluster</span>
<span class="kn">from</span> <span class="nn">dask.distributed</span> <span class="kn">import</span> <span class="n">Client</span>

<span class="kn">import</span> <span class="nn">nvtabular</span> <span class="k">as</span> <span class="nn">nvt</span>

<span class="n">cluster</span> <span class="o">=</span> <span class="n">LocalCUDACluster</span><span class="p">(</span>
    <span class="n">n_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>                        <span class="c1"># Number of GPU workers</span>
    <span class="n">device_memory_limit</span><span class="o">=</span><span class="s2">&quot;24GB&quot;</span><span class="p">,</span>         <span class="c1"># GPU-&gt;CPU spill threshold (~75% of GPU memory)</span>
    <span class="n">rmm_pool_size</span><span class="o">=</span><span class="s2">&quot;28GB&quot;</span><span class="p">,</span>               <span class="c1"># Memory pool size on each worker</span>
    <span class="n">local_directory</span><span class="o">=</span><span class="s2">&quot;/nvme/scratch/&quot;</span><span class="p">,</span>   <span class="c1"># Fast directory for disk spilling</span>
<span class="p">)</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>

<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;col&#39;</span><span class="p">]</span> <span class="o">&gt;&gt;</span> <span class="n">nvt</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Normalize</span><span class="p">()</span>

<span class="n">workflow</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Workflow</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">client</span><span class="o">=</span><span class="n">client</span><span class="p">)</span>

<span class="n">client</span><span class="o">.</span><span class="n">shutdown</span><span class="p">()</span>
<span class="n">client</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="string-column-error">
<h3>3. String Column Error<a class="headerlink" href="#string-column-error" title="Permalink to this headline"></a></h3>
<p>If you run into a problem an error that states the size of your string column is too large, like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ne">Exception</span><span class="p">:</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;cuDF failure at: /opt/conda/envs/rapids/conda-bld/libcudf_1618503955512/work/cpp/src/copying/concatenate.cu:368: Total number of concatenated rows exceeds size_type range&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>This is usually caused by string columns in parquet files. If you encounter this error, to fix it you need to decrease the size of the partitions of your dataset. If, after decreasing the size of the partitions, you get a warning about picking a partition size smaller than the row group size, you will need to reformat the dataset with a smaller row group size (refer to #1). There is a 2GB max size for concatenated string columns in cudf currently, for details refer to <a class="reference external" href="https://github.com/rapidsai/cudf/issues/3958">this</a>.</p>
</div>
</div>
<div class="section" id="reducing-memory-consumption-for-nvtabular-dataloaders">
<h2>Reducing Memory Consumption for NVTabular Dataloaders<a class="headerlink" href="#reducing-memory-consumption-for-nvtabular-dataloaders" title="Permalink to this headline"></a></h2>
<p>NVTabular dataloaders are designed to read data from disk directly into the GPU and prepare the batch. We see this process as really efficient, as the NVTabular dataloaders avoid any CPU-GPU communication and the data will be only processed by the GPU. On the other hand, the dataloader will require GPU memory to hold the data. In some cases, this can cause OOM errors to use NVTabular dataloader on the GPU and train a neural network on the GPU. We can adjust the GPU consumption of the NVTabular dataloader with following configurations.</p>
<div class="section" id="row-group-size-for-the-parquet-files">
<h3>1. Row Group Size for the Parquet Files<a class="headerlink" href="#row-group-size-for-the-parquet-files" title="Permalink to this headline"></a></h3>
<p>It is important that the input parquet files are correctly configured. If you use NVTabular ETL to transform your data, then NVTabular will use the best configuration by default. If you do not use NVTabular ETL, you can take a look on the section above <code class="docutils literal notranslate"><span class="pre">Reducing</span> <span class="pre">Memory</span> <span class="pre">Consumption</span> <span class="pre">for</span> <span class="pre">NVTabular</span> <span class="pre">Workflows</span></code>.</p>
</div>
<div class="section" id="setting-part-size-in-nvt-dataset">
<h3>2. Setting <code class="docutils literal notranslate"><span class="pre">part_size</span></code> in nvt.Dataset<a class="headerlink" href="#setting-part-size-in-nvt-dataset" title="Permalink to this headline"></a></h3>
<p>The class nvt.Dataset abstracts the dataset to a common object. It will read the data from disk into chunks. The parameter <code class="docutils literal notranslate"><span class="pre">part_size</span></code> defines the desired size of each dask partition. You can reduce the GPU memory consumption of the NVTabular dataloader by changing the parameter. This can effect the speed how fast NVTabular dataloader can read the data, but it should not be significant in comparison to updating the neural network parameters. You can try out different values, such as <code class="docutils literal notranslate"><span class="pre">100MB</span></code>, <code class="docutils literal notranslate"><span class="pre">300MB</span></code> or <code class="docutils literal notranslate"><span class="pre">1000MB</span></code>.</p>
<p>PyTorch:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">TorchAsyncItr</span><span class="p">(</span>
    <span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">train_files</span><span class="p">,</span> <span class="n">part_size</span><span class="o">=</span><span class="s2">&quot;300MB&quot;</span><span class="p">),</span> 
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="o">*</span><span class="mi">64</span><span class="p">,</span> 
    <span class="n">cats</span><span class="o">=</span><span class="n">CATEGORICAL_COLUMNS</span><span class="p">,</span> 
    <span class="n">conts</span><span class="o">=</span><span class="n">CONTINUOUS_COLUMNS</span><span class="p">,</span> 
    <span class="n">labels</span><span class="o">=</span><span class="n">LABEL_COLUMNS</span>
<span class="p">)</span>
</pre></div>
</div>
<p>TensorFlow:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train_loader</span> <span class="o">=</span> <span class="n">KerasSequenceLoader</span><span class="p">(</span>
    <span class="n">nvt</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">train_files</span><span class="p">,</span> <span class="n">part_size</span><span class="o">=</span><span class="s2">&quot;300MB&quot;</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
    <span class="n">label_names</span><span class="o">=</span><span class="n">LABEL_COLUMNS</span><span class="p">,</span>
    <span class="n">cat_names</span><span class="o">=</span><span class="n">CATEGORICAL_COLUMNS</span><span class="p">,</span>
    <span class="n">cont_names</span><span class="o">=</span><span class="n">CONTINUOUS_COLUMNS</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="cloud_integration.html" class="btn btn-neutral float-left" title="Cloud Integration" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="links.html" class="btn btn-neutral float-right" title="Talks and Blog Posts" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: main
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../v0.10.0/resources/troubleshooting.html">v0.10.0</a></dd>
      <dd><a href="../../v0.11.0/resources/troubleshooting.html">v0.11.0</a></dd>
      <dd><a href="../../v0.9.0/resources/troubleshooting.html">v0.9.0</a></dd>
      <dd><a href="../../v1.0.0/resources/troubleshooting.html">v1.0.0</a></dd>
      <dd><a href="../../v1.1.0/resources/troubleshooting.html">v1.1.0</a></dd>
      <dd><a href="../../v1.1.1/resources/troubleshooting.html">v1.1.1</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="troubleshooting.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>