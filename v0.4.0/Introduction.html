<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>NVTabular | API documentation &mdash; NVTabular 2021 documentation</title><link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Core Features" href="core_features.html" />
    <link rel="prev" title="Welcome to NVTabular’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="index.html" class="icon icon-home"> NVTabular
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#benefits">Benefits</a></li>
<li class="toctree-l2"><a class="reference internal" href="#installation">Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#installing-nvtabular-using-conda">Installing NVTabular Using Conda</a></li>
<li class="toctree-l3"><a class="reference internal" href="#installing-nvtabular-with-docker">Installing NVTabular with Docker</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#examples-and-tutorials">Examples and Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="#feedback-and-support">Feedback and Support</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="core_features.html">Core Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="training/index.html">Accelerated Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources/index.html">Additional Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">NVTabular</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>NVTabular | API documentation</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="nvtabular-api-documentation">
<h1><a class="reference external" href="https://github.com/NVIDIA/NVTabular">NVTabular</a> | <a class="reference external" href="https://nvidia.github.io/NVTabular/main/Introduction.html">API documentation</a><a class="headerlink" href="#nvtabular-api-documentation" title="Permalink to this headline"></a></h1>
<p><a class="reference external" href="https://github.com/NVIDIA/NVTabular">NVTabular</a> is a feature engineering and preprocessing library for tabular data that is designed to quickly and easily manipulate terabyte scale datasets and train deep learning (DL) based recommender systems. It provides a high level abstraction to simplify code and accelerates computation on the GPU using the <a class="reference external" href="https://github.com/rapidsai/cudf/tree/main/python/dask_cudf">RAPIDS Dask-cuDF</a> library. NVTabular is designed to be interoperable with both PyTorch and TensorFlow using dataloaders that we have developed as extensions of native framework code. In our experiments, we were able to speed up existing TensorFlow pipelines by 9 times and existing PyTorch pipelines by 5 times with our highly optimized dataloaders.</p>
<p>NVTabular is a component of <a class="reference external" href="https://developer.nvidia.com/nvidia-merlin">NVIDIA Merlin Open Beta</a>. NVIDIA Merlin is used for building large-scale recommender systems, which require massive datasets to train, particularly for deep learning based solutions. With NVTabular being a part of the Merlin ecosystem, it also works with the other Merlin components including <a class="reference external" href="https://github.com/NVIDIA/HugeCTR">HugeCTR</a> and <a class="reference external" href="https://github.com/NVIDIA/tensorrt-inference-server">Triton Inference Server</a> to provide end-to-end acceleration of recommender systems on the GPU. Extending beyond model training, with NVIDIA’s Triton Inference Server, the feature engineering and preprocessing steps performed on the data during training can be automatically applied to incoming data during inference.</p>
<div class="section" id="benefits">
<h2>Benefits<a class="headerlink" href="#benefits" title="Permalink to this headline"></a></h2>
<p>Our ultimate goal is faster iteration on massive tabular datasets, both for experimentation during training, and also production model responsiveness. NVTabular is designed to support data scientists and machine learning (ML) engineers train (deep learning) recommender systems and resolve tabular data problems by allowing them to:</p>
<ul class="simple">
<li><p>prepare datasets quickly and easily for experimentation so that more models can be trained.</p></li>
<li><p>process datasets that exceed GPU and CPU memory without having to worry about scale.</p></li>
<li><p>use optimized dataloaders to accelerate training with TensorFlow, PyTorch, and HugeCTR.</p></li>
<li><p>focus on what to do with the data and not how to do it by using abstraction at the operation level.</p></li>
</ul>
<p>NVTabular also helps ML/Ops engineers with deploying models into production by providing faster dataset transformation. This makes it easy for production models to be trained more frequently and kept up to date, helping improve responsiveness and model performance.</p>
<p>To learn more about NVTabular’s core features, see the following:</p>
<ul class="simple">
<li><p><a class="reference external" href="/NVTabular/v0.4.0/core_features.html#tensorflow-and-pytorch-interoperability">TensorFlow and PyTorch Interoperability</a></p></li>
<li><p><a class="reference external" href="/NVTabular/v0.4.0/core_features.html#hugectr-interoperability">HugeCTR Interoperability</a></p></li>
<li><p><a class="reference external" href="/NVTabular/v0.4.0/core_features.html#multi-gpu-support">Multi-GPU Support</a></p></li>
<li><p><a class="reference external" href="/NVTabular/v0.4.0/core_features.html#multi-node-support">Multi-Node Support</a></p></li>
<li><p><a class="reference external" href="/NVTabular/v0.4.0/core_features.html#multi-hot-encoding-and-pre-existing-embeddings">Multi-Hot Encoding and Pre-existing Embeddings</a></p></li>
<li><p><a class="reference external" href="/NVTabular/v0.4.0/core_features.html#shuffling-datasets">Shuffling Datasets</a></p></li>
<li><p><a class="reference external" href="/NVTabular/v0.4.0/core_features.html#cloud-integration">Cloud Integration</a></p></li>
</ul>
</div>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline"></a></h2>
<p>To install NVTabular, ensure that you meet the following prerequisites:</p>
<ul class="simple">
<li><p>CUDA version 10.1+</p></li>
<li><p>Python version 3.7+</p></li>
<li><p>NVIDIA Pascal GPU or later</p></li>
</ul>
<p><strong>NOTE</strong>: NVTabular will only run on Linux. Other operating systems are not currently supported.</p>
<div class="section" id="installing-nvtabular-using-conda">
<h3>Installing NVTabular Using Conda<a class="headerlink" href="#installing-nvtabular-using-conda" title="Permalink to this headline"></a></h3>
<p>NVTabular can be installed with Anaconda from the <code class="docutils literal notranslate"><span class="pre">nvidia</span></code> channel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">install</span> <span class="o">-</span><span class="n">c</span> <span class="n">nvidia</span> <span class="o">-</span><span class="n">c</span> <span class="n">rapidsai</span> <span class="o">-</span><span class="n">c</span> <span class="n">numba</span> <span class="o">-</span><span class="n">c</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span> <span class="n">nvtabular</span> <span class="n">python</span><span class="o">=</span><span class="mf">3.7</span> <span class="n">cudatoolkit</span><span class="o">=</span><span class="mf">10.2</span>
</pre></div>
</div>
<p>If you’d like to create a full conda environment to run the example notebooks, you can use the <a class="reference external" href="https://github.com/NVIDIA/NVTabular/tree/main/conda/environments">provided environment files</a> for CUDA Toolkit 10.1, 10.2, or 11.0. Clone the NVTabular repo and from the root directory, run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">env</span> <span class="n">create</span> <span class="o">-</span><span class="n">f</span><span class="o">=</span><span class="n">conda</span><span class="o">/</span><span class="n">environments</span><span class="o">/</span><span class="n">nvtabular_dev_cuda10</span><span class="mf">.1</span><span class="o">.</span><span class="n">yml</span>
<span class="n">conda</span> <span class="n">activate</span> <span class="n">nvtabular_dev_10</span><span class="mf">.1</span>
<span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">ipykernel</span> <span class="n">install</span> <span class="o">--</span><span class="n">user</span> <span class="o">--</span><span class="n">name</span><span class="o">=</span><span class="n">nvt</span>
<span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">e</span> <span class="o">.</span>
<span class="n">jupyter</span> <span class="n">notebook</span>
</pre></div>
</div>
<p>Then open a notebook and select <code class="docutils literal notranslate"><span class="pre">nvt</span></code> from the <code class="docutils literal notranslate"><span class="pre">Kernel-&gt;Change</span> <span class="pre">Kernel</span></code> menu.</p>
</div>
<div class="section" id="installing-nvtabular-with-docker">
<h3>Installing NVTabular with Docker<a class="headerlink" href="#installing-nvtabular-with-docker" title="Permalink to this headline"></a></h3>
<p>Docker containers with NVTabular are available at the <a class="reference external" href="https://ngc.nvidia.com/catalog/containers/nvidia:merlin">NVIDIA Merlin container repository</a>. There are four different containers, each providing different functionality:</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Container Name</th>
<th>Container Location</th>
<th>Functionality</th>
</tr>
</thead>
<tbody>
<tr>
<td>merlin-training</td>
<td>https://ngc.nvidia.com/catalog/containers/nvidia:merlin:merlin-training</td>
<td>NVTabular and HugeCTR</td>
</tr>
<tr>
<td>merlin-tensorflow-training</td>
<td>https://ngc.nvidia.com/catalog/containers/nvidia:merlin:merlin-tensorflow-training</td>
<td>NVTabular, TensorFlow and HugeCTR Tensorflow Embedding plugin</td>
</tr>
<tr>
<td>merlin-pytorch-training</td>
<td>https://ngc.nvidia.com/catalog/containers/nvidia:merlin:merlin-pytorch-training</td>
<td>NVTabular and PyTorch</td>
</tr>
<tr>
<td>merlin-inference</td>
<td>https://ngc.nvidia.com/catalog/containers/nvidia:merlin:merlin-inference</td>
<td>NVTabular, HugeCTR and Triton Inference</td>
</tr>
</tbody>
</table><p>To use these Docker Containers, you’ll first need to install the <a class="reference external" href="https://github.com/NVIDIA/nvidia-docker">NVIDIA Container Toolkit</a> to provide GPU support to docker.
There are more details on launching and running these containers on the NGC links above.</p>
</div>
</div>
<div class="section" id="examples-and-tutorials">
<h2>Examples and Tutorials<a class="headerlink" href="#examples-and-tutorials" title="Permalink to this headline"></a></h2>
<p>We provide a <a class="reference external" href="https://github.com/NVIDIA/NVTabular/tree/main/examples">collection of examples, use cases, and tutorials</a> as Jupyter notebooks in our repository. These Jupyter notebooks are based on the following datasets:</p>
<ul class="simple">
<li><p>MovieLens</p></li>
<li><p>Outbrain Click Prediction</p></li>
<li><p>Criteo Click Ads Prediction</p></li>
<li><p>RecSys2020 Competition Hosted by Twitter</p></li>
<li><p>Rossmann Sales Prediction</p></li>
</ul>
<p>Each Jupyter notebook covers the following:</p>
<ul class="simple">
<li><p>Preprocessing and feature engineering with NVTabular</p></li>
<li><p>Advanced workflows with NVTabular</p></li>
<li><p>Accelerated dataloaders for TensorFlow and PyTorch</p></li>
<li><p>Scaling to multi-GPU and multi nodes systems</p></li>
<li><p>Integrating NVTabular with HugeCTR</p></li>
<li><p>Deploying to inference with Triton</p></li>
</ul>
<p>Performance of the Criteo DRLM workflow demonstrates the effectiveness of the NVTabular library. The original ETL script provided in Numpy took over five days to complete. Combined with CPU training, the total iteration time is over one week. By optimizing the ETL code in Spark and running on a DGX-1 equivalent cluster, we were able to bring that time down to three hours for ETL and one hour for training.</p>
<p>With NVTabular running on a single V100 32GB GPU, we were able to complete ETL in 13 minutes. With a DGX-1 cluster of eight V100 GPUs, we can accelerate ETL to 3 minutes. Combined with <a class="reference external" href="http://www.github.com/NVIDIA/HugeCTR/">HugeCTR</a>, we can process the dataset and train the full model in only 6 minutes. This fast iteration is the goal of NVTabular and the <a class="reference external" href="https://developer.nvidia.com/nvidia-merlin">Merlin application framework</a>. Additional information can be found <a class="reference external" href="https://github.com/NVIDIA/NVTabular/tree/main/examples">here</a>.</p>
</div>
<div class="section" id="feedback-and-support">
<h2>Feedback and Support<a class="headerlink" href="#feedback-and-support" title="Permalink to this headline"></a></h2>
<p>If you’d like to contribute to the library directly, please see the <a class="reference external" href="https://github.com/NVIDIA/NVTabular/blob/main/CONTRIBUTING.md">Contributing.md</a>. We’re particularly interested in contributions or feature requests for our feature engineering and preprocessing operations. To further advance our Merlin Roadmap, we encourage you to share all the details regarding your recommender system pipeline using this <a class="reference external" href="https://developer.nvidia.com/merlin-devzone-survey">this survey</a>.</p>
<p>If you’re interested in learning more about how NVTabular works under the hood, see
<a class="reference external" href="/NVTabular/v0.4.0/resources/architecture.html">Architecture</a>. We also have <a class="reference external" href="https://nvidia.github.io/NVTabular/main/resources/api/index.html">API documentation</a> that outlines the specifics of the available calls within the library.</p>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to NVTabular’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="core_features.html" class="btn btn-neutral float-right" title="Core Features" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: v0.4.0
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../v0.1.0/Introduction.html">v0.1.0</a></dd>
      <dd><a href="../v0.1.1/Introduction.html">v0.1.1</a></dd>
      <dd><a href="../v0.10.0/Introduction.html">v0.10.0</a></dd>
      <dd><a href="../v0.11.0/Introduction.html">v0.11.0</a></dd>
      <dd><a href="../v0.2.0/Introduction.html">v0.2.0</a></dd>
      <dd><a href="../v0.3.0/Introduction.html">v0.3.0</a></dd>
      <dd><a href="Introduction.html">v0.4.0</a></dd>
      <dd><a href="../v0.5.0/Introduction.html">v0.5.0</a></dd>
      <dd><a href="../v0.5.1/Introduction.html">v0.5.1</a></dd>
      <dd><a href="../v0.5.2/Introduction.html">v0.5.2</a></dd>
      <dd><a href="../v0.5.3/Introduction.html">v0.5.3</a></dd>
      <dd><a href="../v0.6.0/Introduction.html">v0.6.0</a></dd>
      <dd><a href="../v0.6.1/Introduction.html">v0.6.1</a></dd>
      <dd><a href="../v0.7.0/Introduction.html">v0.7.0</a></dd>
      <dd><a href="../v0.7.1/Introduction.html">v0.7.1</a></dd>
      <dd><a href="../v0.8.0/Introduction.html">v0.8.0</a></dd>
      <dd><a href="../v0.9.0/Introduction.html">v0.9.0</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../main/Introduction.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>