{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started Outbrain: Download and Convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outbrain dataset was published in [Kaggle Outbrain click prediction](https://www.kaggle.com/c/outbrain-click-prediction) competition, where the ‘Kagglers’ were challenged to predict on which ads and other forms of sponsored content its global users would click. One of  the top finishers' preprocessing and feature engineering pipeline is taken into consideration here, and this pipeline was restructured using NVTabular and cuDF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get dataframe library - cudf or pandas\n",
    "from nvtabular.dispatch import get_lib, random_uniform, reinitialize\n",
    "df_lib = get_lib()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to [download](https://www.kaggle.com/c/outbrain-click-prediction/data) the Kaggle Outbrain click prediction challenge and set DATA_BUCKET_FOLDER with the dataset path.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BUCKET_FOLDER = os.environ.get(\"INPUT_DATA_DIR\", \"~/nvt-examples/outbrain/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OUTPUT_BUCKET_FOLDER is the folder where the preprocessed dataset will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_BUCKET_FOLDER = os.environ.get(\"OUTPUT_DATA_DIR\", \"./outbrain-preprocessed/\")\n",
    "os.makedirs(OUTPUT_BUCKET_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Our Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we merge the component tables of our dataset into a single data frame, using [cuDF](https://github.com/rapidsai/cudf), which is a GPU DataFrame library for loading, joining, aggregating, filtering, and otherwise manipulating data. We do this because NVTabular applies a workflow to a single table. We also re-initialize managed memory. `rmm.reinitialize()` provides an easy way to initialize RMM (RAPIDS Memory Manager) with specific memory resource options across multiple devices. The reason we re-initialize managed memory here is to allow us to perform memory intensive merge operation. Note that dask-cudf can also be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use managed memory for device memory allocation\n",
    "reinitialize(managed_memory=True)\n",
    "\n",
    "# Alias for read_csv\n",
    "read_csv = df_lib.read_csv\n",
    "\n",
    "# Merge all the CSV files together\n",
    "documents_meta = read_csv(DATA_BUCKET_FOLDER + \"documents_meta.csv\", na_values=[\"\\\\N\", \"\"])\n",
    "merged = (\n",
    "    read_csv(DATA_BUCKET_FOLDER + \"clicks_train.csv\", na_values=[\"\\\\N\", \"\"])\n",
    "    .merge(\n",
    "        read_csv(DATA_BUCKET_FOLDER + \"events.csv\", na_values=[\"\\\\N\", \"\"]),\n",
    "        on=\"display_id\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_event\"),\n",
    "    )\n",
    "    .merge(\n",
    "        read_csv(DATA_BUCKET_FOLDER + \"promoted_content.csv\", na_values=[\"\\\\N\", \"\"]),\n",
    "        on=\"ad_id\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_promo\"),\n",
    "    )\n",
    "    .merge(documents_meta, on=\"document_id\", how=\"left\")\n",
    "    .merge(\n",
    "        documents_meta,\n",
    "        left_on=\"document_id_promo\",\n",
    "        right_on=\"document_id\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_promo\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a time-stratified sample to create a validation set that is more recent, and save both our train and validation sets to parquet files to be read by NVTabular. Note that you should run the cell below only once, then save your `train` and `valid` data frames as parquet files. If you want to rerun this notebook you might end up with a different train-validation split each time because samples are drawn from a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a stratified split of the merged dataset into a training/validation dataset\n",
    "merged[\"day_event\"] = (merged[\"timestamp\"] / 1000 / 60 / 60 / 24).astype(int)\n",
    "random_state = df_lib.Series(random_uniform(size=len(merged)))\n",
    "valid_set, train_set = merged.scatter_by_map(\n",
    "    ((merged.day_event <= 10) & (random_state > 0.2)).astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_id</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>clicked</th>\n",
       "      <th>uuid</th>\n",
       "      <th>document_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>platform</th>\n",
       "      <th>geo_location</th>\n",
       "      <th>document_id_promo</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>advertiser_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>source_id_promo</th>\n",
       "      <th>publisher_id_promo</th>\n",
       "      <th>publish_time_promo</th>\n",
       "      <th>day_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9376</th>\n",
       "      <td>15071</td>\n",
       "      <td>50640</td>\n",
       "      <td>0</td>\n",
       "      <td>ef25dd3a359f77</td>\n",
       "      <td>91525</td>\n",
       "      <td>1053684</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AU&gt;02</td>\n",
       "      <td>869942</td>\n",
       "      <td>6714</td>\n",
       "      <td>1913</td>\n",
       "      <td>8107.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2012-02-13 00:00:00</td>\n",
       "      <td>8484.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2015-09-13 21:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11904</th>\n",
       "      <td>1545</td>\n",
       "      <td>75959</td>\n",
       "      <td>0</td>\n",
       "      <td>7be3eb33be486c</td>\n",
       "      <td>1697627</td>\n",
       "      <td>107138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>US&gt;MA&gt;521</td>\n",
       "      <td>1078193</td>\n",
       "      <td>959</td>\n",
       "      <td>8</td>\n",
       "      <td>8610.0</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1493.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>2016-02-04 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12512</th>\n",
       "      <td>3544</td>\n",
       "      <td>149756</td>\n",
       "      <td>0</td>\n",
       "      <td>33e08ba8e59293</td>\n",
       "      <td>1326664</td>\n",
       "      <td>243025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>US&gt;TX&gt;623</td>\n",
       "      <td>1233590</td>\n",
       "      <td>19007</td>\n",
       "      <td>285</td>\n",
       "      <td>948.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>10972.0</td>\n",
       "      <td>1147.0</td>\n",
       "      <td>2016-04-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15072</th>\n",
       "      <td>229</td>\n",
       "      <td>150817</td>\n",
       "      <td>0</td>\n",
       "      <td>fc514cfac3fd61</td>\n",
       "      <td>1776403</td>\n",
       "      <td>16513</td>\n",
       "      <td>1.0</td>\n",
       "      <td>US&gt;AZ&gt;789</td>\n",
       "      <td>1362397</td>\n",
       "      <td>19188</td>\n",
       "      <td>2407</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>2016-06-13 16:00:00</td>\n",
       "      <td>8610.0</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>2016-04-28 15:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15584</th>\n",
       "      <td>1534</td>\n",
       "      <td>116696</td>\n",
       "      <td>0</td>\n",
       "      <td>da4d73f0a12bfa</td>\n",
       "      <td>1503347</td>\n",
       "      <td>106591</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US&gt;CA&gt;866</td>\n",
       "      <td>1191113</td>\n",
       "      <td>15005</td>\n",
       "      <td>83</td>\n",
       "      <td>5792.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>2016-05-31 00:00:00</td>\n",
       "      <td>7357.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       display_id   ad_id  clicked            uuid  document_id  timestamp  \\\n",
       "9376        15071   50640        0  ef25dd3a359f77        91525    1053684   \n",
       "11904        1545   75959        0  7be3eb33be486c      1697627     107138   \n",
       "12512        3544  149756        0  33e08ba8e59293      1326664     243025   \n",
       "15072         229  150817        0  fc514cfac3fd61      1776403      16513   \n",
       "15584        1534  116696        0  da4d73f0a12bfa      1503347     106591   \n",
       "\n",
       "       platform geo_location  document_id_promo  campaign_id  advertiser_id  \\\n",
       "9376        1.0        AU>02             869942         6714           1913   \n",
       "11904       1.0    US>MA>521            1078193          959              8   \n",
       "12512       1.0    US>TX>623            1233590        19007            285   \n",
       "15072       1.0    US>AZ>789            1362397        19188           2407   \n",
       "15584       2.0    US>CA>866            1191113        15005             83   \n",
       "\n",
       "       source_id  publisher_id         publish_time  source_id_promo  \\\n",
       "9376      8107.0           9.0  2012-02-13 00:00:00           8484.0   \n",
       "11904     8610.0        1142.0                 <NA>           1493.0   \n",
       "12512      948.0         450.0                 <NA>          10972.0   \n",
       "15072     1095.0        1004.0  2016-06-13 16:00:00           8610.0   \n",
       "15584     5792.0         704.0  2016-05-31 00:00:00           7357.0   \n",
       "\n",
       "      publisher_id_promo   publish_time_promo  day_event  \n",
       "9376                <NA>  2015-09-13 21:00:00          0  \n",
       "11904              305.0  2016-02-04 00:00:00          0  \n",
       "12512             1147.0  2016-04-01 00:00:00          0  \n",
       "15072             1142.0  2016-04-28 15:00:00          0  \n",
       "15584               <NA>                 <NA>          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the dataset to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = os.path.join(OUTPUT_BUCKET_FOLDER, \"train_gdf.parquet\")\n",
    "valid_filename = os.path.join(OUTPUT_BUCKET_FOLDER, \"valid_gdf.parquet\")\n",
    "train_set.to_parquet(train_filename, compression=None)\n",
    "valid_set.to_parquet(valid_filename, compression=None)\n",
    "merged = train_set = valid_set = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reinitialize(managed_memory=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
