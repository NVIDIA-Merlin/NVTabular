{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVTabular / HugeCTR Criteo Example \n",
    "Here we'll show how to use NVTabular first as a preprocessing library to prepare the [Criteo Display Advertising Challenge](https://www.kaggle.com/c/criteo-display-ad-challenge) dataset, and then train a model using HugeCTR.\n",
    "\n",
    "### Data Prep\n",
    "Before we get started, make sure you've run the [`optimize_criteo` notebook](./optimize_criteo.ipynb), which will convert the tsv data published by Criteo into the parquet format that our accelerated readers prefer. It's fair to mention at this point that that notebook will take ~4 hours to run. While we're hoping to release accelerated csv readers in the near future, we also believe that inefficiencies in existing data representations like csv are in no small part a consequence of inefficiencies in the existing hardware/software stack. Accelerating these pipelines on new hardware like GPUs may require us to make new choices about the representations we use to store that data, and parquet represents a strong alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Aside: Clearing Cache\n",
    "The following line is not strictly necessary, but is included for those who want to validate NVIDIA's benchmarks. We start by clearing the existing cache to start as \"fresh\" as possible. If you're having trouble running it, try executing the container with the `--privileged` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: cannot create /proc/sys/vm/drop_caches: Read-only file system\n"
     ]
    }
   ],
   "source": [
    "!sync; echo 3 > /proc/sys/vm/drop_caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/lib/python3.7/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_NVVM=/usr/local/cuda/nvvm/lib64/libnvvm.so.\n",
      "\n",
      "For more information about alternatives visit: ('https://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n",
      "/conda/lib/python3.7/site-packages/numba/cuda/envvars.py:17: NumbaWarning: \n",
      "Environment variables with the 'NUMBAPRO' prefix are deprecated and consequently ignored, found use of NUMBAPRO_LIBDEVICE=/usr/local/cuda/nvvm/libdevice/.\n",
      "\n",
      "For more information about alternatives visit: ('https://numba.pydata.org/numba-doc/latest/cuda/overview.html', '#cudatoolkit-lookup')\n",
      "  warnings.warn(errors.NumbaWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from time import time\n",
    "import re\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "# tools for data preproc/loading\n",
    "import torch\n",
    "import rmm\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import Normalize, FillMissing, Categorify, Moments, Median, LogOp, ZeroFill, get_embedding_sizes\n",
    "from nvtabular.torch_dataloader import DLDataLoader, TorchTensorBatchDatasetItr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the Memory Pool\n",
    "For applications like the one that follows where RAPIDS will be the only workhorse user of GPU memory and resource, a good best practices is to use the RAPIDS Memory Manager library `rmm` to allocate a dedicated pool of GPU memory that allows for fast, asynchronous memory management. Here, we'll dedicate 80% of free GPU memory to this pool to make sure we get the most utilization possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nvt/nvtabular/io.py:113: UserWarning: get_memory_info is not supported. Using total device memory from NVML.\n",
      "  warnings.warn(\"get_memory_info is not supported. Using total device memory from NVML.\")\n"
     ]
    }
   ],
   "source": [
    "rmm.reinitialize(pool_allocator=True, initial_pool_size=0.8 * nvt.io.device_mem_size(kind='free'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataset Schema\n",
    "Once our data is ready, we'll define some high level parameters to describe where our data is and what it \"looks like\" at a high level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some information about where to get our data\n",
    "INPUT_DATA_DIR = os.environ.get('INPUT_DATA_DIR', '/dataset/crit_int_pq')\n",
    "OUTPUT_DATA_DIR = os.environ.get('OUTPUT_DATA_DIR', '/dataset/crit_int_pq/output') # where we'll save our procesed data to\n",
    "!mkdir $OUTPUT_DATA_DIR\n",
    "NUM_TRAIN_DAYS = 23 # number of days worth of data to use for training, the rest will be used for validation\n",
    "\n",
    "# define our dataset schema\n",
    "CONTINUOUS_COLUMNS = ['I' + str(x) for x in range(1,14)]\n",
    "CATEGORICAL_COLUMNS =  ['C' + str(x) for x in range(1,27)]\n",
    "LABEL_COLUMNS = ['label']\n",
    "COLUMNS = CONTINUOUS_COLUMNS + CATEGORICAL_COLUMNS + LABEL_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_metadata\tday_13.parquet\tday_19.parquet\tday_3.parquet  day_9.parquet\n",
      "day_0.parquet\tday_14.parquet\tday_2.parquet\tday_4.parquet  output\n",
      "day_1.parquet\tday_15.parquet\tday_20.parquet\tday_5.parquet\n",
      "day_10.parquet\tday_16.parquet\tday_21.parquet\tday_6.parquet\n",
      "day_11.parquet\tday_17.parquet\tday_22.parquet\tday_7.parquet\n",
      "day_12.parquet\tday_18.parquet\tday_23.parquet\tday_8.parquet\n"
     ]
    }
   ],
   "source": [
    "! ls $INPUT_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/dataset/crit_int_pq/day_0.parquet']\n",
      "['/dataset/crit_int_pq/day_23.parquet']\n"
     ]
    }
   ],
   "source": [
    "fname = 'day_{}.parquet'\n",
    "num_days = len([i for i in os.listdir(INPUT_DATA_DIR) if re.match(fname.format('[0-9]{1,2}'), i) is not None])\n",
    "train_paths = [os.path.join(INPUT_DATA_DIR, fname.format(day)) for day in range(1)]\n",
    "valid_paths = [os.path.join(INPUT_DATA_DIR, fname.format(day)) for day in range(NUM_TRAIN_DAYS, num_days)]\n",
    "print(train_paths)\n",
    "print(valid_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "At this point, our data still isn't in a form that's ideal for consumption by neural networks. The most pressing issues are missing values and the fact that our categorical variables are still represented by random, discrete identifiers, and need to be transformed into contiguous indices that can be leveraged by a learned embedding. Less pressing, but still important for learning dynamics, are the distributions of our continuous variables, which are distributed across multiple orders of magnitude and are uncentered (i.e. E[x] != 0).\n",
    "\n",
    "We can fix these issues in a conscise and GPU-accelerated manner with an NVTabular `Workflow`. We'll instantiate one with our current dataset schema, then symbolically add operations _on_ that schema. By setting all these `Ops` to use `replace=True`, the schema itself will remain unmodified, while the variables represented by each field in the schema will be transformed.\n",
    "\n",
    "#### Frequency Thresholding\n",
    "One interesting thing worth pointing out is that we're using _frequency thresholding_ in our `Categorify` op. This handy functionality will map all categories which occur in the dataset with some threshold level of infrequency (which we've set here to be 15 occurrences throughout the dataset) to the _same_ index, keeping the model from overfitting to sparse signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = nvt.Workflow(\n",
    "    cat_names=CATEGORICAL_COLUMNS,\n",
    "    cont_names=CONTINUOUS_COLUMNS,\n",
    "    label_name=LABEL_COLUMNS)\n",
    "\n",
    "# log -> normalize continuous features. Note that doing this in the opposite\n",
    "# order wouldn't make sense! Note also that we're zero filling continuous\n",
    "# values before the log: this is a good time to remember that LogOp\n",
    "# performs log(1+x), not log(x)\n",
    "proc.add_cont_feature([ZeroFill(), LogOp()])\n",
    "proc.add_cont_preprocess(Normalize())\n",
    "\n",
    "# categorification with frequency thresholding\n",
    "proc.add_cat_preprocess(Categorify(freq_threshold=15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instantiate dataset iterators to loop through our dataset (which we couldn't fit into GPU memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I1': <class 'numpy.float32'>, 'I2': <class 'numpy.float32'>, 'I3': <class 'numpy.float32'>, 'I4': <class 'numpy.float32'>, 'I5': <class 'numpy.float32'>, 'I6': <class 'numpy.float32'>, 'I7': <class 'numpy.float32'>, 'I8': <class 'numpy.float32'>, 'I9': <class 'numpy.float32'>, 'I10': <class 'numpy.float32'>, 'I11': <class 'numpy.float32'>, 'I12': <class 'numpy.float32'>, 'I13': <class 'numpy.float32'>, 'C1': <class 'numpy.int64'>, 'C2': <class 'numpy.int64'>, 'C3': <class 'numpy.int64'>, 'C4': <class 'numpy.int64'>, 'C5': <class 'numpy.int64'>, 'C6': <class 'numpy.int64'>, 'C7': <class 'numpy.int64'>, 'C8': <class 'numpy.int64'>, 'C9': <class 'numpy.int64'>, 'C10': <class 'numpy.int64'>, 'C11': <class 'numpy.int64'>, 'C12': <class 'numpy.int64'>, 'C13': <class 'numpy.int64'>, 'C14': <class 'numpy.int64'>, 'C15': <class 'numpy.int64'>, 'C16': <class 'numpy.int64'>, 'C17': <class 'numpy.int64'>, 'C18': <class 'numpy.int64'>, 'C19': <class 'numpy.int64'>, 'C20': <class 'numpy.int64'>, 'C21': <class 'numpy.int64'>, 'C22': <class 'numpy.int64'>, 'C23': <class 'numpy.int64'>, 'C24': <class 'numpy.int64'>, 'C25': <class 'numpy.int64'>, 'C26': <class 'numpy.int64'>, 'label': <class 'numpy.float32'>}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "dict_dtypes={}\n",
    "\n",
    "for col in CONTINUOUS_COLUMNS:\n",
    "    dict_dtypes[col] = np.float32\n",
    "    \n",
    "for col in CATEGORICAL_COLUMNS:\n",
    "    dict_dtypes[col] = np.int64\n",
    "    \n",
    "for col in LABEL_COLUMNS:\n",
    "    dict_dtypes[col] = np.float32\n",
    "\n",
    "print(dict_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = nvt.Dataset(train_paths, engine='parquet', part_mem_fraction=0.12, dtypes=dict_dtypes)\n",
    "valid_dataset = nvt.Dataset(valid_paths, engine='parquet', part_mem_fraction=0.12, dtypes=dict_dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run them through our workflows to collect statistics on the train set, then transform and save to parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train_dir = os.path.join(OUTPUT_DATA_DIR, 'train/')\n",
    "output_valid_dir = os.path.join(OUTPUT_DATA_DIR, 'valid/')\n",
    "! mkdir -p $output_train_dir\n",
    "! mkdir -p $output_valid_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, let's time it to see how long it takes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 29.9 s, total: 1min 43s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proc.apply(train_dataset, apply_offline=True, record_stats=True, shuffle=False, output_format=\"parquet\", output_path=output_train_dir, out_files_per_proc=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([(381808, 16), (341642, 16), (112151, 16), (94957, 16), (11, 6), (2188, 16), (8399, 16), (61, 16), (4, 3), (949, 16), (15, 7), (22456, 16), (382633, 16), (246818, 16), (370704, 16), (92823, 16), (9773, 16), (78, 16), (34, 12), (14763, 16), (7118, 16), (19308, 16), (4, 3), (6443, 16), (1259, 16), (54, 15)])\n"
     ]
    }
   ],
   "source": [
    "embeddings = get_embedding_sizes(proc)\n",
    "print(embeddings.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.1 s, sys: 23.5 s, total: 47.6 s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proc.apply(valid_dataset, apply_offline=True, record_stats=False, shuffle=False, output_format=\"parquet\", output_path=output_valid_dir, out_files_per_proc=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2580642e51104d78bdbef22ef910b88e.parquet\n",
      "1.a50220d390c04a628bd27fa9709e9263.parquet\n",
      "10.a5336d3c8e2a4824a840094781088029.parquet\n",
      "11.c1897972237c4780bbc263758c65ea1b.parquet\n",
      "12.8b0b33ddccd34febb5dfc6683a581757.parquet\n",
      "13.6adbeecc520e4adda842ef53987b095e.parquet\n",
      "14.86f3f1f67c4c469eb2cb6f92f9bd363b.parquet\n",
      "2.3cfed92c47ff4cb1a1c35e2d612bbd41.parquet\n",
      "3.29593104ea214d698636f688c0e17415.parquet\n",
      "4.513da333424f4117a69bd08cc90c3c4e.parquet\n",
      "5.7e577b93d03447789ce6f8c6d67a2be2.parquet\n",
      "6.cc9ac9a0375f468fbcbdb2af947644e6.parquet\n",
      "7.0ce95854b53f4dbc81ed47d8b76d9f9c.parquet\n",
      "8.ba402631f3274f8584f0108692f22cce.parquet\n",
      "9.8580a33fb1fa467e8f3486f2fe9efdaf.parquet\n",
      "_file_list.txt\n",
      "_metadata\n",
      "_metadata.json\n",
      "metadata.json\n",
      "0.2172c9fb15204c76b4e98f2403751879.parquet\n",
      "1.5eb62a295143452b937322b9560f0310.parquet\n",
      "10.60eb9151953b4d229b7916becfb6c462.parquet\n",
      "11.1877c76a16114cdcadfd28639b3ef917.parquet\n",
      "12.e326daa90ca44a55ad87877f1d75de35.parquet\n",
      "13.a308a1438e594ce58b94e1d1999f2d44.parquet\n",
      "14.24e2e701ccb4416f9bd5fe027a67bceb.parquet\n",
      "2.2228744fe3e745e38efe19377d549027.parquet\n",
      "3.2c10dba495fc45fdac19f46ad56daf4e.parquet\n",
      "4.25cb0d89f8b94eeb8cbcb61c24cbc205.parquet\n",
      "5.7306233236914cb3aacff6e2064e8dac.parquet\n",
      "6.e26e2acb1c4c4651a10156ca7735bbb0.parquet\n",
      "7.13b78a1fd3104103a4fa32fe94a039a8.parquet\n",
      "8.5514950b78534cfab6b43c29c308c69d.parquet\n",
      "9.3f77ac9e6d954fc6b97c515c92007172.parquet\n",
      "_file_list.txt\n",
      "_metadata\n",
      "_metadata.json\n",
      "metadata.json\n"
     ]
    }
   ],
   "source": [
    "! cp $output_train_dir/_metadata.json $output_train_dir/metadata.json\n",
    "! cp $output_valid_dir/_metadata.json $output_valid_dir/metadata.json\n",
    "! ls $output_train_dir\n",
    "! ls $output_valid_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just like that, we have training and validation sets ready to feed to a model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HugeCTR\n",
    "### Training\n",
    "We'll run huge_ctr using the configuration file.\n",
    "\n",
    "First, we'll reinitialize our memory pool from earlier to free up some memory so that we can share it with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmm.reinitialize(pool_allocator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001, init_start, ]\n",
      "HugeCTR Version: 2.2.1\n",
      "Config file: dcn_parquet.json\n",
      "[25d20h38m04s][HUGECTR][INFO]: Default evaluation metric is AUC without threshold value\n",
      "[25d20h38m04s][HUGECTR][INFO]: algorithm_search is not specified using default: 1\n",
      "[25d20h38m04s][HUGECTR][INFO]: Algorithm search: ON\n",
      "[25d20h38m06s][HUGECTR][INFO]: Peer-to-peer access cannot be fully enabled.\n",
      "Device 0: Tesla V100-DGXS-16GB\n",
      "[25d20h38m06s][HUGECTR][INFO]: Initial seed is 2794287524\n",
      "[25d20h38m06s][HUGECTR][INFO]: cache_eval_data is not specified using default: 0\n",
      "[25d20h38m07s][HUGECTR][INFO]: Vocabulary size: 2116453\n",
      "[25d20h38m08s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[25d20h38m08s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[25d20h38m08s][HUGECTR][INFO]: max_vocabulary_size_per_gpu_=2700000\n",
      "[25d20h38m08s][HUGECTR][INFO]: All2All Warmup Start\n",
      "[25d20h38m08s][HUGECTR][INFO]: All2All Warmup End\n",
      "[25d20h38m09s][HUGECTR][INFO]: gpu0 start to init embedding\n",
      "[25d20h38m09s][HUGECTR][INFO]: gpu0 init embedding done\n",
      "[25d20h38m09s][HUGECTR][INFO]: warmup_steps is not specified using default: 1\n",
      "[25d20h38m09s][HUGECTR][INFO]: decay_start is not specified using default: 0\n",
      "[25d20h38m09s][HUGECTR][INFO]: decay_steps is not specified using default: 1\n",
      "[25d20h38m09s][HUGECTR][INFO]: decay_power is not specified using default: 2.000000\n",
      "[25d20h38m09s][HUGECTR][INFO]: end_lr is not specified using default: 0.000000\n",
      "[4663.16, init_end, ]\n",
      "[4663.17, run_start, ]\n",
      "HugeCTR training start:\n",
      "[4663.18, train_epoch_start, 0, ]\n",
      "[25d20h38m12s][HUGECTR][INFO]: Iter: 100 Time(100 iters): 2.690068s Loss: 0.133227 lr:0.001000\n",
      "[25d20h38m14s][HUGECTR][INFO]: Iter: 200 Time(100 iters): 2.646925s Loss: 0.130028 lr:0.001000\n",
      "[25d20h38m17s][HUGECTR][INFO]: Iter: 300 Time(100 iters): 2.637935s Loss: 0.129158 lr:0.001000\n",
      "[25d20h38m20s][HUGECTR][INFO]: Iter: 400 Time(100 iters): 2.618589s Loss: 0.134818 lr:0.001000\n",
      "[25d20h38m22s][HUGECTR][INFO]: Iter: 500 Time(100 iters): 2.627229s Loss: 0.124502 lr:0.001000\n",
      "[25d20h38m25s][HUGECTR][INFO]: Iter: 600 Time(100 iters): 2.634780s Loss: 0.117442 lr:0.001000\n",
      "[25d20h38m28s][HUGECTR][INFO]: Iter: 700 Time(100 iters): 2.634976s Loss: 0.122512 lr:0.001000\n",
      "[25d20h38m30s][HUGECTR][INFO]: Iter: 800 Time(100 iters): 2.632954s Loss: 0.117518 lr:0.001000\n",
      "[25d20h38m33s][HUGECTR][INFO]: Iter: 900 Time(100 iters): 2.609023s Loss: 0.123270 lr:0.001000\n",
      "[25d20h38m35s][HUGECTR][INFO]: Iter: 1000 Time(100 iters): 2.638226s Loss: 0.124973 lr:0.001000\n",
      "[25d20h38m38s][HUGECTR][INFO]: Iter: 1100 Time(100 iters): 2.637300s Loss: 0.124177 lr:0.001000\n",
      "[25d20h38m41s][HUGECTR][INFO]: Iter: 1200 Time(100 iters): 2.635439s Loss: 0.126173 lr:0.001000\n",
      "[25d20h38m43s][HUGECTR][INFO]: Iter: 1300 Time(100 iters): 2.609512s Loss: 0.117550 lr:0.001000\n",
      "[25d20h38m46s][HUGECTR][INFO]: Iter: 1400 Time(100 iters): 2.631900s Loss: 0.116511 lr:0.001000\n",
      "[25d20h38m49s][HUGECTR][INFO]: Iter: 1500 Time(100 iters): 2.631698s Loss: 0.119112 lr:0.001000\n",
      "[25d20h38m51s][HUGECTR][INFO]: Iter: 1600 Time(100 iters): 2.629566s Loss: 0.116431 lr:0.001000\n",
      "[25d20h38m54s][HUGECTR][INFO]: Iter: 1700 Time(100 iters): 2.615489s Loss: 0.114597 lr:0.001000\n",
      "[25d20h38m56s][HUGECTR][INFO]: Iter: 1800 Time(100 iters): 2.627121s Loss: 0.125127 lr:0.001000\n",
      "[25d20h38m59s][HUGECTR][INFO]: Iter: 1900 Time(100 iters): 2.635954s Loss: 0.127147 lr:0.001000\n",
      "[25d20h39m02s][HUGECTR][INFO]: Iter: 2000 Time(100 iters): 2.634639s Loss: 0.122965 lr:0.001000\n",
      "[25d20h39m04s][HUGECTR][INFO]: Iter: 2100 Time(100 iters): 2.606407s Loss: 0.120732 lr:0.001000\n",
      "[25d20h39m07s][HUGECTR][INFO]: Iter: 2200 Time(100 iters): 2.632016s Loss: 0.118385 lr:0.001000\n",
      "[25d20h39m10s][HUGECTR][INFO]: Iter: 2300 Time(100 iters): 2.632461s Loss: 0.123062 lr:0.001000\n",
      "[25d20h39m12s][HUGECTR][INFO]: Iter: 2400 Time(100 iters): 2.625666s Loss: 0.121781 lr:0.001000\n",
      "[25d20h39m15s][HUGECTR][INFO]: Iter: 2500 Time(100 iters): 2.613086s Loss: 0.123004 lr:0.001000\n",
      "[25d20h39m17s][HUGECTR][INFO]: Iter: 2600 Time(100 iters): 2.628439s Loss: 0.130568 lr:0.001000\n",
      "[25d20h39m20s][HUGECTR][INFO]: Iter: 2700 Time(100 iters): 2.634628s Loss: 0.126688 lr:0.001000\n",
      "[25d20h39m23s][HUGECTR][INFO]: Iter: 2800 Time(100 iters): 2.631991s Loss: 0.133538 lr:0.001000\n",
      "[25d20h39m25s][HUGECTR][INFO]: Iter: 2900 Time(100 iters): 2.613102s Loss: 0.126905 lr:0.001000\n",
      "[83547.6, train_epoch_end, 1, ]\n",
      "[83547.6, run_stop, ]\n"
     ]
    }
   ],
   "source": [
    "! /usr/local/hugectr/bin/huge_ctr --train dcn_parquet.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001, init_start, ]\n",
      "HugeCTR Version: 2.2.1\n",
      "Config file: dlrm_fp32_64k-ONLY2.json\n",
      "[25d20h40m12s][HUGECTR][INFO]: algorithm_search is not specified using default: 1\n",
      "[25d20h40m12s][HUGECTR][INFO]: Algorithm search: ON\n",
      "[25d20h40m13s][HUGECTR][INFO]: Peer-to-peer access cannot be fully enabled.\n",
      "Device 0: Tesla V100-DGXS-16GB\n",
      "[25d20h40m13s][HUGECTR][INFO]: Initial seed is 3713915342\n",
      "[25d20h40m13s][HUGECTR][INFO]: cache_eval_data is not specified using default: 0\n",
      "[25d20h40m15s][HUGECTR][INFO]: Vocabulary size: 2116453\n",
      "[25d20h40m15s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[25d20h40m15s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[25d20h40m15s][HUGECTR][INFO]: max_vocabulary_size_per_gpu_=2116453\n",
      "[25d20h40m15s][HUGECTR][INFO]: All2All Warmup Start\n",
      "[25d20h40m15s][HUGECTR][INFO]: All2All Warmup End\n",
      "[25d20h40m17s][HUGECTR][INFO]: gpu0 start to init embedding of slot0 , slot_size=381808, key_offset=0, value_index_offset=0\n",
      "[25d20h40m17s][HUGECTR][INFO]: gpu0 start to init embedding of slot1 , slot_size=341642, key_offset=381808, value_index_offset=381808\n",
      "[25d20h40m18s][HUGECTR][INFO]: gpu0 start to init embedding of slot2 , slot_size=112151, key_offset=723450, value_index_offset=723450\n",
      "[25d20h40m18s][HUGECTR][INFO]: gpu0 start to init embedding of slot3 , slot_size=94957, key_offset=835601, value_index_offset=835601\n",
      "[25d20h40m18s][HUGECTR][INFO]: gpu0 start to init embedding of slot4 , slot_size=11, key_offset=930558, value_index_offset=930558\n",
      "[25d20h40m18s][HUGECTR][INFO]: gpu0 start to init embedding of slot5 , slot_size=2188, key_offset=930569, value_index_offset=930569\n",
      "[25d20h40m18s][HUGECTR][INFO]: gpu0 start to init embedding of slot6 , slot_size=8399, key_offset=932757, value_index_offset=932757\n",
      "[25d20h40m18s][HUGECTR][INFO]: gpu0 start to init embedding of slot7 , slot_size=61, key_offset=941156, value_index_offset=941156\n",
      "[25d20h40m18s][HUGECTR][INFO]: gpu0 start to init embedding of slot8 , slot_size=4, key_offset=941217, value_index_offset=941217\n",
      "[25d20h40m18s][HUGECTR][INFO]: gpu0 start to init embedding of slot9 , slot_size=949, key_offset=941221, value_index_offset=941221\n",
      "[25d20h40m18s][HUGECTR][INFO]: gpu0 start to init embedding of slot10 , slot_size=15, key_offset=942170, value_index_offset=942170\n",
      "[25d20h40m18s][HUGECTR][INFO]: gpu0 start to init embedding of slot11 , slot_size=22456, key_offset=942185, value_index_offset=942185\n",
      "[25d20h40m18s][HUGECTR][INFO]: gpu0 start to init embedding of slot12 , slot_size=382633, key_offset=964641, value_index_offset=964641\n",
      "[25d20h40m19s][HUGECTR][INFO]: gpu0 start to init embedding of slot13 , slot_size=246818, key_offset=1347274, value_index_offset=1347274\n",
      "[25d20h40m19s][HUGECTR][INFO]: gpu0 start to init embedding of slot14 , slot_size=370704, key_offset=1594092, value_index_offset=1594092\n",
      "[25d20h40m20s][HUGECTR][INFO]: gpu0 start to init embedding of slot15 , slot_size=92823, key_offset=1964796, value_index_offset=1964796\n",
      "[25d20h40m20s][HUGECTR][INFO]: gpu0 start to init embedding of slot16 , slot_size=9773, key_offset=2057619, value_index_offset=2057619\n",
      "[25d20h40m20s][HUGECTR][INFO]: gpu0 start to init embedding of slot17 , slot_size=78, key_offset=2067392, value_index_offset=2067392\n",
      "[25d20h40m20s][HUGECTR][INFO]: gpu0 start to init embedding of slot18 , slot_size=34, key_offset=2067470, value_index_offset=2067470\n",
      "[25d20h40m20s][HUGECTR][INFO]: gpu0 start to init embedding of slot19 , slot_size=14763, key_offset=2067504, value_index_offset=2067504\n",
      "[25d20h40m20s][HUGECTR][INFO]: gpu0 start to init embedding of slot20 , slot_size=7118, key_offset=2082267, value_index_offset=2082267\n",
      "[25d20h40m20s][HUGECTR][INFO]: gpu0 start to init embedding of slot21 , slot_size=19308, key_offset=2089385, value_index_offset=2089385\n",
      "[25d20h40m20s][HUGECTR][INFO]: gpu0 start to init embedding of slot22 , slot_size=4, key_offset=2108693, value_index_offset=2108693\n",
      "[25d20h40m20s][HUGECTR][INFO]: gpu0 start to init embedding of slot23 , slot_size=6443, key_offset=2108697, value_index_offset=2108697\n",
      "[25d20h40m20s][HUGECTR][INFO]: gpu0 start to init embedding of slot24 , slot_size=1259, key_offset=2115140, value_index_offset=2115140\n",
      "[25d20h40m20s][HUGECTR][INFO]: gpu0 start to init embedding of slot25 , slot_size=54, key_offset=2116399, value_index_offset=2116399\n",
      "[8281.64, init_end, ]\n",
      "[8281.66, run_start, ]\n",
      "HugeCTR training start:\n",
      "[8281.67, train_epoch_start, 0, ]\n",
      "[25d20h40m51s][HUGECTR][INFO]: Iter: 1000 Time(1000 iters): 30.922205s Loss: 0.131201 lr:3.003000\n",
      "[25d20h41m22s][HUGECTR][INFO]: Iter: 2000 Time(1000 iters): 30.863894s Loss: 0.126320 lr:6.003000\n",
      "[25d20h41m53s][HUGECTR][INFO]: Iter: 3000 Time(1000 iters): 30.833528s Loss: 0.128341 lr:9.003000\n",
      "[HCDEBUG][ERROR] Runtime error: Runtime vocabulary size (2460028) exceeds max_vocabulary_size_per_gpu (2116453) on GPU 0, new feature insertion failed.\n",
      " /hugectr/HugeCTR/include/embeddings/localized_slot_sparse_embedding_hash.hpp:592 \n",
      "\n",
      "Terminated with error\n"
     ]
    }
   ],
   "source": [
    "! /usr/local/hugectr/bin/huge_ctr --train dlrm_fp32_64k-ONLY2.json # 1 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001, init_start, ]\n",
      "HugeCTR Version: 2.2.1\n",
      "Config file: dlrm_fp32_64k-ONLY2.json\n",
      "[25d20h54m22s][HUGECTR][INFO]: algorithm_search is not specified using default: 1\n",
      "[25d20h54m22s][HUGECTR][INFO]: Algorithm search: ON\n",
      "[25d20h54m23s][HUGECTR][INFO]: Peer-to-peer access cannot be fully enabled.\n",
      "Device 0: Tesla V100-DGXS-16GB\n",
      "[25d20h54m23s][HUGECTR][INFO]: Initial seed is 129554190\n",
      "[25d20h54m23s][HUGECTR][INFO]: cache_eval_data is not specified using default: 0\n",
      "[25d20h54m25s][HUGECTR][INFO]: Vocabulary size: 2116453\n",
      "[25d20h54m25s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[25d20h54m25s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[25d20h54m25s][HUGECTR][INFO]: max_vocabulary_size_per_gpu_=2116453\n",
      "[25d20h54m25s][HUGECTR][INFO]: All2All Warmup Start\n",
      "[25d20h54m25s][HUGECTR][INFO]: All2All Warmup End\n",
      "[25d20h54m26s][HUGECTR][INFO]: gpu0 start to init embedding of slot0 , slot_size=381808, key_offset=0, value_index_offset=0\n",
      "[25d20h54m27s][HUGECTR][INFO]: gpu0 start to init embedding of slot1 , slot_size=341642, key_offset=381808, value_index_offset=381808\n",
      "[25d20h54m28s][HUGECTR][INFO]: gpu0 start to init embedding of slot2 , slot_size=112151, key_offset=723450, value_index_offset=723450\n",
      "[25d20h54m28s][HUGECTR][INFO]: gpu0 start to init embedding of slot3 , slot_size=94957, key_offset=835601, value_index_offset=835601\n",
      "[25d20h54m28s][HUGECTR][INFO]: gpu0 start to init embedding of slot4 , slot_size=11, key_offset=930558, value_index_offset=930558\n",
      "[25d20h54m28s][HUGECTR][INFO]: gpu0 start to init embedding of slot5 , slot_size=2188, key_offset=930569, value_index_offset=930569\n",
      "[25d20h54m28s][HUGECTR][INFO]: gpu0 start to init embedding of slot6 , slot_size=8399, key_offset=932757, value_index_offset=932757\n",
      "[25d20h54m28s][HUGECTR][INFO]: gpu0 start to init embedding of slot7 , slot_size=61, key_offset=941156, value_index_offset=941156\n",
      "[25d20h54m28s][HUGECTR][INFO]: gpu0 start to init embedding of slot8 , slot_size=4, key_offset=941217, value_index_offset=941217\n",
      "[25d20h54m28s][HUGECTR][INFO]: gpu0 start to init embedding of slot9 , slot_size=949, key_offset=941221, value_index_offset=941221\n",
      "[25d20h54m28s][HUGECTR][INFO]: gpu0 start to init embedding of slot10 , slot_size=15, key_offset=942170, value_index_offset=942170\n",
      "[25d20h54m28s][HUGECTR][INFO]: gpu0 start to init embedding of slot11 , slot_size=22456, key_offset=942185, value_index_offset=942185\n",
      "[25d20h54m28s][HUGECTR][INFO]: gpu0 start to init embedding of slot12 , slot_size=382633, key_offset=964641, value_index_offset=964641\n",
      "[25d20h54m29s][HUGECTR][INFO]: gpu0 start to init embedding of slot13 , slot_size=246818, key_offset=1347274, value_index_offset=1347274\n",
      "[25d20h54m29s][HUGECTR][INFO]: gpu0 start to init embedding of slot14 , slot_size=370704, key_offset=1594092, value_index_offset=1594092\n",
      "[25d20h54m30s][HUGECTR][INFO]: gpu0 start to init embedding of slot15 , slot_size=92823, key_offset=1964796, value_index_offset=1964796\n",
      "[25d20h54m30s][HUGECTR][INFO]: gpu0 start to init embedding of slot16 , slot_size=9773, key_offset=2057619, value_index_offset=2057619\n",
      "[25d20h54m30s][HUGECTR][INFO]: gpu0 start to init embedding of slot17 , slot_size=78, key_offset=2067392, value_index_offset=2067392\n",
      "[25d20h54m30s][HUGECTR][INFO]: gpu0 start to init embedding of slot18 , slot_size=34, key_offset=2067470, value_index_offset=2067470\n",
      "[25d20h54m30s][HUGECTR][INFO]: gpu0 start to init embedding of slot19 , slot_size=14763, key_offset=2067504, value_index_offset=2067504\n",
      "[25d20h54m30s][HUGECTR][INFO]: gpu0 start to init embedding of slot20 , slot_size=7118, key_offset=2082267, value_index_offset=2082267\n",
      "[25d20h54m30s][HUGECTR][INFO]: gpu0 start to init embedding of slot21 , slot_size=19308, key_offset=2089385, value_index_offset=2089385\n",
      "[25d20h54m30s][HUGECTR][INFO]: gpu0 start to init embedding of slot22 , slot_size=4, key_offset=2108693, value_index_offset=2108693\n",
      "[25d20h54m30s][HUGECTR][INFO]: gpu0 start to init embedding of slot23 , slot_size=6443, key_offset=2108697, value_index_offset=2108697\n",
      "[25d20h54m30s][HUGECTR][INFO]: gpu0 start to init embedding of slot24 , slot_size=1259, key_offset=2115140, value_index_offset=2115140\n",
      "[25d20h54m30s][HUGECTR][INFO]: gpu0 start to init embedding of slot25 , slot_size=54, key_offset=2116399, value_index_offset=2116399\n",
      "[8305.04, init_end, ]\n",
      "[8305.06, run_start, ]\n",
      "HugeCTR training start:\n",
      "[8305.07, train_epoch_start, 0, ]\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "! /usr/local/hugectr/bin/huge_ctr --train dlrm_fp32_64k-ONLY2.json # 2 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.001, init_start, ]\n",
      "HugeCTR Version: 2.2.1\n",
      "Config file: dlrm_fp32_64k-ONLY2.json\n",
      "[25d20h54m57s][HUGECTR][INFO]: algorithm_search is not specified using default: 1\n",
      "[25d20h54m57s][HUGECTR][INFO]: Algorithm search: ON\n",
      "Device 0: Tesla V100-DGXS-16GB\n",
      "Device 1: Tesla V100-DGXS-16GB\n",
      "Device 2: Tesla V100-DGXS-16GB\n",
      "Device 3: Tesla V100-DGXS-16GB\n",
      "[25d20h55m08s][HUGECTR][INFO]: Initial seed is 1315226875\n",
      "[25d20h55m08s][HUGECTR][INFO]: cache_eval_data is not specified using default: 0\n",
      "[25d20h55m08s][HUGECTR][INFO]: Vocabulary size: 2116453\n",
      "[25d20h55m08s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[25d20h55m08s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[25d20h55m08s][HUGECTR][INFO]: max_vocabulary_size_per_gpu_=782606\n",
      "[25d20h55m08s][HUGECTR][INFO]: All2All Warmup Start\n",
      "[25d20h55m08s][HUGECTR][INFO]: All2All Warmup End\n",
      "[25d20h55m10s][HUGECTR][INFO]: gpu0 start to init embedding of slot0 , slot_size=381808, key_offset=0, value_index_offset=0\n",
      "[25d20h55m11s][HUGECTR][INFO]: gpu0 start to init embedding of slot4 , slot_size=11, key_offset=930558, value_index_offset=381808\n",
      "[25d20h55m11s][HUGECTR][INFO]: gpu0 start to init embedding of slot8 , slot_size=4, key_offset=941217, value_index_offset=381819\n",
      "[25d20h55m11s][HUGECTR][INFO]: gpu0 start to init embedding of slot12 , slot_size=382633, key_offset=964641, value_index_offset=381823\n",
      "[25d20h55m12s][HUGECTR][INFO]: gpu0 start to init embedding of slot16 , slot_size=9773, key_offset=2057619, value_index_offset=764456\n",
      "[25d20h55m12s][HUGECTR][INFO]: gpu0 start to init embedding of slot20 , slot_size=7118, key_offset=2082267, value_index_offset=774229\n",
      "[25d20h55m12s][HUGECTR][INFO]: gpu0 start to init embedding of slot24 , slot_size=1259, key_offset=2115140, value_index_offset=781347\n",
      "[25d20h55m12s][HUGECTR][INFO]: gpu1 start to init embedding of slot1 , slot_size=341642, key_offset=381808, value_index_offset=0\n",
      "[25d20h55m12s][HUGECTR][INFO]: gpu1 start to init embedding of slot5 , slot_size=2188, key_offset=930569, value_index_offset=341642\n",
      "[25d20h55m12s][HUGECTR][INFO]: gpu1 start to init embedding of slot9 , slot_size=949, key_offset=941221, value_index_offset=343830\n",
      "[25d20h55m12s][HUGECTR][INFO]: gpu1 start to init embedding of slot13 , slot_size=246818, key_offset=1347274, value_index_offset=344779\n",
      "[25d20h55m13s][HUGECTR][INFO]: gpu1 start to init embedding of slot17 , slot_size=78, key_offset=2067392, value_index_offset=591597\n",
      "[25d20h55m13s][HUGECTR][INFO]: gpu1 start to init embedding of slot21 , slot_size=19308, key_offset=2089385, value_index_offset=591675\n",
      "[25d20h55m13s][HUGECTR][INFO]: gpu1 start to init embedding of slot25 , slot_size=54, key_offset=2116399, value_index_offset=610983\n",
      "[25d20h55m13s][HUGECTR][INFO]: gpu2 start to init embedding of slot2 , slot_size=112151, key_offset=723450, value_index_offset=0\n",
      "[25d20h55m13s][HUGECTR][INFO]: gpu2 start to init embedding of slot6 , slot_size=8399, key_offset=932757, value_index_offset=112151\n",
      "[25d20h55m13s][HUGECTR][INFO]: gpu2 start to init embedding of slot10 , slot_size=15, key_offset=942170, value_index_offset=120550\n",
      "[25d20h55m13s][HUGECTR][INFO]: gpu2 start to init embedding of slot14 , slot_size=370704, key_offset=1594092, value_index_offset=120565\n",
      "[25d20h55m14s][HUGECTR][INFO]: gpu2 start to init embedding of slot18 , slot_size=34, key_offset=2067470, value_index_offset=491269\n",
      "[25d20h55m14s][HUGECTR][INFO]: gpu2 start to init embedding of slot22 , slot_size=4, key_offset=2108693, value_index_offset=491303\n",
      "[25d20h55m14s][HUGECTR][INFO]: gpu3 start to init embedding of slot3 , slot_size=94957, key_offset=835601, value_index_offset=0\n",
      "[25d20h55m14s][HUGECTR][INFO]: gpu3 start to init embedding of slot7 , slot_size=61, key_offset=941156, value_index_offset=94957\n",
      "[25d20h55m14s][HUGECTR][INFO]: gpu3 start to init embedding of slot11 , slot_size=22456, key_offset=942185, value_index_offset=95018\n",
      "[25d20h55m14s][HUGECTR][INFO]: gpu3 start to init embedding of slot15 , slot_size=92823, key_offset=1964796, value_index_offset=117474\n",
      "[25d20h55m14s][HUGECTR][INFO]: gpu3 start to init embedding of slot19 , slot_size=14763, key_offset=2067504, value_index_offset=210297\n",
      "[25d20h55m14s][HUGECTR][INFO]: gpu3 start to init embedding of slot23 , slot_size=6443, key_offset=2108697, value_index_offset=225060\n",
      "[17209.1, init_end, ]\n",
      "[17209.2, run_start, ]\n",
      "HugeCTR training start:\n",
      "[17209.2, train_epoch_start, 0, ]\n",
      "[25d20h58m55s][HUGECTR][INFO]: Iter: 1000 Time(1000 iters): 220.682345s Loss: 0.135077 lr:3.003000\n"
     ]
    }
   ],
   "source": [
    "! /usr/local/hugectr/bin/huge_ctr --train dlrm_fp32_64k-ONLY2.json # 4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
