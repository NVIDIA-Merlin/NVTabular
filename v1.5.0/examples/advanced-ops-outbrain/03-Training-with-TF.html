<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>NVTabular demo on Outbrain Data &mdash; NVTabular 2021 documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/mystnb.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
    <link rel="canonical" href="https://nvidia-merlin.github.io/NVTabular/main/examples/advanced-ops-outbrain/03-Training-with-TF.html" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="../../_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Scaling to Large Datasets with Criteo" href="../scaling-criteo/index.html" />
    <link rel="prev" title="Getting Started Outbrain: ETL with NVTabular" href="02-ETL-with-NVTabular.html" /> 
</head>

<body class="wy-body-for-nav">
  <div class="banner">
    <p class="banner">
      Beginning in January 2023, versions for all NVIDIA Merlin projects
      will change from semantic versioning like <code>4.0</code>
      to calendar versioning like <code>23.01</code>.</p>
  </div>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> NVTabular
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../Introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core_features.html">Core Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/index.html">Accelerated Training</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Example Notebooks</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#structure">Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#available-example-notebooks">Available Example Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#running-the-example-notebooks">Running the Example Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#troubleshooting">Troubleshooting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../getting-started-movielens/index.html">Getting Started with MovieLens</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Advanced Ops with Outbrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../scaling-criteo/index.html">Scaling to Large Datasets with Criteo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tabular-data-rossmann/index.html">Applying Techniques to Rossmann Stores Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multi-gpu-movielens/index.html">Multi-GPU Example Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../winning-solution-recsys2020-twitter/01-02-04-Download-Convert-ETL-with-NVTabular-Training-with-XGBoost.html">Winning Solution of the RecSys2020 Competition</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources/index.html">Additional Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">NVTabular</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">NVTabular Example Notebooks</a></li>
          <li class="breadcrumb-item"><a href="index.html">Advanced Ops with Outbrain</a></li>
      <li class="breadcrumb-item active">NVTabular demo on Outbrain Data</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Copyright 2021 NVIDIA Corporation. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
</pre></div>
</div>
</div>
</div>
<div class="section" id="nvtabular-demo-on-outbrain-data">
<h1>NVTabular demo on Outbrain Data<a class="headerlink" href="#nvtabular-demo-on-outbrain-data" title="Permalink to this headline"></a></h1>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>In this notebook we train TF Wide &amp; Deep Learning framework using <a class="reference external" href="https://www.kaggle.com/c/outbrain-click-prediction">Kaggle Outbrain dataset</a>. In that competition, ‘Kagglers’ were challenged to predict on which ads and other forms of sponsored content its global users would click.</p>
<p><a class="reference external" href="https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html">Wide &amp; Deep Learning</a> refers to a class of networks that use the output of two parts working in parallel - wide model and deep model - to make predictions using categorical and continuous inputs. The wide model is a generalized linear model of features together with their transforms. The deep model in this notebook is a series of three hidden MLP layers of [1024, 512, 256] neurons each beginning with a dense embedding of features.</p>
<p><strong>Learning objectives</strong><br><br>
This notebook explains, how to use the NVTabular dataloader to accelerate TensorFlow training.</p>
<ul class="simple">
<li><p>Use NVTabular dataloader with TensorFlow Keras model</p></li>
<li><p>Training Wide&amp;Deep model with NVTabular dataloader in TensorFlow</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
import tensorflow as tf

# we can control how much memory to give tensorflow with this environment variable
# IMPORTANT: make sure you do this before you initialize TF&#39;s runtime, otherwise
# TF will have claimed all free GPU memory
# os.environ[&#39;TF_MEMORY_ALLOCATION&#39;] = &quot;0.8&quot; # fraction of free memory

from nvtabular.loader.tensorflow import KerasSequenceLoader, KerasSequenceValidater
from nvtabular.framework_utils.tensorflow import layers
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import glob

import nvtabular as nvt
</pre></div>
</div>
</div>
</div>
<p>First, we set where the parquet datasets were saved once processed (OUTPUT_BUCKET_FOLDER).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>OUTPUT_BUCKET_FOLDER = os.environ.get(&quot;OUTPUT_DATA_DIR&quot;, &quot;./outbrain-preprocessed/&quot;)
</pre></div>
</div>
</div>
</div>
<p>In the previous notebook, we used NVTabular for ETL and stored the workflow to disk. We can load the NVTabular workflow to extract important metadata for our training pipeline.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>workflow = nvt.Workflow.load(os.path.join(OUTPUT_BUCKET_FOLDER, &quot;workflow&quot;))
</pre></div>
</div>
</div>
</div>
<p>EMBEDDING_TABLE_SHAPES defines the size of the embedding tables that our model will use to map categorical outputs from NVTabular into numeric dense inputs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from nvtabular.ops import get_embedding_sizes

EMBEDDING_TABLE_SHAPES = {
    column: (shape[0], min(shape[1], 16)) for column, shape in get_embedding_sizes(workflow).items()
}
EMBEDDING_TABLE_SHAPES
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;ad_id&#39;: (418480, 16),
 &#39;advertiser_id&#39;: (4054, 16),
 &#39;campaign_id&#39;: (31390, 16),
 &#39;document_id&#39;: (693497, 16),
 &#39;document_id_promo&#39;: (143991, 16),
 &#39;geo_location&#39;: (2885, 16),
 &#39;geo_location_country&#39;: (231, 16),
 &#39;geo_location_state&#39;: (2485, 16),
 &#39;platform&#39;: (4, 16),
 &#39;publisher_id&#39;: (482, 16),
 &#39;publisher_id_promo&#39;: (861, 16),
 &#39;source_id&#39;: (4739, 16),
 &#39;source_id_promo&#39;: (6818, 16)}
</pre></div>
</div>
</div>
</div>
<p>We select define categorical and numerical features that are processed and generated via the NVTabular workflow to train our W&amp;D TF model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>CATEGORICAL_COLUMNS = [
    &quot;geo_location&quot;,
    &quot;geo_location_country&quot;,
    &quot;geo_location_state&quot;,
    &quot;ad_id&quot;,
    &quot;document_id&quot;,
    &quot;platform&quot;,
    &quot;document_id_promo&quot;,
    &quot;campaign_id&quot;,
    &quot;advertiser_id&quot;,
    &quot;source_id&quot;,
    &quot;publisher_id&quot;,
    &quot;source_id_promo&quot;,
    &quot;publisher_id_promo&quot;,
]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>NUMERIC_COLUMNS = [
    &quot;document_id_document_id_promo_sim_categories&quot;,
    &quot;document_id_document_id_promo_sim_topics&quot;,
    &quot;document_id_document_id_promo_sim_entities&quot;,
    &quot;publish_time_since_published&quot;,
    &quot;publish_time_promo_since_published&quot;,
    &quot;TE_ad_id_clicked&quot;,
    &quot;TE_document_id_promo_clicked&quot;,
    &quot;TE_campaign_id_clicked&quot;,
    &quot;TE_advertiser_id_clicked&quot;,
    &quot;TE_source_id_clicked&quot;,
    &quot;TE_publisher_id_clicked&quot;,
]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="training-a-tf-w-d-model">
<h2>Training a TF W&amp;D Model<a class="headerlink" href="#training-a-tf-w-d-model" title="Permalink to this headline"></a></h2>
<p>We create tensorflow feature columns corresponding to each feature of the model input. If you’re using NVTabular with TensorFlow feature_columns, you should only be using <code class="docutils literal notranslate"><span class="pre">tf.feature_column.categorical_column_with_identity</span></code> for categorical features, since any other transformation (categorification and/or hashing) should be handled in NVTabular on the GPU. This feature column is passed to the wide portion of the model. If a categorical column corresponds to an embedding table, it is wrapped with an embedding_column feature_column, if it does not correspond to an embedding table, it is wrapped as an indicator column. The wrapped column is passed to the deep portion of the model. Continuous columns are passed to both the wide and deep portions of the model after being encapsulated as a <code class="docutils literal notranslate"><span class="pre">numeric_column</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def get_feature_columns():
    wide_columns, deep_columns = [], []

    for column_name in CATEGORICAL_COLUMNS:
        if (
            column_name in EMBEDDING_TABLE_SHAPES
        ):  # Changing hashing to identity + adding modulo to dataloader
            categorical_column = tf.feature_column.categorical_column_with_identity(
                column_name, num_buckets=EMBEDDING_TABLE_SHAPES[column_name][0]
            )
        else:
            raise ValueError(f&quot;Unexpected categorical column found {column_name}&quot;)

        if column_name in EMBEDDING_TABLE_SHAPES:
            wrapped_column = tf.feature_column.embedding_column(
                categorical_column,
                dimension=EMBEDDING_TABLE_SHAPES[column_name][1],
                combiner=&quot;mean&quot;,
            )
        else:
            wrapped_column = tf.feature_column.indicator_column(categorical_column)

        wide_columns.append(categorical_column)
        deep_columns.append(wrapped_column)

    numerics = [
        tf.feature_column.numeric_column(column_name, shape=(1,), dtype=tf.float32)
        for column_name in NUMERIC_COLUMNS
    ]

    wide_columns.extend(numerics)
    deep_columns.extend(numerics)

    return wide_columns, deep_columns
</pre></div>
</div>
</div>
</div>
<p>Next, we define the layer shape and dropout probability for the deep portion of the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>deep_hidden_units = [1024, 512, 256]
deep_dropout = 0.1
</pre></div>
</div>
</div>
</div>
<p>An input is created for each feature column, with a datatype of either tf.float32 for continuous values, or tf.int32 for categorical values. To implement the wide model, for categorical inputs, we embed them to a dimension of one, and sum them with the results of applying a dense layer with output dimension one, effectively weighting and summing each of the inputs. For the deep model, we embed our categorical columns according to the feature columns we defined earlier, and concatenate the newly dense features with our dense continuous features, which we pass to our deep model, which by default is a 5 layer MLP with internal dimension of 1024 neurons for each layer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>wide_columns, deep_columns = get_feature_columns()

wide_weighted_outputs = []  # a list of (batch_size, 1) contributors to the linear weighted sum
numeric_dense_inputs = []  # NumericColumn inputs; to be concatenated and then fed to a dense layer
wide_columns_dict = {}  # key : column
deep_columns_dict = {}  # key : column
features = {}  # tf.keras.Input placeholders for each feature to be used

# construct input placeholders for wide features
for col in wide_columns:
    features[col.key] = tf.keras.Input(
        shape=(1,),
        batch_size=None,
        name=col.key,
        dtype=tf.float32 if col.key in NUMERIC_COLUMNS else tf.int32,
        sparse=False,
    )
    wide_columns_dict[col.key] = col
for col in deep_columns:
    is_embedding_column = &quot;key&quot; not in dir(col)
    key = col.categorical_column.key if is_embedding_column else col.key

    if key not in features:
        features[key] = tf.keras.Input(
            shape=(1,),
            batch_size=None,
            name=key,
            dtype=tf.float32 if col.key in NUMERIC_COLUMNS else tf.int32,
            sparse=False,
        )
    deep_columns_dict[key] = col

for key in wide_columns_dict:
    if key in EMBEDDING_TABLE_SHAPES:
        wide_weighted_outputs.append(
            tf.keras.layers.Flatten()(
                tf.keras.layers.Embedding(EMBEDDING_TABLE_SHAPES[key][0], 1, input_length=1)(
                    features[key]
                )
            )
        )
    else:
        numeric_dense_inputs.append(features[key])

categorical_output_contrib = tf.keras.layers.add(wide_weighted_outputs, name=&quot;categorical_output&quot;)
numeric_dense_tensor = tf.keras.layers.concatenate(numeric_dense_inputs, name=&quot;numeric_dense&quot;)
deep_columns = list(deep_columns_dict.values())

dnn = layers.DenseFeatures(deep_columns, name=&quot;deep_embedded&quot;)(features)
for unit_size in deep_hidden_units:
    dnn = tf.keras.layers.Dense(units=unit_size, activation=&quot;relu&quot;)(dnn)
    dnn = tf.keras.layers.Dropout(rate=deep_dropout)(dnn)
    dnn = tf.keras.layers.BatchNormalization(momentum=0.999)(dnn)
dnn = tf.keras.layers.Dense(units=1)(dnn)
dnn_model = tf.keras.Model(inputs=features, outputs=dnn)
linear_output = categorical_output_contrib + tf.keras.layers.Dense(1)(numeric_dense_tensor)

linear_model = tf.keras.Model(inputs=features, outputs=linear_output)

wide_and_deep_model = tf.keras.experimental.WideDeepModel(
    linear_model, dnn_model, activation=&quot;sigmoid&quot;
)
</pre></div>
</div>
</div>
</div>
<p>We define the datasets that will be used to ingest data into our model. In this case, the NVTabular dataloaders take a set of parquet files generated by NVTabular as input, and are capable of accelerated throughput. The <a class="reference external" href="https://github.com/NVIDIA/NVTabular/blob/9aa70caa1dfb5d2fd694cad535def1e470d37b29/nvtabular/loader/tensorflow.py#L89">KerasSequenceLoader</a> manages shuffling by loading in chunks of data from different parts of the full dataset, concatenating them and then shuffling, then iterating through this super-chunk sequentially in batches. The number of “parts” of the dataset that get sample, or “partitions”, is controlled by the <i>parts_per_chunk</i> parameter, while the size of each one of these parts is controlled by the <i>buffer_size</i> parameter, which refers to a fraction of available GPU memory. Using more chunks leads to better randomness, especially at the epoch level where physically disparate samples can be brought into the same batch, but can impact throughput if you use too many.</p>
<p>The validation process gets slightly complicated by the fact that <i>model.fit</i> doesn’t accept Keras Sequence objects as validation data. To support this, we also define a <a class="reference external" href="https://github.com/NVIDIA/NVTabular/blob/9aa70caa1dfb5d2fd694cad535def1e470d37b29/nvtabular/loader/tensorflow.py#L351">KerasSequenceValidater</a>, a lightweight Keras callback to handle validation.</p>
<p>Now that our data is preprocessed and saved out, we can leverage datasets to read through the preprocessed parquet files in an online fashion to train neural networks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>TRAIN_PATHS = sorted(glob.glob(os.path.join(OUTPUT_BUCKET_FOLDER, &quot;train/*.parquet&quot;)))
VALID_PATHS = sorted(glob.glob(os.path.join(OUTPUT_BUCKET_FOLDER, &quot;valid/*.parquet&quot;)))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_dataset_tf = KerasSequenceLoader(
    TRAIN_PATHS,  # you could also use a glob pattern
    batch_size=131072,
    label_names=[&quot;clicked&quot;],
    cat_names=CATEGORICAL_COLUMNS,
    cont_names=NUMERIC_COLUMNS,
    engine=&quot;parquet&quot;,
    shuffle=True,
    buffer_size=0.06,  # how many batches to load at once
    parts_per_chunk=1,
)

valid_dataset_tf = KerasSequenceLoader(
    VALID_PATHS,  # you could also use a glob pattern
    batch_size=131072,
    label_names=[&quot;clicked&quot;],
    cat_names=CATEGORICAL_COLUMNS,
    cont_names=NUMERIC_COLUMNS,
    engine=&quot;parquet&quot;,
    shuffle=False,
    buffer_size=0.06,
    parts_per_chunk=1,
)
validation_callback = KerasSequenceValidater(valid_dataset_tf)
</pre></div>
</div>
</div>
</div>
<p>The wide portion of the model is optimized using the <i>Follow The Regularized Leader (FTRL)</i> algorithm, while the deep portion of the model is optimized using <i>Adam</i> optimizer.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>wide_optimizer = tf.keras.optimizers.Ftrl(
    learning_rate=0.1,
)

deep_optimizer = tf.keras.optimizers.Adam(learning_rate=0.2)
</pre></div>
</div>
</div>
</div>
<p>Finally, we compile our model with our dual optimizers and binary cross-entropy loss, and train our model for 10 epochs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>wide_and_deep_model.compile(
    optimizer=[wide_optimizer, deep_optimizer],
    loss=&quot;binary_crossentropy&quot;,
    metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.AUC()],
    experimental_run_tf_function=False,
)
history = wide_and_deep_model.fit(train_dataset_tf, callbacks=[validation_callback], epochs=5)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/5
456/456 [==============================] - 93s 196ms/step - loss: 0.8359 - binary_accuracy: 0.7808 - auc: 0.6394
Epoch 2/5
456/456 [==============================] - 85s 187ms/step - loss: 0.4289 - binary_accuracy: 0.8145 - auc: 0.7449
Epoch 3/5
456/456 [==============================] - 86s 188ms/step - loss: 0.4244 - binary_accuracy: 0.8165 - auc: 0.7519
Epoch 4/5
456/456 [==============================] - 84s 184ms/step - loss: 0.4190 - binary_accuracy: 0.8187 - auc: 0.7608
Epoch 5/5
456/456 [==============================] - 86s 189ms/step - loss: 0.4130 - binary_accuracy: 0.8219 - auc: 0.7694
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="02-ETL-with-NVTabular.html" class="btn btn-neutral float-left" title="Getting Started Outbrain: ETL with NVTabular" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../scaling-criteo/index.html" class="btn btn-neutral float-right" title="Scaling to Large Datasets with Criteo" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: v1.5.0
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../../v1.3.2/index.html">v1.3.2</a></dd>
      <dd><a href="../../../v1.3.3/index.html">v1.3.3</a></dd>
      <dd><a href="../../../v1.4.0/index.html">v1.4.0</a></dd>
      <dd><a href="03-Training-with-TF.html">v1.5.0</a></dd>
      <dd><a href="../../../v1.6.0/index.html">v1.6.0</a></dd>
      <dd><a href="../../../v1.7.0/index.html">v1.7.0</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../../../main/index.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NVJ1Y1YJHK', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>