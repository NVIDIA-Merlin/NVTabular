<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Getting Started Outbrain: ETL with NVTabular &mdash; NVTabular 2021 documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/mystnb.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
    <link rel="canonical" href="https://nvidia-merlin.github.io/NVTabular/main/examples/advanced-ops-outbrain/02-ETL-with-NVTabular.html" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="../../_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="NVTabular demo on Outbrain Data" href="03-Training-with-TF.html" />
    <link rel="prev" title="Getting Started Outbrain: Download and Convert" href="01-Download-Convert.html" /> 
</head>

<body class="wy-body-for-nav">
  <div class="banner">
    <p class="banner">
      Beginning in January 2023, versions for all NVIDIA Merlin projects
      will change from semantic versioning like <code>4.0</code>
      to calendar versioning like <code>23.01</code>.</p>
  </div>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> NVTabular
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../Introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core_features.html">Core Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/index.html">Accelerated Training</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Example Notebooks</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#structure">Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#available-example-notebooks">Available Example Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#running-the-example-notebooks">Running the Example Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#troubleshooting">Troubleshooting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../getting-started-movielens/index.html">Getting Started with MovieLens</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Advanced Ops with Outbrain</a></li>
<li class="toctree-l2"><a class="reference internal" href="../scaling-criteo/index.html">Scaling to Large Datasets with Criteo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tabular-data-rossmann/index.html">Applying Techniques to Rossmann Stores Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multi-gpu-movielens/index.html">Multi-GPU Example Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../winning-solution-recsys2020-twitter/01-02-04-Download-Convert-ETL-with-NVTabular-Training-with-XGBoost.html">Winning Solution of the RecSys2020 Competition</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources/index.html">Additional Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">NVTabular</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">NVTabular Example Notebooks</a></li>
          <li class="breadcrumb-item"><a href="index.html">Advanced Ops with Outbrain</a></li>
      <li class="breadcrumb-item active">Getting Started Outbrain: ETL with NVTabular</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Copyright 2021 NVIDIA Corporation. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
</pre></div>
</div>
</div>
</div>
<div class="section" id="getting-started-outbrain-etl-with-nvtabular">
<h1>Getting Started Outbrain: ETL with NVTabular<a class="headerlink" href="#getting-started-outbrain-etl-with-nvtabular" title="Permalink to this headline"></a></h1>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>In this notebook we will do preprocessing and feature engineering using <a class="reference external" href="https://www.kaggle.com/c/outbrain-click-prediction">Kaggle Outbrain dataset</a>.</p>
<p><strong>Learning objectives</strong></p>
<p>In this notebook, we learn how to</p>
<ul class="simple">
<li><p>Use LambdaOp for custom row-wise dataframe manipulations with NVTabular</p></li>
<li><p>Preprocess single-hot categorical input features with NVTabular</p></li>
<li><p>Apply TargetEncoding to categorical features</p></li>
<li><p>Create a custom operator to create time features</p></li>
<li><p>Apply ColumnSimilarity to calculate the similarity between two columns using tf-idf metric</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
import glob

import cupy

# Get dataframe library - cudf or pandas
from merlin.core.dispatch import get_lib
df_lib = get_lib()

import nvtabular as nvt
from merlin.io import Shuffle
from nvtabular.ops import (
    FillMedian,
    Categorify,
    LogOp,
    TargetEncoding,
    Rename,
)
from nvtabular.ops.column_similarity import ColumnSimilarity

from nvtabular import ColumnGroup
</pre></div>
</div>
</div>
</div>
<p>First, we set where the dataset should be saved once processed (OUTPUT_BUCKET_FOLDER), as well as where the dataset originally resides (DATA_BUCKET_FOLDER).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>DATA_BUCKET_FOLDER = os.environ.get(&quot;INPUT_DATA_DIR&quot;, &quot;~/nvt-examples/outbrain/data&quot;)
OUTPUT_BUCKET_FOLDER = os.environ.get(&quot;OUTPUT_DATA_DIR&quot;, &quot;./outbrain-preprocessed/&quot;)
</pre></div>
</div>
</div>
</div>
<p>Let’s read our saved train and valid datasets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_filename = os.path.join(OUTPUT_BUCKET_FOLDER, &quot;train_gdf.parquet&quot;)
valid_filename = os.path.join(OUTPUT_BUCKET_FOLDER, &quot;valid_gdf.parquet&quot;)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="preparing-documents-metadata">
<h2>Preparing documents metadata<a class="headerlink" href="#preparing-documents-metadata" title="Permalink to this headline"></a></h2>
<p>Let’s create the output directories to store the preprocessed parquet files.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>output_train_dir = os.path.join(OUTPUT_BUCKET_FOLDER, &quot;train/&quot;)
output_valid_dir = os.path.join(OUTPUT_BUCKET_FOLDER, &quot;valid/&quot;)
! mkdir -p $output_train_dir
! mkdir -p $output_valid_dir
</pre></div>
</div>
</div>
</div>
<p>We read in three more cudf data frames, <i>documents categories</i>, <i>topics</i>, and <i>entities</i>, and use them to create sparse matrices in cupy. We will use these later to calculate cosine similarity between event document (landing page context) and ad document profile vectors (TF-IDF), i.e., how close in profile an ad is to the page that it is being displayed.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Alias for read_csv
read_csv = df_lib.read_csv

documents_categories_cudf = read_csv(DATA_BUCKET_FOLDER + &quot;documents_categories.csv&quot;)
documents_topics_cudf = read_csv(DATA_BUCKET_FOLDER + &quot;documents_topics.csv&quot;)
documents_entities_cudf = read_csv(DATA_BUCKET_FOLDER + &quot;documents_entities.csv&quot;)


# read in document categories/topics/entities as cupy sparse matrices
def df_to_coo(df, row=&quot;document_id&quot;, col=None, data=&quot;confidence_level&quot;):
    return cupy.sparse.coo_matrix((df[data].values, (df[row].values, df[col].values)))


categories = df_to_coo(documents_categories_cudf, col=&quot;category_id&quot;)
topics = df_to_coo(documents_topics_cudf, col=&quot;topic_id&quot;)
documents_entities_cudf[&quot;entity_id&quot;] = (
    documents_entities_cudf[&quot;entity_id&quot;].astype(&quot;category&quot;).cat.codes
)
entities = df_to_coo(documents_entities_cudf, col=&quot;entity_id&quot;)

documents_categories_cudf = documents_topics_cudf = documents_entities_cudf = None
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="initiate-nvtabular-workflow">
<h2>Initiate NVTabular Workflow<a class="headerlink" href="#initiate-nvtabular-workflow" title="Permalink to this headline"></a></h2>
<p>Now that our datasets, sparse matrices and udf are created, we can begin laying the groundwork for NVTabular. NVTabular requires input features to be defined as groups of columns , so we define our ColumnGroup features at this step. Note that feature engineering and preprocessing often happens to sets of columns, so we adopt that method and require the user to specify continuous and categoricals along with the target as lists within ColumnGroup.</p>
<p>At this point, our data still isn’t in a form that’s ideal for consumption by our W&amp;D model that we will train in the next notebook. There are missing values, and our categorical variables are still represented by random, discrete identifiers, and need to be transformed into contiguous indices for embedding lookups. The distributions of our continuous variables are uncentered. We also would like to create new features that will help to increase the model accuracy.</p>
<p>Let’s begin to create and process features using NVTabular ops:</p>
<ul class="simple">
<li><p><i>geo_location_state</i> and <i>geo_location_country</i> are created by stripping geo_location using the <code class="docutils literal notranslate"><span class="pre">LambdaOp</span></code></p></li>
<li><p><i>publish_time_days_since_published</i> and <i>publish_time_promo_days_since_published</i> features are created using the <code class="docutils literal notranslate"><span class="pre">calculate_delta</span></code> function in a <code class="docutils literal notranslate"><span class="pre">LambdaOp</span></code></p></li>
<li><p>Missing values are filled using median value depending on the feature using <code class="docutils literal notranslate"><span class="pre">FillMedian()</span></code>op</p></li>
<li><p>Continuous features are log transformed with the <code class="docutils literal notranslate"><span class="pre">LogOp()</span></code>.</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">Categorify</span></code> op is used for categorification, i.e. encoding of categorical features. Categorify op takes a param called <code class="docutils literal notranslate"><span class="pre">freq_threshold</span></code> which is used for frequency capping. This handy functionality will map all categories which occur in the dataset with some threshold level of infrequency to the <em>same</em> index, keeping the model from overfitting to sparse signals. We don’t apply  frequency thresholds in this example, but one can easily create a frequency threshold dictionary, assign a custom threshold value for each categorical feature, and feed that dictionary into the <code class="docutils literal notranslate"><span class="pre">Categorify</span></code> op as <code class="docutils literal notranslate"><span class="pre">freq_threshold</span></code> param.</p>
<p>One of the important part of building recommender systems is to do feature engineering. As a very promising feature engineering technique, <code class="docutils literal notranslate"><span class="pre">Target</span> <span class="pre">Encoding</span></code> processes the categorical features and makes them easier accessible to the model during training and validation. <em>Target Encoding (TE)</em> has emerged as being both effective and efficient in many data science projects. For example, it is the major component of Nvidia Kaggle Grandmasters team’s <a class="reference external" href="https://medium.com/rapids-ai/winning-solution-of-recsys2020-challenge-gpu-accelerated-feature-engineering-and-training-for-cd67c5a87b1f">winning solution</a> of <a class="reference external" href="http://www.recsyschallenge.com/2020/">Recsys Challenge 2020</a>. TE calculates the statistics from a target variable grouped by the unique values of one or more categorical features. For example in a binary classification problem, it calculates the probability that the target is true for each category value - a simple mean. In other words, for each distinct element in feature <b>$x$</b> we are going to compute the average of the corresponding values in target <i>y</i>. Then we are going to replace each $x_{i}$ with the corresponding mean value. For more details on TargetEncoding please visit <a class="reference external" href="https://medium.com/rapids-ai/target-encoding-with-rapids-cuml-do-more-with-your-categorical-data-8c762c79e784">here</a> and <a class="reference external" href="https://github.com/rapidsai/deeplearning/blob/main/RecSys2020Tutorial/03_3_TargetEncoding.ipynb">here</a>.</p>
<p>Here, we apply Target Encoding to certain categorical features with <em>kfold</em> of 5 and <em>smoothing</em> of 20 to avoid overfitting using <a class="reference external" href="https://github.com/NVIDIA/NVTabular/blob/a0141d0a710698470160bc2cbc42b18ce2d49133/nvtabular/ops/target_encoding.py">TargetEncoding op</a>.</p>
</div>
<div class="section" id="feature-engineering">
<h2>Feature Engineering<a class="headerlink" href="#feature-engineering" title="Permalink to this headline"></a></h2>
<p>Below, we create a custom operator that calculates the time difference between a specified time column (either publish_time or publish_time_promo) and timestamp. This is used to calculate <i>time elapsed since publication</i> between the landing page and the ad.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># To save disk space, the timestamps in the entire dataset are relative to the first time in the dataset.
# To recover the actual epoch time of the visit, we add 1465876799998 to the timestamp.
TIMESTAMP_DELTA = 1465876799998

from nvtabular.ops import Operator


class DaysSincePublished(Operator):
    def transform(self, columns, gdf):
        for column in columns.names:
            col = gdf[column]
            col.loc[col == &quot;&quot;] = None
            col = col.astype(&quot;datetime64[ns]&quot;)
            timestamp = (gdf[&quot;timestamp&quot;] + TIMESTAMP_DELTA).astype(&quot;datetime64[ms]&quot;)
            delta = (timestamp - col).dt.days
            gdf[column + &quot;_since_published&quot;] = delta * (delta &gt;= 0) * (delta &lt;= 10 * 365)
        return gdf

    def output_column_names(self, columns):
        return nvt.ColumnSelector([column + &quot;_since_published&quot; for column in columns.names])

    @property
    def dependencies(self):
        return [&quot;timestamp&quot;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># geo processing: apply two different lambda operators to the ‘geo_location’ column, and
# extract the country/state from the geo_location value. The geo_location column
# looks something like &quot;US&gt;CA&gt;12345&quot;, so we&#39;re using string slicing to pull out the country
# and the country+state then
geo_location = ColumnGroup([&quot;geo_location&quot;])
country = geo_location &gt;&gt; (lambda col: col.str.slice(0, 2)) &gt;&gt; Rename(postfix=&quot;_country&quot;)
state = geo_location &gt;&gt; (lambda col: col.str.slice(0, 5)) &gt;&gt; Rename(postfix=&quot;_state&quot;)
geo_features = geo_location + country + state

# categoricals processing: categorify certain input columns as well as the geo features
cats = ColumnGroup(
    [
        &quot;ad_id&quot;,
        &quot;document_id&quot;,
        &quot;platform&quot;,
        &quot;document_id_promo&quot;,
        &quot;campaign_id&quot;,
        &quot;advertiser_id&quot;,
        &quot;source_id&quot;,
        &quot;publisher_id&quot;,
        &quot;source_id_promo&quot;,
        &quot;publisher_id_promo&quot;,
    ]
)
cat_features = geo_features + cats &gt;&gt; Categorify()

# Apply TargetEncoding to certain categoricals with kfold of 5 and smoothing of 20
te_features = cats &gt;&gt; TargetEncoding(&quot;clicked&quot;, kfold=5, p_smooth=20)

# process dates using the ‘DaysSincePublished’ custom operator
dates = [&quot;publish_time&quot;, &quot;publish_time_promo&quot;]
date_features = dates &gt;&gt; DaysSincePublished() &gt;&gt; FillMedian() &gt;&gt; LogOp()
</pre></div>
</div>
</div>
</div>
<p>Let’s visualize our calculation graph with the column groups we used and created so far.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>features = date_features + cat_features + te_features + &quot;clicked&quot;
features.graph
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/e0ab3e17d3556a62cf52a40aafabf532fc98be0a9b2463c14a11dbd491e21ea6.svg" src="../../_images/e0ab3e17d3556a62cf52a40aafabf532fc98be0a9b2463c14a11dbd491e21ea6.svg" /></div>
</div>
<p>A user might sometimes be interested to continue reading about the same topics of the current page. Computing the similarity between the textual content of the current page and the pages linked to the displayed ads, can be a relevant feature for a model that predicts which ad the user would click next. A simple, yet effective way to compute the similarity between documents is generating the TF-IDF vectors for each of them, which captures their most relevant terms, and then computing the cosine similarity between those vectors.</p>
<p>Below, we calculate <i>doc_event_doc_ad_sim_categories</i>, <i>topics</i>, and <i>entities</i> using the <code class="docutils literal notranslate"><span class="pre">ColumnSimilarity</span></code> op, which utilizes the sparse categories, topics, and entities matrices that were created above to calculate landing page similarity for categories, topics, and entities. We calculate Cosine similarity between event doc (landing page) and ad doc aspects vectors (TF-IDF). Creating these extra features help to improve model accuracy and predictability.</p>
<p>Note that we rename the column names to avoid duplicated column names.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>sim_features_categ = (
    [[&quot;document_id&quot;, &quot;document_id_promo&quot;]]
    &gt;&gt; ColumnSimilarity(categories, metric=&quot;tfidf&quot;, on_device=False)
    &gt;&gt; Rename(postfix=&quot;_categories&quot;)
)
sim_features_topics = (
    [[&quot;document_id&quot;, &quot;document_id_promo&quot;]]
    &gt;&gt; ColumnSimilarity(topics, metric=&quot;tfidf&quot;, on_device=False)
    &gt;&gt; Rename(postfix=&quot;_topics&quot;)
)
sim_features_entities = (
    [[&quot;document_id&quot;, &quot;document_id_promo&quot;]]
    &gt;&gt; ColumnSimilarity(entities, metric=&quot;tfidf&quot;, on_device=False)
    &gt;&gt; Rename(postfix=&quot;_entities&quot;)
)
sim_features = sim_features_categ + sim_features_topics + sim_features_entities
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># The workflow is created with the output node of the graph
workflow = nvt.Workflow(features + sim_features)
</pre></div>
</div>
</div>
</div>
<p>We then create an NVTabular Dataset object both for train and validation sets. We calculate statistics for this workflow on the input dataset, i.e. on our training set, using the <code class="docutils literal notranslate"><span class="pre">workflow.fit()</span></code> method so that our <i>Workflow</i> can use these stats to transform any given input. When our <i>Workflow</i> transforms our datasets and, we also save the results out to parquet files for fast reading at train time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>train_dataset = nvt.Dataset(train_filename)
valid_dataset = nvt.Dataset(valid_filename)

# Calculate statistics on the training set
workflow.fit(train_dataset)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.8/dist-packages/numba/cuda/compiler.py:865: NumbaPerformanceWarning: Grid size (1) &lt; 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.
  warn(NumbaPerformanceWarning(msg))
/usr/local/lib/python3.8/dist-packages/numba/cuda/compiler.py:865: NumbaPerformanceWarning: Grid size (1) &lt; 2 * SM count (112) will likely result in GPU under utilization due to low occupancy.
  warn(NumbaPerformanceWarning(msg))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># use the calculated statistics to transform the train/valid datasets
# and write out each as parquet
workflow.transform(train_dataset).to_parquet(
    output_path=output_train_dir, shuffle=Shuffle.PER_PARTITION, out_files_per_proc=5
)
workflow.transform(valid_dataset).to_parquet(output_path=output_valid_dir)
</pre></div>
</div>
</div>
</div>
<p>We can save the stats from the workflow and load it anytime, so we can run training without doing preprocessing.</p>
<p>In the next notebooks, we will train a deep learning model. Our training pipeline requires information about the data schema to define the neural network architecture. We will save the NVTabular workflow to disk so that we can restore it in the next notebooks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>workflow.save(os.path.join(OUTPUT_BUCKET_FOLDER, &quot;workflow&quot;))
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="reviewing-processed-data">
<h2>Reviewing processed data<a class="headerlink" href="#reviewing-processed-data" title="Permalink to this headline"></a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>TRAIN_PATHS = sorted(glob.glob(os.path.join(OUTPUT_BUCKET_FOLDER, &quot;train/*.parquet&quot;)))
VALID_PATHS = sorted(glob.glob(os.path.join(OUTPUT_BUCKET_FOLDER, &quot;valid/*.parquet&quot;)))
TRAIN_PATHS, VALID_PATHS
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>df = df_lib.read_parquet(TRAIN_PATHS[0])
df.head()
</pre></div>
</div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="01-Download-Convert.html" class="btn btn-neutral float-left" title="Getting Started Outbrain: Download and Convert" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="03-Training-with-TF.html" class="btn btn-neutral float-right" title="NVTabular demo on Outbrain Data" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: v1.5.0
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../../v1.3.2/index.html">v1.3.2</a></dd>
      <dd><a href="../../../v1.3.3/index.html">v1.3.3</a></dd>
      <dd><a href="../../../v1.4.0/index.html">v1.4.0</a></dd>
      <dd><a href="02-ETL-with-NVTabular.html">v1.5.0</a></dd>
      <dd><a href="../../../v1.6.0/index.html">v1.6.0</a></dd>
      <dd><a href="../../../v1.7.0/index.html">v1.7.0</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../../../main/index.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NVJ1Y1YJHK', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>