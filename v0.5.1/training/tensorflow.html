<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Accelerated Training with TensorFlow &mdash; NVTabular 2021 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Accelerated Training with PyTorch" href="pytorch.html" />
    <link rel="prev" title="Accelerated Training" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> NVTabular
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../Introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../core_features.html">Core Features</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Accelerated Training</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">TensorFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="pytorch.html">PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="hugectr.html">HugeCTR</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../resources/index.html">Additional Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">NVTabular</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Accelerated Training</a> &raquo;</li>
      <li>Accelerated Training with TensorFlow</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="accelerated-training-with-tensorflow">
<h1>Accelerated Training with TensorFlow<a class="headerlink" href="#accelerated-training-with-tensorflow" title="Permalink to this headline"></a></h1>
<p>When training pipelines with TensorFlow, the dataloader cannot prepare
sequential batches fast enough, so the GPU is not fully utilized. To
combat this issue, we’ve developed a highly customized tabular
dataloader, <code class="docutils literal notranslate"><span class="pre">KerasSequenceLoader</span></code>, to accelerate existing pipelines in
TensorFlow. In our experiments, we were able to achieve a speed-up 9
times as fast as the same training workflow that contains a NVTabular
dataloader. The NVTabular dataloader is capable of:</p>
<ul class="simple">
<li><p>removing bottlenecks from dataloading by processing large chunks of
data at a time instead of item by item</p></li>
<li><p>processing datasets that don’t fit within the GPU or CPU memory by
streaming from the disk</p></li>
<li><p>reading data directly into the GPU memory and removing CPU-GPU
communication</p></li>
<li><p>preparing batch asynchronously into the GPU to avoid CPU-GPU
communication</p></li>
<li><p>supporting commonly used formats such as parquet</p></li>
<li><p>integrating easily into existing TensorFlow training pipelines by
using a similar API as the native TensorFlow dataloader since it
works with tf.keras models</p></li>
</ul>
<p>When <code class="docutils literal notranslate"><span class="pre">KerasSequenceLoader</span></code> accelerates training with TensorFlow, the
following happens:</p>
<ol class="arabic simple">
<li><p>The required libraries are imported. The dataloader loads and
prepares batches directly in the GPU and requires some of the GPU
memory. Before initializing TensorFlow, the amount of memory that is
allocated to TensorFlow needs to be controlled as well as the
remaining memory allocation that is allocated to the dataloader. The
environment variable ‘TF_MEMORY_ALLOCATION’ can be used to control
the TensorFlow memory allocation.</p></li>
</ol>
<p>```python import tensorflow as tf</p>
<p># Control how much memory to give TensorFlow with this environment
variable # IMPORTANT: Do this before you initialize the TensorFlow
runtime, otherwise # it’s too late and TensorFlow will claim all free
GPU memory os.environ[‘TF_MEMORY_ALLOCATION’] = “8192” # explicit MB
os.environ[‘TF_MEMORY_ALLOCATION’] = “0.5” # fraction of free memory
from nvtabular.loader.tensorflow import KerasSequenceLoader,
KerasSequenceValidater ```</p>
<ol class="arabic simple" start="2">
<li><p>The data schema is defined with <code class="docutils literal notranslate"><span class="pre">tf.feature_columns</span></code>, the
categorical input features (<code class="docutils literal notranslate"><span class="pre">CATEGORICAL_COLUMNS</span></code>) are fed through
an embedding layer, and the continuous input (<code class="docutils literal notranslate"><span class="pre">CONTINUOUS_COLUMNS</span></code>)
features are defined with <code class="docutils literal notranslate"><span class="pre">numeric_column</span></code>. The
<code class="docutils literal notranslate"><span class="pre">EMBEDDING_TABLE_SHAPES</span></code> is a dictionary that contains cardinality
and emb_size tuples for each categorical feature.</p></li>
</ol>
<p>```python def make_categorical_embedding_column(name,
dictionary_size, embedding_dim): return
tf.feature_column.embedding_column(
tf.feature_column.categorical_column_with_identity(name,
dictionary_size), embedding_dim )</p>
<p># instantiate the columns categorical_columns = [
make_categorical_embedding_column(name,*EMBEDDING_TABLE_SHAPES[name])
for name in CATEGORICAL_COLUMNS ] continuous_columns = [
tf.feature_column.numeric_column(name, (1,)) for name in
CONTINUOUS_COLUMNS ] ```</p>
<ol class="arabic simple" start="3">
<li><p>The NVTabular dataloader is initialized. The NVTabular dataloader
supports a list of filenames and glob pattern as input, which it will
load and iterate over. <code class="docutils literal notranslate"><span class="pre">feature_columns</span></code> defines the data
structure, which uses the <code class="docutils literal notranslate"><span class="pre">tf.feature_column</span></code> structure that was
previously defined. The<code class="docutils literal notranslate"><span class="pre">batch_size</span></code>, <code class="docutils literal notranslate"><span class="pre">label_names</span></code> (target
columns), <code class="docutils literal notranslate"><span class="pre">shuffle</span></code>, and <code class="docutils literal notranslate"><span class="pre">buffer_size</span></code> are defined.</p></li>
</ol>
<p><code class="docutils literal notranslate"><span class="pre">python</span>&#160;&#160;&#160; <span class="pre">TRAIN_PATHS</span> <span class="pre">=</span> <span class="pre">glob.glob(‘./train/*.parquet’)</span>&#160;&#160;&#160; <span class="pre">train_dataset_tf</span> <span class="pre">=</span> <span class="pre">KerasSequenceLoader(</span>&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">TRAIN_PATHS,</span> <span class="pre">#</span> <span class="pre">you</span> <span class="pre">could</span> <span class="pre">also</span> <span class="pre">use</span> <span class="pre">a</span> <span class="pre">glob</span> <span class="pre">pattern</span>&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">feature_columns=categorical_columns+continuous_columns,</span>&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">batch_size=BATCH_SIZE,</span>&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">label_names=LABEL_COLUMNS,</span>&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">shuffle=True,</span>&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">buffer_size=0.06</span> <span class="pre">#</span> <span class="pre">amount</span> <span class="pre">of</span> <span class="pre">data,</span> <span class="pre">as</span> <span class="pre">a</span> <span class="pre">fraction</span> <span class="pre">of</span> <span class="pre">GPU</span> <span class="pre">memory,</span> <span class="pre">to</span> <span class="pre">load</span> <span class="pre">at</span> <span class="pre">one</span> <span class="pre">time</span>&#160;&#160;&#160; <span class="pre">)</span></code></p>
<ol class="arabic simple" start="4">
<li><p>The TensorFlow Keras model ( <code class="docutils literal notranslate"><span class="pre">tf.keras.Model</span></code>) is defined if a
neural network architecture is created in which <code class="docutils literal notranslate"><span class="pre">inputs</span></code> are the
input tensors and <code class="docutils literal notranslate"><span class="pre">output</span></code> is the output tensors.</p></li>
</ol>
<p><code class="docutils literal notranslate"><span class="pre">python</span>&#160;&#160;&#160; <span class="pre">...</span>&#160;&#160;&#160; <span class="pre">model</span> <span class="pre">=</span> <span class="pre">tf.keras.Model(inputs=inputs,</span> <span class="pre">outputs=output)</span>&#160;&#160;&#160; <span class="pre">model.compile('sgd',</span> <span class="pre">'binary_crossentropy')</span></code></p>
<ol class="arabic simple" start="5">
<li><p>The model is trained with <code class="docutils literal notranslate"><span class="pre">model.fit</span></code> using the NVTabular
dataloader.</p></li>
</ol>
<p><code class="docutils literal notranslate"><span class="pre">python</span>&#160;&#160;&#160; <span class="pre">...</span>&#160;&#160;&#160; <span class="pre">)</span>&#160;&#160;&#160; <span class="pre">history</span> <span class="pre">=</span> <span class="pre">model.fit(train_dataset_tf,</span> <span class="pre">epochs=5)</span></code></p>
<p><strong>Note</strong>: If using the NVTabular dataloader for the validation dataset,
a callback can be used for it.</p>
<p><code class="docutils literal notranslate"><span class="pre">python</span>&#160;&#160;&#160; <span class="pre">...</span>&#160;&#160;&#160; <span class="pre">valid_dataset_tf</span> <span class="pre">=</span> <span class="pre">KerasSequenceLoader(...)</span>&#160;&#160;&#160; <span class="pre">validation_callback</span> <span class="pre">=</span> <span class="pre">KerasSequenceValidater(valid_dataset_tf)</span>&#160;&#160;&#160; <span class="pre">history</span> <span class="pre">=</span> <span class="pre">model.fit(train_dataset_tf,</span> <span class="pre">callbacks=[validation_callback],</span> <span class="pre">epochs=5)</span></code></p>
<p>You can find additional examples in our repository such as
<a class="reference external" href="../examples/getting-started-movielens/">MovieLens</a> and
<a class="reference external" href="../examples/advanced-ops-outbrain/">Outbrain</a>.</p>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Accelerated Training" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="pytorch.html" class="btn btn-neutral float-right" title="Accelerated Training with PyTorch" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: v0.5.1
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../v0.1.0/index.html">v0.1.0</a></dd>
      <dd><a href="../../v0.1.1/index.html">v0.1.1</a></dd>
      <dd><a href="../../v0.10.0/training/tensorflow.html">v0.10.0</a></dd>
      <dd><a href="../../v0.11.0/training/tensorflow.html">v0.11.0</a></dd>
      <dd><a href="../../v0.2.0/index.html">v0.2.0</a></dd>
      <dd><a href="../../v0.3.0/index.html">v0.3.0</a></dd>
      <dd><a href="../../v0.4.0/training/tensorflow.html">v0.4.0</a></dd>
      <dd><a href="../../v0.5.0/training/tensorflow.html">v0.5.0</a></dd>
      <dd><a href="tensorflow.html">v0.5.1</a></dd>
      <dd><a href="../../v0.5.2/training/tensorflow.html">v0.5.2</a></dd>
      <dd><a href="../../v0.5.3/training/tensorflow.html">v0.5.3</a></dd>
      <dd><a href="../../v0.6.0/training/tensorflow.html">v0.6.0</a></dd>
      <dd><a href="../../v0.6.1/training/tensorflow.html">v0.6.1</a></dd>
      <dd><a href="../../v0.7.0/training/tensorflow.html">v0.7.0</a></dd>
      <dd><a href="../../v0.7.1/training/tensorflow.html">v0.7.1</a></dd>
      <dd><a href="../../v0.8.0/training/tensorflow.html">v0.8.0</a></dd>
      <dd><a href="../../v0.9.0/training/tensorflow.html">v0.9.0</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../../main/training/tensorflow.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>