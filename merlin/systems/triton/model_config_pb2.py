# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: model_config.proto

import sys

_b = sys.version_info[0] < 3 and (lambda x: x) or (lambda x: x.encode("latin1"))
from google.protobuf.internal import enum_type_wrapper
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database

# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


DESCRIPTOR = _descriptor.FileDescriptor(
    name="model_config.proto",
    package="inference",
    syntax="proto3",
    serialized_options=None,
    serialized_pb=_b(
        '\n\x12model_config.proto\x12\tinference"\x96\x01\n\x10ModelRateLimiter\x12\x37\n\tresources\x18\x01 \x03(\x0b\x32$.inference.ModelRateLimiter.Resource\x12\x10\n\x08priority\x18\x02 \x01(\r\x1a\x37\n\x08Resource\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0e\n\x06global\x18\x02 \x01(\x08\x12\r\n\x05\x63ount\x18\x03 \x01(\r"\xf8\x01\n\x12ModelInstanceGroup\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x30\n\x04kind\x18\x04 \x01(\x0e\x32".inference.ModelInstanceGroup.Kind\x12\r\n\x05\x63ount\x18\x02 \x01(\x05\x12\x31\n\x0crate_limiter\x18\x06 \x01(\x0b\x32\x1b.inference.ModelRateLimiter\x12\x0c\n\x04gpus\x18\x03 \x03(\x05\x12\x0f\n\x07profile\x18\x05 \x03(\t"A\n\x04Kind\x12\r\n\tKIND_AUTO\x10\x00\x12\x0c\n\x08KIND_GPU\x10\x01\x12\x0c\n\x08KIND_CPU\x10\x02\x12\x0e\n\nKIND_MODEL\x10\x03"#\n\x12ModelTensorReshape\x12\r\n\x05shape\x18\x01 \x03(\x03"\xa0\x02\n\nModelInput\x12\x0c\n\x04name\x18\x01 \x01(\t\x12&\n\tdata_type\x18\x02 \x01(\x0e\x32\x13.inference.DataType\x12,\n\x06\x66ormat\x18\x03 \x01(\x0e\x32\x1c.inference.ModelInput.Format\x12\x0c\n\x04\x64ims\x18\x04 \x03(\x03\x12.\n\x07reshape\x18\x05 \x01(\x0b\x32\x1d.inference.ModelTensorReshape\x12\x17\n\x0fis_shape_tensor\x18\x06 \x01(\x08\x12\x1a\n\x12\x61llow_ragged_batch\x18\x07 \x01(\x08";\n\x06\x46ormat\x12\x0f\n\x0b\x46ORMAT_NONE\x10\x00\x12\x0f\n\x0b\x46ORMAT_NHWC\x10\x01\x12\x0f\n\x0b\x46ORMAT_NCHW\x10\x02"\xb2\x01\n\x0bModelOutput\x12\x0c\n\x04name\x18\x01 \x01(\t\x12&\n\tdata_type\x18\x02 \x01(\x0e\x32\x13.inference.DataType\x12\x0c\n\x04\x64ims\x18\x03 \x03(\x03\x12.\n\x07reshape\x18\x05 \x01(\x0b\x32\x1d.inference.ModelTensorReshape\x12\x16\n\x0elabel_filename\x18\x04 \x01(\t\x12\x17\n\x0fis_shape_tensor\x18\x06 \x01(\x08"\xa5\x02\n\nBatchInput\x12(\n\x04kind\x18\x01 \x01(\x0e\x32\x1a.inference.BatchInput.Kind\x12\x13\n\x0btarget_name\x18\x02 \x03(\t\x12&\n\tdata_type\x18\x03 \x01(\x0e\x32\x13.inference.DataType\x12\x14\n\x0csource_input\x18\x04 \x03(\t"\x99\x01\n\x04Kind\x12\x17\n\x13\x42\x41TCH_ELEMENT_COUNT\x10\x00\x12#\n\x1f\x42\x41TCH_ACCUMULATED_ELEMENT_COUNT\x10\x01\x12-\n)BATCH_ACCUMULATED_ELEMENT_COUNT_WITH_ZERO\x10\x02\x12$\n BATCH_MAX_ELEMENT_COUNT_AS_SHAPE\x10\x03"\x8f\x01\n\x0b\x42\x61tchOutput\x12\x13\n\x0btarget_name\x18\x01 \x03(\t\x12)\n\x04kind\x18\x02 \x01(\x0e\x32\x1b.inference.BatchOutput.Kind\x12\x14\n\x0csource_input\x18\x03 \x03(\t"*\n\x04Kind\x12"\n\x1e\x42\x41TCH_SCATTER_WITH_INPUT_SHAPE\x10\x00"\x90\x02\n\x12ModelVersionPolicy\x12\x36\n\x06latest\x18\x01 \x01(\x0b\x32$.inference.ModelVersionPolicy.LatestH\x00\x12\x30\n\x03\x61ll\x18\x02 \x01(\x0b\x32!.inference.ModelVersionPolicy.AllH\x00\x12:\n\x08specific\x18\x03 \x01(\x0b\x32&.inference.ModelVersionPolicy.SpecificH\x00\x1a\x1e\n\x06Latest\x12\x14\n\x0cnum_versions\x18\x01 \x01(\r\x1a\x05\n\x03\x41ll\x1a\x1c\n\x08Specific\x12\x10\n\x08versions\x18\x01 \x03(\x03\x42\x0f\n\rpolicy_choice"\xa1\r\n\x17ModelOptimizationPolicy\x12\x37\n\x05graph\x18\x01 \x01(\x0b\x32(.inference.ModelOptimizationPolicy.Graph\x12\x42\n\x08priority\x18\x02 \x01(\x0e\x32\x30.inference.ModelOptimizationPolicy.ModelPriority\x12\x35\n\x04\x63uda\x18\x03 \x01(\x0b\x32\'.inference.ModelOptimizationPolicy.Cuda\x12X\n\x16\x65xecution_accelerators\x18\x04 \x01(\x0b\x32\x38.inference.ModelOptimizationPolicy.ExecutionAccelerators\x12R\n\x13input_pinned_memory\x18\x05 \x01(\x0b\x32\x35.inference.ModelOptimizationPolicy.PinnedMemoryBuffer\x12S\n\x14output_pinned_memory\x18\x06 \x01(\x0b\x32\x35.inference.ModelOptimizationPolicy.PinnedMemoryBuffer\x1a\x16\n\x05Graph\x12\r\n\x05level\x18\x01 \x01(\x05\x1a\x9e\x05\n\x04\x43uda\x12\x0e\n\x06graphs\x18\x01 \x01(\x08\x12\x18\n\x10\x62usy_wait_events\x18\x02 \x01(\x08\x12\x45\n\ngraph_spec\x18\x03 \x03(\x0b\x32\x31.inference.ModelOptimizationPolicy.Cuda.GraphSpec\x1a\xa4\x04\n\tGraphSpec\x12\x12\n\nbatch_size\x18\x01 \x01(\x05\x12K\n\x05input\x18\x02 \x03(\x0b\x32<.inference.ModelOptimizationPolicy.Cuda.GraphSpec.InputEntry\x12W\n\x11graph_lower_bound\x18\x03 \x01(\x0b\x32<.inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound\x1a\x14\n\x05Shape\x12\x0b\n\x03\x64im\x18\x01 \x03(\x03\x1a\xdf\x01\n\nLowerBound\x12\x12\n\nbatch_size\x18\x01 \x01(\x05\x12V\n\x05input\x18\x02 \x03(\x0b\x32G.inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound.InputEntry\x1a\x65\n\nInputEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x46\n\x05value\x18\x02 \x01(\x0b\x32\x37.inference.ModelOptimizationPolicy.Cuda.GraphSpec.Shape:\x02\x38\x01\x1a\x65\n\nInputEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x46\n\x05value\x18\x02 \x01(\x0b\x32\x37.inference.ModelOptimizationPolicy.Cuda.GraphSpec.Shape:\x02\x38\x01\x1a\xa4\x03\n\x15\x45xecutionAccelerators\x12g\n\x19gpu_execution_accelerator\x18\x01 \x03(\x0b\x32\x44.inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator\x12g\n\x19\x63pu_execution_accelerator\x18\x02 \x03(\x0b\x32\x44.inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator\x1a\xb8\x01\n\x0b\x41\x63\x63\x65lerator\x12\x0c\n\x04name\x18\x01 \x01(\t\x12h\n\nparameters\x18\x02 \x03(\x0b\x32T.inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.ParametersEntry\x1a\x31\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a$\n\x12PinnedMemoryBuffer\x12\x0e\n\x06\x65nable\x18\x01 \x01(\x08"I\n\rModelPriority\x12\x14\n\x10PRIORITY_DEFAULT\x10\x00\x12\x10\n\x0cPRIORITY_MAX\x10\x01\x12\x10\n\x0cPRIORITY_MIN\x10\x02"\xdb\x01\n\x10ModelQueuePolicy\x12\x41\n\x0etimeout_action\x18\x01 \x01(\x0e\x32).inference.ModelQueuePolicy.TimeoutAction\x12$\n\x1c\x64\x65\x66\x61ult_timeout_microseconds\x18\x02 \x01(\x04\x12\x1e\n\x16\x61llow_timeout_override\x18\x03 \x01(\x08\x12\x16\n\x0emax_queue_size\x18\x04 \x01(\r"&\n\rTimeoutAction\x12\n\n\x06REJECT\x10\x00\x12\t\n\x05\x44\x45LAY\x10\x01"\x9b\x03\n\x14ModelDynamicBatching\x12\x1c\n\x14preferred_batch_size\x18\x01 \x03(\x05\x12$\n\x1cmax_queue_delay_microseconds\x18\x02 \x01(\x04\x12\x19\n\x11preserve_ordering\x18\x03 \x01(\x08\x12\x17\n\x0fpriority_levels\x18\x04 \x01(\r\x12\x1e\n\x16\x64\x65\x66\x61ult_priority_level\x18\x05 \x01(\r\x12\x39\n\x14\x64\x65\x66\x61ult_queue_policy\x18\x06 \x01(\x0b\x32\x1b.inference.ModelQueuePolicy\x12W\n\x15priority_queue_policy\x18\x07 \x03(\x0b\x32\x38.inference.ModelDynamicBatching.PriorityQueuePolicyEntry\x1aW\n\x18PriorityQueuePolicyEntry\x12\x0b\n\x03key\x18\x01 \x01(\r\x12*\n\x05value\x18\x02 \x01(\x0b\x32\x1b.inference.ModelQueuePolicy:\x02\x38\x01"\xe3\x06\n\x15ModelSequenceBatching\x12\x41\n\x06\x64irect\x18\x03 \x01(\x0b\x32/.inference.ModelSequenceBatching.StrategyDirectH\x00\x12\x41\n\x06oldest\x18\x04 \x01(\x0b\x32/.inference.ModelSequenceBatching.StrategyOldestH\x00\x12&\n\x1emax_sequence_idle_microseconds\x18\x01 \x01(\x04\x12\x44\n\rcontrol_input\x18\x02 \x03(\x0b\x32-.inference.ModelSequenceBatching.ControlInput\x1a\x98\x02\n\x07\x43ontrol\x12;\n\x04kind\x18\x01 \x01(\x0e\x32-.inference.ModelSequenceBatching.Control.Kind\x12\x18\n\x10int32_false_true\x18\x02 \x03(\x05\x12\x17\n\x0f\x66p32_false_true\x18\x03 \x03(\x02\x12&\n\tdata_type\x18\x04 \x01(\x0e\x32\x13.inference.DataType"u\n\x04Kind\x12\x1a\n\x16\x43ONTROL_SEQUENCE_START\x10\x00\x12\x1a\n\x16\x43ONTROL_SEQUENCE_READY\x10\x01\x12\x18\n\x14\x43ONTROL_SEQUENCE_END\x10\x02\x12\x1b\n\x17\x43ONTROL_SEQUENCE_CORRID\x10\x03\x1aW\n\x0c\x43ontrolInput\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x39\n\x07\x63ontrol\x18\x02 \x03(\x0b\x32(.inference.ModelSequenceBatching.Control\x1aX\n\x0eStrategyDirect\x12$\n\x1cmax_queue_delay_microseconds\x18\x01 \x01(\x04\x12 \n\x18minimum_slot_utilization\x18\x02 \x01(\x02\x1au\n\x0eStrategyOldest\x12\x1f\n\x17max_candidate_sequences\x18\x01 \x01(\x05\x12\x1c\n\x14preferred_batch_size\x18\x02 \x03(\x05\x12$\n\x1cmax_queue_delay_microseconds\x18\x03 \x01(\x04\x42\x11\n\x0fstrategy_choice"\xdd\x02\n\x0fModelEnsembling\x12-\n\x04step\x18\x01 \x03(\x0b\x32\x1f.inference.ModelEnsembling.Step\x1a\x9a\x02\n\x04Step\x12\x12\n\nmodel_name\x18\x01 \x01(\t\x12\x15\n\rmodel_version\x18\x02 \x01(\x03\x12@\n\tinput_map\x18\x03 \x03(\x0b\x32-.inference.ModelEnsembling.Step.InputMapEntry\x12\x42\n\noutput_map\x18\x04 \x03(\x0b\x32..inference.ModelEnsembling.Step.OutputMapEntry\x1a/\n\rInputMapEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x30\n\x0eOutputMapEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"&\n\x0eModelParameter\x12\x14\n\x0cstring_value\x18\x01 \x01(\t"\xca\x02\n\x0bModelWarmup\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x12\n\nbatch_size\x18\x02 \x01(\r\x12\x32\n\x06inputs\x18\x03 \x03(\x0b\x32".inference.ModelWarmup.InputsEntry\x1a\x97\x01\n\x05Input\x12&\n\tdata_type\x18\x01 \x01(\x0e\x32\x13.inference.DataType\x12\x0c\n\x04\x64ims\x18\x02 \x03(\x03\x12\x13\n\tzero_data\x18\x03 \x01(\x08H\x00\x12\x15\n\x0brandom_data\x18\x04 \x01(\x08H\x00\x12\x19\n\x0finput_data_file\x18\x05 \x01(\tH\x00\x42\x11\n\x0finput_data_type\x1aK\n\x0bInputsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12+\n\x05value\x18\x02 \x01(\x0b\x32\x1c.inference.ModelWarmup.Input:\x02\x38\x01".\n\x0fModelOperations\x12\x1b\n\x13op_library_filename\x18\x01 \x03(\t"+\n\x16ModelTransactionPolicy\x12\x11\n\tdecoupled\x18\x01 \x01(\x08"\xb8\t\n\x0bModelConfig\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x10\n\x08platform\x18\x02 \x01(\t\x12\x0f\n\x07\x62\x61\x63kend\x18\x11 \x01(\t\x12\x35\n\x0eversion_policy\x18\x03 \x01(\x0b\x32\x1d.inference.ModelVersionPolicy\x12\x16\n\x0emax_batch_size\x18\x04 \x01(\x05\x12$\n\x05input\x18\x05 \x03(\x0b\x32\x15.inference.ModelInput\x12&\n\x06output\x18\x06 \x03(\x0b\x32\x16.inference.ModelOutput\x12*\n\x0b\x62\x61tch_input\x18\x14 \x03(\x0b\x32\x15.inference.BatchInput\x12,\n\x0c\x62\x61tch_output\x18\x15 \x03(\x0b\x32\x16.inference.BatchOutput\x12\x38\n\x0coptimization\x18\x0c \x01(\x0b\x32".inference.ModelOptimizationPolicy\x12;\n\x10\x64ynamic_batching\x18\x0b \x01(\x0b\x32\x1f.inference.ModelDynamicBatchingH\x00\x12=\n\x11sequence_batching\x18\r \x01(\x0b\x32 .inference.ModelSequenceBatchingH\x00\x12\x39\n\x13\x65nsemble_scheduling\x18\x0f \x01(\x0b\x32\x1a.inference.ModelEnsemblingH\x00\x12\x35\n\x0einstance_group\x18\x07 \x03(\x0b\x32\x1d.inference.ModelInstanceGroup\x12\x1e\n\x16\x64\x65\x66\x61ult_model_filename\x18\x08 \x01(\t\x12H\n\x12\x63\x63_model_filenames\x18\t \x03(\x0b\x32,.inference.ModelConfig.CcModelFilenamesEntry\x12;\n\x0bmetric_tags\x18\n \x03(\x0b\x32&.inference.ModelConfig.MetricTagsEntry\x12:\n\nparameters\x18\x0e \x03(\x0b\x32&.inference.ModelConfig.ParametersEntry\x12,\n\x0cmodel_warmup\x18\x10 \x03(\x0b\x32\x16.inference.ModelWarmup\x12\x34\n\x10model_operations\x18\x12 \x01(\x0b\x32\x1a.inference.ModelOperations\x12\x43\n\x18model_transaction_policy\x18\x13 \x01(\x0b\x32!.inference.ModelTransactionPolicy\x1a\x37\n\x15\x43\x63ModelFilenamesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1a\x31\n\x0fMetricTagsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01\x1aL\n\x0fParametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12(\n\x05value\x18\x02 \x01(\x0b\x32\x19.inference.ModelParameter:\x02\x38\x01\x42\x13\n\x11scheduling_choice*\xeb\x01\n\x08\x44\x61taType\x12\x10\n\x0cTYPE_INVALID\x10\x00\x12\r\n\tTYPE_BOOL\x10\x01\x12\x0e\n\nTYPE_UINT8\x10\x02\x12\x0f\n\x0bTYPE_UINT16\x10\x03\x12\x0f\n\x0bTYPE_UINT32\x10\x04\x12\x0f\n\x0bTYPE_UINT64\x10\x05\x12\r\n\tTYPE_INT8\x10\x06\x12\x0e\n\nTYPE_INT16\x10\x07\x12\x0e\n\nTYPE_INT32\x10\x08\x12\x0e\n\nTYPE_INT64\x10\t\x12\r\n\tTYPE_FP16\x10\n\x12\r\n\tTYPE_FP32\x10\x0b\x12\r\n\tTYPE_FP64\x10\x0c\x12\x0f\n\x0bTYPE_STRING\x10\rb\x06proto3'
    ),
)

_DATATYPE = _descriptor.EnumDescriptor(
    name="DataType",
    full_name="inference.DataType",
    filename=None,
    file=DESCRIPTOR,
    values=[
        _descriptor.EnumValueDescriptor(
            name="TYPE_INVALID", index=0, number=0, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="TYPE_BOOL", index=1, number=1, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="TYPE_UINT8", index=2, number=2, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="TYPE_UINT16", index=3, number=3, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="TYPE_UINT32", index=4, number=4, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="TYPE_UINT64", index=5, number=5, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="TYPE_INT8", index=6, number=6, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="TYPE_INT16", index=7, number=7, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="TYPE_INT32", index=8, number=8, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="TYPE_INT64", index=9, number=9, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="TYPE_FP16", index=10, number=10, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="TYPE_FP32", index=11, number=11, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="TYPE_FP64", index=12, number=12, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="TYPE_STRING", index=13, number=13, serialized_options=None, type=None
        ),
    ],
    containing_type=None,
    serialized_options=None,
    serialized_start=6899,
    serialized_end=7134,
)
_sym_db.RegisterEnumDescriptor(_DATATYPE)

DataType = enum_type_wrapper.EnumTypeWrapper(_DATATYPE)
TYPE_INVALID = 0
TYPE_BOOL = 1
TYPE_UINT8 = 2
TYPE_UINT16 = 3
TYPE_UINT32 = 4
TYPE_UINT64 = 5
TYPE_INT8 = 6
TYPE_INT16 = 7
TYPE_INT32 = 8
TYPE_INT64 = 9
TYPE_FP16 = 10
TYPE_FP32 = 11
TYPE_FP64 = 12
TYPE_STRING = 13


_MODELINSTANCEGROUP_KIND = _descriptor.EnumDescriptor(
    name="Kind",
    full_name="inference.ModelInstanceGroup.Kind",
    filename=None,
    file=DESCRIPTOR,
    values=[
        _descriptor.EnumValueDescriptor(
            name="KIND_AUTO", index=0, number=0, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="KIND_GPU", index=1, number=1, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="KIND_CPU", index=2, number=2, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="KIND_MODEL", index=3, number=3, serialized_options=None, type=None
        ),
    ],
    containing_type=None,
    serialized_options=None,
    serialized_start=370,
    serialized_end=435,
)
_sym_db.RegisterEnumDescriptor(_MODELINSTANCEGROUP_KIND)

_MODELINPUT_FORMAT = _descriptor.EnumDescriptor(
    name="Format",
    full_name="inference.ModelInput.Format",
    filename=None,
    file=DESCRIPTOR,
    values=[
        _descriptor.EnumValueDescriptor(
            name="FORMAT_NONE", index=0, number=0, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="FORMAT_NHWC", index=1, number=1, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="FORMAT_NCHW", index=2, number=2, serialized_options=None, type=None
        ),
    ],
    containing_type=None,
    serialized_options=None,
    serialized_start=704,
    serialized_end=763,
)
_sym_db.RegisterEnumDescriptor(_MODELINPUT_FORMAT)

_BATCHINPUT_KIND = _descriptor.EnumDescriptor(
    name="Kind",
    full_name="inference.BatchInput.Kind",
    filename=None,
    file=DESCRIPTOR,
    values=[
        _descriptor.EnumValueDescriptor(
            name="BATCH_ELEMENT_COUNT", index=0, number=0, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="BATCH_ACCUMULATED_ELEMENT_COUNT",
            index=1,
            number=1,
            serialized_options=None,
            type=None,
        ),
        _descriptor.EnumValueDescriptor(
            name="BATCH_ACCUMULATED_ELEMENT_COUNT_WITH_ZERO",
            index=2,
            number=2,
            serialized_options=None,
            type=None,
        ),
        _descriptor.EnumValueDescriptor(
            name="BATCH_MAX_ELEMENT_COUNT_AS_SHAPE",
            index=3,
            number=3,
            serialized_options=None,
            type=None,
        ),
    ],
    containing_type=None,
    serialized_options=None,
    serialized_start=1087,
    serialized_end=1240,
)
_sym_db.RegisterEnumDescriptor(_BATCHINPUT_KIND)

_BATCHOUTPUT_KIND = _descriptor.EnumDescriptor(
    name="Kind",
    full_name="inference.BatchOutput.Kind",
    filename=None,
    file=DESCRIPTOR,
    values=[
        _descriptor.EnumValueDescriptor(
            name="BATCH_SCATTER_WITH_INPUT_SHAPE",
            index=0,
            number=0,
            serialized_options=None,
            type=None,
        ),
    ],
    containing_type=None,
    serialized_options=None,
    serialized_start=1344,
    serialized_end=1386,
)
_sym_db.RegisterEnumDescriptor(_BATCHOUTPUT_KIND)

_MODELOPTIMIZATIONPOLICY_MODELPRIORITY = _descriptor.EnumDescriptor(
    name="ModelPriority",
    full_name="inference.ModelOptimizationPolicy.ModelPriority",
    filename=None,
    file=DESCRIPTOR,
    values=[
        _descriptor.EnumValueDescriptor(
            name="PRIORITY_DEFAULT", index=0, number=0, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="PRIORITY_MAX", index=1, number=1, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="PRIORITY_MIN", index=2, number=2, serialized_options=None, type=None
        ),
    ],
    containing_type=None,
    serialized_options=None,
    serialized_start=3288,
    serialized_end=3361,
)
_sym_db.RegisterEnumDescriptor(_MODELOPTIMIZATIONPOLICY_MODELPRIORITY)

_MODELQUEUEPOLICY_TIMEOUTACTION = _descriptor.EnumDescriptor(
    name="TimeoutAction",
    full_name="inference.ModelQueuePolicy.TimeoutAction",
    filename=None,
    file=DESCRIPTOR,
    values=[
        _descriptor.EnumValueDescriptor(
            name="REJECT", index=0, number=0, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="DELAY", index=1, number=1, serialized_options=None, type=None
        ),
    ],
    containing_type=None,
    serialized_options=None,
    serialized_start=3545,
    serialized_end=3583,
)
_sym_db.RegisterEnumDescriptor(_MODELQUEUEPOLICY_TIMEOUTACTION)

_MODELSEQUENCEBATCHING_CONTROL_KIND = _descriptor.EnumDescriptor(
    name="Kind",
    full_name="inference.ModelSequenceBatching.Control.Kind",
    filename=None,
    file=DESCRIPTOR,
    values=[
        _descriptor.EnumValueDescriptor(
            name="CONTROL_SEQUENCE_START", index=0, number=0, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="CONTROL_SEQUENCE_READY", index=1, number=1, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="CONTROL_SEQUENCE_END", index=2, number=2, serialized_options=None, type=None
        ),
        _descriptor.EnumValueDescriptor(
            name="CONTROL_SEQUENCE_CORRID", index=3, number=3, serialized_options=None, type=None
        ),
    ],
    containing_type=None,
    serialized_options=None,
    serialized_start=4433,
    serialized_end=4550,
)
_sym_db.RegisterEnumDescriptor(_MODELSEQUENCEBATCHING_CONTROL_KIND)


_MODELRATELIMITER_RESOURCE = _descriptor.Descriptor(
    name="Resource",
    full_name="inference.ModelRateLimiter.Resource",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelRateLimiter.Resource.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="global",
            full_name="inference.ModelRateLimiter.Resource.global",
            index=1,
            number=2,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="count",
            full_name="inference.ModelRateLimiter.Resource.count",
            index=2,
            number=3,
            type=13,
            cpp_type=3,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=129,
    serialized_end=184,
)

_MODELRATELIMITER = _descriptor.Descriptor(
    name="ModelRateLimiter",
    full_name="inference.ModelRateLimiter",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="resources",
            full_name="inference.ModelRateLimiter.resources",
            index=0,
            number=1,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="priority",
            full_name="inference.ModelRateLimiter.priority",
            index=1,
            number=2,
            type=13,
            cpp_type=3,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELRATELIMITER_RESOURCE,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=34,
    serialized_end=184,
)


_MODELINSTANCEGROUP = _descriptor.Descriptor(
    name="ModelInstanceGroup",
    full_name="inference.ModelInstanceGroup",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelInstanceGroup.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="kind",
            full_name="inference.ModelInstanceGroup.kind",
            index=1,
            number=4,
            type=14,
            cpp_type=8,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="count",
            full_name="inference.ModelInstanceGroup.count",
            index=2,
            number=2,
            type=5,
            cpp_type=1,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="rate_limiter",
            full_name="inference.ModelInstanceGroup.rate_limiter",
            index=3,
            number=6,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="gpus",
            full_name="inference.ModelInstanceGroup.gpus",
            index=4,
            number=3,
            type=5,
            cpp_type=1,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="profile",
            full_name="inference.ModelInstanceGroup.profile",
            index=5,
            number=5,
            type=9,
            cpp_type=9,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[
        _MODELINSTANCEGROUP_KIND,
    ],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=187,
    serialized_end=435,
)


_MODELTENSORRESHAPE = _descriptor.Descriptor(
    name="ModelTensorReshape",
    full_name="inference.ModelTensorReshape",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="shape",
            full_name="inference.ModelTensorReshape.shape",
            index=0,
            number=1,
            type=3,
            cpp_type=2,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=437,
    serialized_end=472,
)


_MODELINPUT = _descriptor.Descriptor(
    name="ModelInput",
    full_name="inference.ModelInput",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelInput.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="data_type",
            full_name="inference.ModelInput.data_type",
            index=1,
            number=2,
            type=14,
            cpp_type=8,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="format",
            full_name="inference.ModelInput.format",
            index=2,
            number=3,
            type=14,
            cpp_type=8,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="dims",
            full_name="inference.ModelInput.dims",
            index=3,
            number=4,
            type=3,
            cpp_type=2,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="reshape",
            full_name="inference.ModelInput.reshape",
            index=4,
            number=5,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="is_shape_tensor",
            full_name="inference.ModelInput.is_shape_tensor",
            index=5,
            number=6,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="allow_ragged_batch",
            full_name="inference.ModelInput.allow_ragged_batch",
            index=6,
            number=7,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[
        _MODELINPUT_FORMAT,
    ],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=475,
    serialized_end=763,
)


_MODELOUTPUT = _descriptor.Descriptor(
    name="ModelOutput",
    full_name="inference.ModelOutput",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelOutput.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="data_type",
            full_name="inference.ModelOutput.data_type",
            index=1,
            number=2,
            type=14,
            cpp_type=8,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="dims",
            full_name="inference.ModelOutput.dims",
            index=2,
            number=3,
            type=3,
            cpp_type=2,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="reshape",
            full_name="inference.ModelOutput.reshape",
            index=3,
            number=5,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="label_filename",
            full_name="inference.ModelOutput.label_filename",
            index=4,
            number=4,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="is_shape_tensor",
            full_name="inference.ModelOutput.is_shape_tensor",
            index=5,
            number=6,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=766,
    serialized_end=944,
)


_BATCHINPUT = _descriptor.Descriptor(
    name="BatchInput",
    full_name="inference.BatchInput",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="kind",
            full_name="inference.BatchInput.kind",
            index=0,
            number=1,
            type=14,
            cpp_type=8,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="target_name",
            full_name="inference.BatchInput.target_name",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="data_type",
            full_name="inference.BatchInput.data_type",
            index=2,
            number=3,
            type=14,
            cpp_type=8,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="source_input",
            full_name="inference.BatchInput.source_input",
            index=3,
            number=4,
            type=9,
            cpp_type=9,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[
        _BATCHINPUT_KIND,
    ],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=947,
    serialized_end=1240,
)


_BATCHOUTPUT = _descriptor.Descriptor(
    name="BatchOutput",
    full_name="inference.BatchOutput",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="target_name",
            full_name="inference.BatchOutput.target_name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="kind",
            full_name="inference.BatchOutput.kind",
            index=1,
            number=2,
            type=14,
            cpp_type=8,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="source_input",
            full_name="inference.BatchOutput.source_input",
            index=2,
            number=3,
            type=9,
            cpp_type=9,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[
        _BATCHOUTPUT_KIND,
    ],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=1243,
    serialized_end=1386,
)


_MODELVERSIONPOLICY_LATEST = _descriptor.Descriptor(
    name="Latest",
    full_name="inference.ModelVersionPolicy.Latest",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="num_versions",
            full_name="inference.ModelVersionPolicy.Latest.num_versions",
            index=0,
            number=1,
            type=13,
            cpp_type=3,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=1577,
    serialized_end=1607,
)

_MODELVERSIONPOLICY_ALL = _descriptor.Descriptor(
    name="All",
    full_name="inference.ModelVersionPolicy.All",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=1609,
    serialized_end=1614,
)

_MODELVERSIONPOLICY_SPECIFIC = _descriptor.Descriptor(
    name="Specific",
    full_name="inference.ModelVersionPolicy.Specific",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="versions",
            full_name="inference.ModelVersionPolicy.Specific.versions",
            index=0,
            number=1,
            type=3,
            cpp_type=2,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=1616,
    serialized_end=1644,
)

_MODELVERSIONPOLICY = _descriptor.Descriptor(
    name="ModelVersionPolicy",
    full_name="inference.ModelVersionPolicy",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="latest",
            full_name="inference.ModelVersionPolicy.latest",
            index=0,
            number=1,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="all",
            full_name="inference.ModelVersionPolicy.all",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="specific",
            full_name="inference.ModelVersionPolicy.specific",
            index=2,
            number=3,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELVERSIONPOLICY_LATEST,
        _MODELVERSIONPOLICY_ALL,
        _MODELVERSIONPOLICY_SPECIFIC,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[
        _descriptor.OneofDescriptor(
            name="policy_choice",
            full_name="inference.ModelVersionPolicy.policy_choice",
            index=0,
            containing_type=None,
            fields=[],
        ),
    ],
    serialized_start=1389,
    serialized_end=1661,
)


_MODELOPTIMIZATIONPOLICY_GRAPH = _descriptor.Descriptor(
    name="Graph",
    full_name="inference.ModelOptimizationPolicy.Graph",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="level",
            full_name="inference.ModelOptimizationPolicy.Graph.level",
            index=0,
            number=1,
            type=5,
            cpp_type=1,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=2130,
    serialized_end=2152,
)

_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_SHAPE = _descriptor.Descriptor(
    name="Shape",
    full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec.Shape",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="dim",
            full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec.Shape.dim",
            index=0,
            number=1,
            type=3,
            cpp_type=2,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=2476,
    serialized_end=2496,
)

_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_LOWERBOUND_INPUTENTRY = _descriptor.Descriptor(
    name="InputEntry",
    full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound.InputEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound.InputEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound.InputEntry.value",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=_b("8\001"),
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=2621,
    serialized_end=2722,
)

_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_LOWERBOUND = _descriptor.Descriptor(
    name="LowerBound",
    full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="batch_size",
            full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound.batch_size",
            index=0,
            number=1,
            type=5,
            cpp_type=1,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="input",
            full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound.input",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_LOWERBOUND_INPUTENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=2499,
    serialized_end=2722,
)

_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_INPUTENTRY = _descriptor.Descriptor(
    name="InputEntry",
    full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec.InputEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec.InputEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec.InputEntry.value",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=_b("8\001"),
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=2621,
    serialized_end=2722,
)

_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC = _descriptor.Descriptor(
    name="GraphSpec",
    full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="batch_size",
            full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec.batch_size",
            index=0,
            number=1,
            type=5,
            cpp_type=1,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="input",
            full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec.input",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="graph_lower_bound",
            full_name="inference.ModelOptimizationPolicy.Cuda.GraphSpec.graph_lower_bound",
            index=2,
            number=3,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_SHAPE,
        _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_LOWERBOUND,
        _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_INPUTENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=2277,
    serialized_end=2825,
)

_MODELOPTIMIZATIONPOLICY_CUDA = _descriptor.Descriptor(
    name="Cuda",
    full_name="inference.ModelOptimizationPolicy.Cuda",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="graphs",
            full_name="inference.ModelOptimizationPolicy.Cuda.graphs",
            index=0,
            number=1,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="busy_wait_events",
            full_name="inference.ModelOptimizationPolicy.Cuda.busy_wait_events",
            index=1,
            number=2,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="graph_spec",
            full_name="inference.ModelOptimizationPolicy.Cuda.graph_spec",
            index=2,
            number=3,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=2155,
    serialized_end=2825,
)

_MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS_ACCELERATOR_PARAMETERSENTRY = _descriptor.Descriptor(
    name="ParametersEntry",
    full_name="inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.ParametersEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.ParametersEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.ParametersEntry.value",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=_b("8\001"),
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=3199,
    serialized_end=3248,
)

_MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS_ACCELERATOR = _descriptor.Descriptor(
    name="Accelerator",
    full_name="inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="parameters",
            full_name="inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.parameters",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS_ACCELERATOR_PARAMETERSENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=3064,
    serialized_end=3248,
)

_MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS = _descriptor.Descriptor(
    name="ExecutionAccelerators",
    full_name="inference.ModelOptimizationPolicy.ExecutionAccelerators",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="gpu_execution_accelerator",
            full_name="inference.ModelOptimizationPolicy.ExecutionAccelerators.gpu_execution_accelerator",
            index=0,
            number=1,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="cpu_execution_accelerator",
            full_name="inference.ModelOptimizationPolicy.ExecutionAccelerators.cpu_execution_accelerator",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS_ACCELERATOR,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=2828,
    serialized_end=3248,
)

_MODELOPTIMIZATIONPOLICY_PINNEDMEMORYBUFFER = _descriptor.Descriptor(
    name="PinnedMemoryBuffer",
    full_name="inference.ModelOptimizationPolicy.PinnedMemoryBuffer",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="enable",
            full_name="inference.ModelOptimizationPolicy.PinnedMemoryBuffer.enable",
            index=0,
            number=1,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=3250,
    serialized_end=3286,
)

_MODELOPTIMIZATIONPOLICY = _descriptor.Descriptor(
    name="ModelOptimizationPolicy",
    full_name="inference.ModelOptimizationPolicy",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="graph",
            full_name="inference.ModelOptimizationPolicy.graph",
            index=0,
            number=1,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="priority",
            full_name="inference.ModelOptimizationPolicy.priority",
            index=1,
            number=2,
            type=14,
            cpp_type=8,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="cuda",
            full_name="inference.ModelOptimizationPolicy.cuda",
            index=2,
            number=3,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="execution_accelerators",
            full_name="inference.ModelOptimizationPolicy.execution_accelerators",
            index=3,
            number=4,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="input_pinned_memory",
            full_name="inference.ModelOptimizationPolicy.input_pinned_memory",
            index=4,
            number=5,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="output_pinned_memory",
            full_name="inference.ModelOptimizationPolicy.output_pinned_memory",
            index=5,
            number=6,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELOPTIMIZATIONPOLICY_GRAPH,
        _MODELOPTIMIZATIONPOLICY_CUDA,
        _MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS,
        _MODELOPTIMIZATIONPOLICY_PINNEDMEMORYBUFFER,
    ],
    enum_types=[
        _MODELOPTIMIZATIONPOLICY_MODELPRIORITY,
    ],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=1664,
    serialized_end=3361,
)


_MODELQUEUEPOLICY = _descriptor.Descriptor(
    name="ModelQueuePolicy",
    full_name="inference.ModelQueuePolicy",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="timeout_action",
            full_name="inference.ModelQueuePolicy.timeout_action",
            index=0,
            number=1,
            type=14,
            cpp_type=8,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="default_timeout_microseconds",
            full_name="inference.ModelQueuePolicy.default_timeout_microseconds",
            index=1,
            number=2,
            type=4,
            cpp_type=4,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="allow_timeout_override",
            full_name="inference.ModelQueuePolicy.allow_timeout_override",
            index=2,
            number=3,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="max_queue_size",
            full_name="inference.ModelQueuePolicy.max_queue_size",
            index=3,
            number=4,
            type=13,
            cpp_type=3,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[
        _MODELQUEUEPOLICY_TIMEOUTACTION,
    ],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=3364,
    serialized_end=3583,
)


_MODELDYNAMICBATCHING_PRIORITYQUEUEPOLICYENTRY = _descriptor.Descriptor(
    name="PriorityQueuePolicyEntry",
    full_name="inference.ModelDynamicBatching.PriorityQueuePolicyEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelDynamicBatching.PriorityQueuePolicyEntry.key",
            index=0,
            number=1,
            type=13,
            cpp_type=3,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelDynamicBatching.PriorityQueuePolicyEntry.value",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=_b("8\001"),
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=3910,
    serialized_end=3997,
)

_MODELDYNAMICBATCHING = _descriptor.Descriptor(
    name="ModelDynamicBatching",
    full_name="inference.ModelDynamicBatching",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="preferred_batch_size",
            full_name="inference.ModelDynamicBatching.preferred_batch_size",
            index=0,
            number=1,
            type=5,
            cpp_type=1,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="max_queue_delay_microseconds",
            full_name="inference.ModelDynamicBatching.max_queue_delay_microseconds",
            index=1,
            number=2,
            type=4,
            cpp_type=4,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="preserve_ordering",
            full_name="inference.ModelDynamicBatching.preserve_ordering",
            index=2,
            number=3,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="priority_levels",
            full_name="inference.ModelDynamicBatching.priority_levels",
            index=3,
            number=4,
            type=13,
            cpp_type=3,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="default_priority_level",
            full_name="inference.ModelDynamicBatching.default_priority_level",
            index=4,
            number=5,
            type=13,
            cpp_type=3,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="default_queue_policy",
            full_name="inference.ModelDynamicBatching.default_queue_policy",
            index=5,
            number=6,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="priority_queue_policy",
            full_name="inference.ModelDynamicBatching.priority_queue_policy",
            index=6,
            number=7,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELDYNAMICBATCHING_PRIORITYQUEUEPOLICYENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=3586,
    serialized_end=3997,
)


_MODELSEQUENCEBATCHING_CONTROL = _descriptor.Descriptor(
    name="Control",
    full_name="inference.ModelSequenceBatching.Control",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="kind",
            full_name="inference.ModelSequenceBatching.Control.kind",
            index=0,
            number=1,
            type=14,
            cpp_type=8,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="int32_false_true",
            full_name="inference.ModelSequenceBatching.Control.int32_false_true",
            index=1,
            number=2,
            type=5,
            cpp_type=1,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="fp32_false_true",
            full_name="inference.ModelSequenceBatching.Control.fp32_false_true",
            index=2,
            number=3,
            type=2,
            cpp_type=6,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="data_type",
            full_name="inference.ModelSequenceBatching.Control.data_type",
            index=3,
            number=4,
            type=14,
            cpp_type=8,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[
        _MODELSEQUENCEBATCHING_CONTROL_KIND,
    ],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=4270,
    serialized_end=4550,
)

_MODELSEQUENCEBATCHING_CONTROLINPUT = _descriptor.Descriptor(
    name="ControlInput",
    full_name="inference.ModelSequenceBatching.ControlInput",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelSequenceBatching.ControlInput.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="control",
            full_name="inference.ModelSequenceBatching.ControlInput.control",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=4552,
    serialized_end=4639,
)

_MODELSEQUENCEBATCHING_STRATEGYDIRECT = _descriptor.Descriptor(
    name="StrategyDirect",
    full_name="inference.ModelSequenceBatching.StrategyDirect",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="max_queue_delay_microseconds",
            full_name="inference.ModelSequenceBatching.StrategyDirect.max_queue_delay_microseconds",
            index=0,
            number=1,
            type=4,
            cpp_type=4,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="minimum_slot_utilization",
            full_name="inference.ModelSequenceBatching.StrategyDirect.minimum_slot_utilization",
            index=1,
            number=2,
            type=2,
            cpp_type=6,
            label=1,
            has_default_value=False,
            default_value=float(0),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=4641,
    serialized_end=4729,
)

_MODELSEQUENCEBATCHING_STRATEGYOLDEST = _descriptor.Descriptor(
    name="StrategyOldest",
    full_name="inference.ModelSequenceBatching.StrategyOldest",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="max_candidate_sequences",
            full_name="inference.ModelSequenceBatching.StrategyOldest.max_candidate_sequences",
            index=0,
            number=1,
            type=5,
            cpp_type=1,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="preferred_batch_size",
            full_name="inference.ModelSequenceBatching.StrategyOldest.preferred_batch_size",
            index=1,
            number=2,
            type=5,
            cpp_type=1,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="max_queue_delay_microseconds",
            full_name="inference.ModelSequenceBatching.StrategyOldest.max_queue_delay_microseconds",
            index=2,
            number=3,
            type=4,
            cpp_type=4,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=4731,
    serialized_end=4848,
)

_MODELSEQUENCEBATCHING = _descriptor.Descriptor(
    name="ModelSequenceBatching",
    full_name="inference.ModelSequenceBatching",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="direct",
            full_name="inference.ModelSequenceBatching.direct",
            index=0,
            number=3,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="oldest",
            full_name="inference.ModelSequenceBatching.oldest",
            index=1,
            number=4,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="max_sequence_idle_microseconds",
            full_name="inference.ModelSequenceBatching.max_sequence_idle_microseconds",
            index=2,
            number=1,
            type=4,
            cpp_type=4,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="control_input",
            full_name="inference.ModelSequenceBatching.control_input",
            index=3,
            number=2,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELSEQUENCEBATCHING_CONTROL,
        _MODELSEQUENCEBATCHING_CONTROLINPUT,
        _MODELSEQUENCEBATCHING_STRATEGYDIRECT,
        _MODELSEQUENCEBATCHING_STRATEGYOLDEST,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[
        _descriptor.OneofDescriptor(
            name="strategy_choice",
            full_name="inference.ModelSequenceBatching.strategy_choice",
            index=0,
            containing_type=None,
            fields=[],
        ),
    ],
    serialized_start=4000,
    serialized_end=4867,
)


_MODELENSEMBLING_STEP_INPUTMAPENTRY = _descriptor.Descriptor(
    name="InputMapEntry",
    full_name="inference.ModelEnsembling.Step.InputMapEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelEnsembling.Step.InputMapEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelEnsembling.Step.InputMapEntry.value",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=_b("8\001"),
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=5122,
    serialized_end=5169,
)

_MODELENSEMBLING_STEP_OUTPUTMAPENTRY = _descriptor.Descriptor(
    name="OutputMapEntry",
    full_name="inference.ModelEnsembling.Step.OutputMapEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelEnsembling.Step.OutputMapEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelEnsembling.Step.OutputMapEntry.value",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=_b("8\001"),
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=5171,
    serialized_end=5219,
)

_MODELENSEMBLING_STEP = _descriptor.Descriptor(
    name="Step",
    full_name="inference.ModelEnsembling.Step",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="model_name",
            full_name="inference.ModelEnsembling.Step.model_name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="model_version",
            full_name="inference.ModelEnsembling.Step.model_version",
            index=1,
            number=2,
            type=3,
            cpp_type=2,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="input_map",
            full_name="inference.ModelEnsembling.Step.input_map",
            index=2,
            number=3,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="output_map",
            full_name="inference.ModelEnsembling.Step.output_map",
            index=3,
            number=4,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELENSEMBLING_STEP_INPUTMAPENTRY,
        _MODELENSEMBLING_STEP_OUTPUTMAPENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=4937,
    serialized_end=5219,
)

_MODELENSEMBLING = _descriptor.Descriptor(
    name="ModelEnsembling",
    full_name="inference.ModelEnsembling",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="step",
            full_name="inference.ModelEnsembling.step",
            index=0,
            number=1,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELENSEMBLING_STEP,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=4870,
    serialized_end=5219,
)


_MODELPARAMETER = _descriptor.Descriptor(
    name="ModelParameter",
    full_name="inference.ModelParameter",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="string_value",
            full_name="inference.ModelParameter.string_value",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=5221,
    serialized_end=5259,
)


_MODELWARMUP_INPUT = _descriptor.Descriptor(
    name="Input",
    full_name="inference.ModelWarmup.Input",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="data_type",
            full_name="inference.ModelWarmup.Input.data_type",
            index=0,
            number=1,
            type=14,
            cpp_type=8,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="dims",
            full_name="inference.ModelWarmup.Input.dims",
            index=1,
            number=2,
            type=3,
            cpp_type=2,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="zero_data",
            full_name="inference.ModelWarmup.Input.zero_data",
            index=2,
            number=3,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="random_data",
            full_name="inference.ModelWarmup.Input.random_data",
            index=3,
            number=4,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="input_data_file",
            full_name="inference.ModelWarmup.Input.input_data_file",
            index=4,
            number=5,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[
        _descriptor.OneofDescriptor(
            name="input_data_type",
            full_name="inference.ModelWarmup.Input.input_data_type",
            index=0,
            containing_type=None,
            fields=[],
        ),
    ],
    serialized_start=5364,
    serialized_end=5515,
)

_MODELWARMUP_INPUTSENTRY = _descriptor.Descriptor(
    name="InputsEntry",
    full_name="inference.ModelWarmup.InputsEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelWarmup.InputsEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelWarmup.InputsEntry.value",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=_b("8\001"),
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=5517,
    serialized_end=5592,
)

_MODELWARMUP = _descriptor.Descriptor(
    name="ModelWarmup",
    full_name="inference.ModelWarmup",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelWarmup.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="batch_size",
            full_name="inference.ModelWarmup.batch_size",
            index=1,
            number=2,
            type=13,
            cpp_type=3,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="inputs",
            full_name="inference.ModelWarmup.inputs",
            index=2,
            number=3,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELWARMUP_INPUT,
        _MODELWARMUP_INPUTSENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=5262,
    serialized_end=5592,
)


_MODELOPERATIONS = _descriptor.Descriptor(
    name="ModelOperations",
    full_name="inference.ModelOperations",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="op_library_filename",
            full_name="inference.ModelOperations.op_library_filename",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=5594,
    serialized_end=5640,
)


_MODELTRANSACTIONPOLICY = _descriptor.Descriptor(
    name="ModelTransactionPolicy",
    full_name="inference.ModelTransactionPolicy",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="decoupled",
            full_name="inference.ModelTransactionPolicy.decoupled",
            index=0,
            number=1,
            type=8,
            cpp_type=7,
            label=1,
            has_default_value=False,
            default_value=False,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=5642,
    serialized_end=5685,
)


_MODELCONFIG_CCMODELFILENAMESENTRY = _descriptor.Descriptor(
    name="CcModelFilenamesEntry",
    full_name="inference.ModelConfig.CcModelFilenamesEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelConfig.CcModelFilenamesEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelConfig.CcModelFilenamesEntry.value",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=_b("8\001"),
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=6691,
    serialized_end=6746,
)

_MODELCONFIG_METRICTAGSENTRY = _descriptor.Descriptor(
    name="MetricTagsEntry",
    full_name="inference.ModelConfig.MetricTagsEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelConfig.MetricTagsEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelConfig.MetricTagsEntry.value",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=_b("8\001"),
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=6748,
    serialized_end=6797,
)

_MODELCONFIG_PARAMETERSENTRY = _descriptor.Descriptor(
    name="ParametersEntry",
    full_name="inference.ModelConfig.ParametersEntry",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="key",
            full_name="inference.ModelConfig.ParametersEntry.key",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="value",
            full_name="inference.ModelConfig.ParametersEntry.value",
            index=1,
            number=2,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[],
    enum_types=[],
    serialized_options=_b("8\001"),
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[],
    serialized_start=6799,
    serialized_end=6875,
)

_MODELCONFIG = _descriptor.Descriptor(
    name="ModelConfig",
    full_name="inference.ModelConfig",
    filename=None,
    file=DESCRIPTOR,
    containing_type=None,
    fields=[
        _descriptor.FieldDescriptor(
            name="name",
            full_name="inference.ModelConfig.name",
            index=0,
            number=1,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="platform",
            full_name="inference.ModelConfig.platform",
            index=1,
            number=2,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="backend",
            full_name="inference.ModelConfig.backend",
            index=2,
            number=17,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="version_policy",
            full_name="inference.ModelConfig.version_policy",
            index=3,
            number=3,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="max_batch_size",
            full_name="inference.ModelConfig.max_batch_size",
            index=4,
            number=4,
            type=5,
            cpp_type=1,
            label=1,
            has_default_value=False,
            default_value=0,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="input",
            full_name="inference.ModelConfig.input",
            index=5,
            number=5,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="output",
            full_name="inference.ModelConfig.output",
            index=6,
            number=6,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="batch_input",
            full_name="inference.ModelConfig.batch_input",
            index=7,
            number=20,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="batch_output",
            full_name="inference.ModelConfig.batch_output",
            index=8,
            number=21,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="optimization",
            full_name="inference.ModelConfig.optimization",
            index=9,
            number=12,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="dynamic_batching",
            full_name="inference.ModelConfig.dynamic_batching",
            index=10,
            number=11,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="sequence_batching",
            full_name="inference.ModelConfig.sequence_batching",
            index=11,
            number=13,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="ensemble_scheduling",
            full_name="inference.ModelConfig.ensemble_scheduling",
            index=12,
            number=15,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="instance_group",
            full_name="inference.ModelConfig.instance_group",
            index=13,
            number=7,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="default_model_filename",
            full_name="inference.ModelConfig.default_model_filename",
            index=14,
            number=8,
            type=9,
            cpp_type=9,
            label=1,
            has_default_value=False,
            default_value=_b("").decode("utf-8"),
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="cc_model_filenames",
            full_name="inference.ModelConfig.cc_model_filenames",
            index=15,
            number=9,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="metric_tags",
            full_name="inference.ModelConfig.metric_tags",
            index=16,
            number=10,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="parameters",
            full_name="inference.ModelConfig.parameters",
            index=17,
            number=14,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="model_warmup",
            full_name="inference.ModelConfig.model_warmup",
            index=18,
            number=16,
            type=11,
            cpp_type=10,
            label=3,
            has_default_value=False,
            default_value=[],
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="model_operations",
            full_name="inference.ModelConfig.model_operations",
            index=19,
            number=18,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
        _descriptor.FieldDescriptor(
            name="model_transaction_policy",
            full_name="inference.ModelConfig.model_transaction_policy",
            index=20,
            number=19,
            type=11,
            cpp_type=10,
            label=1,
            has_default_value=False,
            default_value=None,
            message_type=None,
            enum_type=None,
            containing_type=None,
            is_extension=False,
            extension_scope=None,
            serialized_options=None,
            file=DESCRIPTOR,
        ),
    ],
    extensions=[],
    nested_types=[
        _MODELCONFIG_CCMODELFILENAMESENTRY,
        _MODELCONFIG_METRICTAGSENTRY,
        _MODELCONFIG_PARAMETERSENTRY,
    ],
    enum_types=[],
    serialized_options=None,
    is_extendable=False,
    syntax="proto3",
    extension_ranges=[],
    oneofs=[
        _descriptor.OneofDescriptor(
            name="scheduling_choice",
            full_name="inference.ModelConfig.scheduling_choice",
            index=0,
            containing_type=None,
            fields=[],
        ),
    ],
    serialized_start=5688,
    serialized_end=6896,
)

_MODELRATELIMITER_RESOURCE.containing_type = _MODELRATELIMITER
_MODELRATELIMITER.fields_by_name["resources"].message_type = _MODELRATELIMITER_RESOURCE
_MODELINSTANCEGROUP.fields_by_name["kind"].enum_type = _MODELINSTANCEGROUP_KIND
_MODELINSTANCEGROUP.fields_by_name["rate_limiter"].message_type = _MODELRATELIMITER
_MODELINSTANCEGROUP_KIND.containing_type = _MODELINSTANCEGROUP
_MODELINPUT.fields_by_name["data_type"].enum_type = _DATATYPE
_MODELINPUT.fields_by_name["format"].enum_type = _MODELINPUT_FORMAT
_MODELINPUT.fields_by_name["reshape"].message_type = _MODELTENSORRESHAPE
_MODELINPUT_FORMAT.containing_type = _MODELINPUT
_MODELOUTPUT.fields_by_name["data_type"].enum_type = _DATATYPE
_MODELOUTPUT.fields_by_name["reshape"].message_type = _MODELTENSORRESHAPE
_BATCHINPUT.fields_by_name["kind"].enum_type = _BATCHINPUT_KIND
_BATCHINPUT.fields_by_name["data_type"].enum_type = _DATATYPE
_BATCHINPUT_KIND.containing_type = _BATCHINPUT
_BATCHOUTPUT.fields_by_name["kind"].enum_type = _BATCHOUTPUT_KIND
_BATCHOUTPUT_KIND.containing_type = _BATCHOUTPUT
_MODELVERSIONPOLICY_LATEST.containing_type = _MODELVERSIONPOLICY
_MODELVERSIONPOLICY_ALL.containing_type = _MODELVERSIONPOLICY
_MODELVERSIONPOLICY_SPECIFIC.containing_type = _MODELVERSIONPOLICY
_MODELVERSIONPOLICY.fields_by_name["latest"].message_type = _MODELVERSIONPOLICY_LATEST
_MODELVERSIONPOLICY.fields_by_name["all"].message_type = _MODELVERSIONPOLICY_ALL
_MODELVERSIONPOLICY.fields_by_name["specific"].message_type = _MODELVERSIONPOLICY_SPECIFIC
_MODELVERSIONPOLICY.oneofs_by_name["policy_choice"].fields.append(
    _MODELVERSIONPOLICY.fields_by_name["latest"]
)
_MODELVERSIONPOLICY.fields_by_name["latest"].containing_oneof = _MODELVERSIONPOLICY.oneofs_by_name[
    "policy_choice"
]
_MODELVERSIONPOLICY.oneofs_by_name["policy_choice"].fields.append(
    _MODELVERSIONPOLICY.fields_by_name["all"]
)
_MODELVERSIONPOLICY.fields_by_name["all"].containing_oneof = _MODELVERSIONPOLICY.oneofs_by_name[
    "policy_choice"
]
_MODELVERSIONPOLICY.oneofs_by_name["policy_choice"].fields.append(
    _MODELVERSIONPOLICY.fields_by_name["specific"]
)
_MODELVERSIONPOLICY.fields_by_name[
    "specific"
].containing_oneof = _MODELVERSIONPOLICY.oneofs_by_name["policy_choice"]
_MODELOPTIMIZATIONPOLICY_GRAPH.containing_type = _MODELOPTIMIZATIONPOLICY
_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_SHAPE.containing_type = (
    _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC
)
_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_LOWERBOUND_INPUTENTRY.fields_by_name[
    "value"
].message_type = _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_SHAPE
_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_LOWERBOUND_INPUTENTRY.containing_type = (
    _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_LOWERBOUND
)
_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_LOWERBOUND.fields_by_name[
    "input"
].message_type = _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_LOWERBOUND_INPUTENTRY
_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_LOWERBOUND.containing_type = (
    _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC
)
_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_INPUTENTRY.fields_by_name[
    "value"
].message_type = _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_SHAPE
_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_INPUTENTRY.containing_type = (
    _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC
)
_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC.fields_by_name[
    "input"
].message_type = _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_INPUTENTRY
_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC.fields_by_name[
    "graph_lower_bound"
].message_type = _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_LOWERBOUND
_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC.containing_type = _MODELOPTIMIZATIONPOLICY_CUDA
_MODELOPTIMIZATIONPOLICY_CUDA.fields_by_name[
    "graph_spec"
].message_type = _MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC
_MODELOPTIMIZATIONPOLICY_CUDA.containing_type = _MODELOPTIMIZATIONPOLICY
_MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS_ACCELERATOR_PARAMETERSENTRY.containing_type = (
    _MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS_ACCELERATOR
)
_MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS_ACCELERATOR.fields_by_name[
    "parameters"
].message_type = _MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS_ACCELERATOR_PARAMETERSENTRY
_MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS_ACCELERATOR.containing_type = (
    _MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS
)
_MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS.fields_by_name[
    "gpu_execution_accelerator"
].message_type = _MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS_ACCELERATOR
_MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS.fields_by_name[
    "cpu_execution_accelerator"
].message_type = _MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS_ACCELERATOR
_MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS.containing_type = _MODELOPTIMIZATIONPOLICY
_MODELOPTIMIZATIONPOLICY_PINNEDMEMORYBUFFER.containing_type = _MODELOPTIMIZATIONPOLICY
_MODELOPTIMIZATIONPOLICY.fields_by_name["graph"].message_type = _MODELOPTIMIZATIONPOLICY_GRAPH
_MODELOPTIMIZATIONPOLICY.fields_by_name[
    "priority"
].enum_type = _MODELOPTIMIZATIONPOLICY_MODELPRIORITY
_MODELOPTIMIZATIONPOLICY.fields_by_name["cuda"].message_type = _MODELOPTIMIZATIONPOLICY_CUDA
_MODELOPTIMIZATIONPOLICY.fields_by_name[
    "execution_accelerators"
].message_type = _MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS
_MODELOPTIMIZATIONPOLICY.fields_by_name[
    "input_pinned_memory"
].message_type = _MODELOPTIMIZATIONPOLICY_PINNEDMEMORYBUFFER
_MODELOPTIMIZATIONPOLICY.fields_by_name[
    "output_pinned_memory"
].message_type = _MODELOPTIMIZATIONPOLICY_PINNEDMEMORYBUFFER
_MODELOPTIMIZATIONPOLICY_MODELPRIORITY.containing_type = _MODELOPTIMIZATIONPOLICY
_MODELQUEUEPOLICY.fields_by_name["timeout_action"].enum_type = _MODELQUEUEPOLICY_TIMEOUTACTION
_MODELQUEUEPOLICY_TIMEOUTACTION.containing_type = _MODELQUEUEPOLICY
_MODELDYNAMICBATCHING_PRIORITYQUEUEPOLICYENTRY.fields_by_name[
    "value"
].message_type = _MODELQUEUEPOLICY
_MODELDYNAMICBATCHING_PRIORITYQUEUEPOLICYENTRY.containing_type = _MODELDYNAMICBATCHING
_MODELDYNAMICBATCHING.fields_by_name["default_queue_policy"].message_type = _MODELQUEUEPOLICY
_MODELDYNAMICBATCHING.fields_by_name[
    "priority_queue_policy"
].message_type = _MODELDYNAMICBATCHING_PRIORITYQUEUEPOLICYENTRY
_MODELSEQUENCEBATCHING_CONTROL.fields_by_name[
    "kind"
].enum_type = _MODELSEQUENCEBATCHING_CONTROL_KIND
_MODELSEQUENCEBATCHING_CONTROL.fields_by_name["data_type"].enum_type = _DATATYPE
_MODELSEQUENCEBATCHING_CONTROL.containing_type = _MODELSEQUENCEBATCHING
_MODELSEQUENCEBATCHING_CONTROL_KIND.containing_type = _MODELSEQUENCEBATCHING_CONTROL
_MODELSEQUENCEBATCHING_CONTROLINPUT.fields_by_name[
    "control"
].message_type = _MODELSEQUENCEBATCHING_CONTROL
_MODELSEQUENCEBATCHING_CONTROLINPUT.containing_type = _MODELSEQUENCEBATCHING
_MODELSEQUENCEBATCHING_STRATEGYDIRECT.containing_type = _MODELSEQUENCEBATCHING
_MODELSEQUENCEBATCHING_STRATEGYOLDEST.containing_type = _MODELSEQUENCEBATCHING
_MODELSEQUENCEBATCHING.fields_by_name["direct"].message_type = _MODELSEQUENCEBATCHING_STRATEGYDIRECT
_MODELSEQUENCEBATCHING.fields_by_name["oldest"].message_type = _MODELSEQUENCEBATCHING_STRATEGYOLDEST
_MODELSEQUENCEBATCHING.fields_by_name[
    "control_input"
].message_type = _MODELSEQUENCEBATCHING_CONTROLINPUT
_MODELSEQUENCEBATCHING.oneofs_by_name["strategy_choice"].fields.append(
    _MODELSEQUENCEBATCHING.fields_by_name["direct"]
)
_MODELSEQUENCEBATCHING.fields_by_name[
    "direct"
].containing_oneof = _MODELSEQUENCEBATCHING.oneofs_by_name["strategy_choice"]
_MODELSEQUENCEBATCHING.oneofs_by_name["strategy_choice"].fields.append(
    _MODELSEQUENCEBATCHING.fields_by_name["oldest"]
)
_MODELSEQUENCEBATCHING.fields_by_name[
    "oldest"
].containing_oneof = _MODELSEQUENCEBATCHING.oneofs_by_name["strategy_choice"]
_MODELENSEMBLING_STEP_INPUTMAPENTRY.containing_type = _MODELENSEMBLING_STEP
_MODELENSEMBLING_STEP_OUTPUTMAPENTRY.containing_type = _MODELENSEMBLING_STEP
_MODELENSEMBLING_STEP.fields_by_name["input_map"].message_type = _MODELENSEMBLING_STEP_INPUTMAPENTRY
_MODELENSEMBLING_STEP.fields_by_name[
    "output_map"
].message_type = _MODELENSEMBLING_STEP_OUTPUTMAPENTRY
_MODELENSEMBLING_STEP.containing_type = _MODELENSEMBLING
_MODELENSEMBLING.fields_by_name["step"].message_type = _MODELENSEMBLING_STEP
_MODELWARMUP_INPUT.fields_by_name["data_type"].enum_type = _DATATYPE
_MODELWARMUP_INPUT.containing_type = _MODELWARMUP
_MODELWARMUP_INPUT.oneofs_by_name["input_data_type"].fields.append(
    _MODELWARMUP_INPUT.fields_by_name["zero_data"]
)
_MODELWARMUP_INPUT.fields_by_name["zero_data"].containing_oneof = _MODELWARMUP_INPUT.oneofs_by_name[
    "input_data_type"
]
_MODELWARMUP_INPUT.oneofs_by_name["input_data_type"].fields.append(
    _MODELWARMUP_INPUT.fields_by_name["random_data"]
)
_MODELWARMUP_INPUT.fields_by_name[
    "random_data"
].containing_oneof = _MODELWARMUP_INPUT.oneofs_by_name["input_data_type"]
_MODELWARMUP_INPUT.oneofs_by_name["input_data_type"].fields.append(
    _MODELWARMUP_INPUT.fields_by_name["input_data_file"]
)
_MODELWARMUP_INPUT.fields_by_name[
    "input_data_file"
].containing_oneof = _MODELWARMUP_INPUT.oneofs_by_name["input_data_type"]
_MODELWARMUP_INPUTSENTRY.fields_by_name["value"].message_type = _MODELWARMUP_INPUT
_MODELWARMUP_INPUTSENTRY.containing_type = _MODELWARMUP
_MODELWARMUP.fields_by_name["inputs"].message_type = _MODELWARMUP_INPUTSENTRY
_MODELCONFIG_CCMODELFILENAMESENTRY.containing_type = _MODELCONFIG
_MODELCONFIG_METRICTAGSENTRY.containing_type = _MODELCONFIG
_MODELCONFIG_PARAMETERSENTRY.fields_by_name["value"].message_type = _MODELPARAMETER
_MODELCONFIG_PARAMETERSENTRY.containing_type = _MODELCONFIG
_MODELCONFIG.fields_by_name["version_policy"].message_type = _MODELVERSIONPOLICY
_MODELCONFIG.fields_by_name["input"].message_type = _MODELINPUT
_MODELCONFIG.fields_by_name["output"].message_type = _MODELOUTPUT
_MODELCONFIG.fields_by_name["batch_input"].message_type = _BATCHINPUT
_MODELCONFIG.fields_by_name["batch_output"].message_type = _BATCHOUTPUT
_MODELCONFIG.fields_by_name["optimization"].message_type = _MODELOPTIMIZATIONPOLICY
_MODELCONFIG.fields_by_name["dynamic_batching"].message_type = _MODELDYNAMICBATCHING
_MODELCONFIG.fields_by_name["sequence_batching"].message_type = _MODELSEQUENCEBATCHING
_MODELCONFIG.fields_by_name["ensemble_scheduling"].message_type = _MODELENSEMBLING
_MODELCONFIG.fields_by_name["instance_group"].message_type = _MODELINSTANCEGROUP
_MODELCONFIG.fields_by_name["cc_model_filenames"].message_type = _MODELCONFIG_CCMODELFILENAMESENTRY
_MODELCONFIG.fields_by_name["metric_tags"].message_type = _MODELCONFIG_METRICTAGSENTRY
_MODELCONFIG.fields_by_name["parameters"].message_type = _MODELCONFIG_PARAMETERSENTRY
_MODELCONFIG.fields_by_name["model_warmup"].message_type = _MODELWARMUP
_MODELCONFIG.fields_by_name["model_operations"].message_type = _MODELOPERATIONS
_MODELCONFIG.fields_by_name["model_transaction_policy"].message_type = _MODELTRANSACTIONPOLICY
_MODELCONFIG.oneofs_by_name["scheduling_choice"].fields.append(
    _MODELCONFIG.fields_by_name["dynamic_batching"]
)
_MODELCONFIG.fields_by_name["dynamic_batching"].containing_oneof = _MODELCONFIG.oneofs_by_name[
    "scheduling_choice"
]
_MODELCONFIG.oneofs_by_name["scheduling_choice"].fields.append(
    _MODELCONFIG.fields_by_name["sequence_batching"]
)
_MODELCONFIG.fields_by_name["sequence_batching"].containing_oneof = _MODELCONFIG.oneofs_by_name[
    "scheduling_choice"
]
_MODELCONFIG.oneofs_by_name["scheduling_choice"].fields.append(
    _MODELCONFIG.fields_by_name["ensemble_scheduling"]
)
_MODELCONFIG.fields_by_name["ensemble_scheduling"].containing_oneof = _MODELCONFIG.oneofs_by_name[
    "scheduling_choice"
]
DESCRIPTOR.message_types_by_name["ModelRateLimiter"] = _MODELRATELIMITER
DESCRIPTOR.message_types_by_name["ModelInstanceGroup"] = _MODELINSTANCEGROUP
DESCRIPTOR.message_types_by_name["ModelTensorReshape"] = _MODELTENSORRESHAPE
DESCRIPTOR.message_types_by_name["ModelInput"] = _MODELINPUT
DESCRIPTOR.message_types_by_name["ModelOutput"] = _MODELOUTPUT
DESCRIPTOR.message_types_by_name["BatchInput"] = _BATCHINPUT
DESCRIPTOR.message_types_by_name["BatchOutput"] = _BATCHOUTPUT
DESCRIPTOR.message_types_by_name["ModelVersionPolicy"] = _MODELVERSIONPOLICY
DESCRIPTOR.message_types_by_name["ModelOptimizationPolicy"] = _MODELOPTIMIZATIONPOLICY
DESCRIPTOR.message_types_by_name["ModelQueuePolicy"] = _MODELQUEUEPOLICY
DESCRIPTOR.message_types_by_name["ModelDynamicBatching"] = _MODELDYNAMICBATCHING
DESCRIPTOR.message_types_by_name["ModelSequenceBatching"] = _MODELSEQUENCEBATCHING
DESCRIPTOR.message_types_by_name["ModelEnsembling"] = _MODELENSEMBLING
DESCRIPTOR.message_types_by_name["ModelParameter"] = _MODELPARAMETER
DESCRIPTOR.message_types_by_name["ModelWarmup"] = _MODELWARMUP
DESCRIPTOR.message_types_by_name["ModelOperations"] = _MODELOPERATIONS
DESCRIPTOR.message_types_by_name["ModelTransactionPolicy"] = _MODELTRANSACTIONPOLICY
DESCRIPTOR.message_types_by_name["ModelConfig"] = _MODELCONFIG
DESCRIPTOR.enum_types_by_name["DataType"] = _DATATYPE
_sym_db.RegisterFileDescriptor(DESCRIPTOR)

ModelRateLimiter = _reflection.GeneratedProtocolMessageType(
    "ModelRateLimiter",
    (_message.Message,),
    dict(
        Resource=_reflection.GeneratedProtocolMessageType(
            "Resource",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELRATELIMITER_RESOURCE,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelRateLimiter.Resource)
            ),
        ),
        DESCRIPTOR=_MODELRATELIMITER,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelRateLimiter)
    ),
)
_sym_db.RegisterMessage(ModelRateLimiter)
_sym_db.RegisterMessage(ModelRateLimiter.Resource)

ModelInstanceGroup = _reflection.GeneratedProtocolMessageType(
    "ModelInstanceGroup",
    (_message.Message,),
    dict(
        DESCRIPTOR=_MODELINSTANCEGROUP,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelInstanceGroup)
    ),
)
_sym_db.RegisterMessage(ModelInstanceGroup)

ModelTensorReshape = _reflection.GeneratedProtocolMessageType(
    "ModelTensorReshape",
    (_message.Message,),
    dict(
        DESCRIPTOR=_MODELTENSORRESHAPE,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelTensorReshape)
    ),
)
_sym_db.RegisterMessage(ModelTensorReshape)

ModelInput = _reflection.GeneratedProtocolMessageType(
    "ModelInput",
    (_message.Message,),
    dict(
        DESCRIPTOR=_MODELINPUT,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelInput)
    ),
)
_sym_db.RegisterMessage(ModelInput)

ModelOutput = _reflection.GeneratedProtocolMessageType(
    "ModelOutput",
    (_message.Message,),
    dict(
        DESCRIPTOR=_MODELOUTPUT,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelOutput)
    ),
)
_sym_db.RegisterMessage(ModelOutput)

BatchInput = _reflection.GeneratedProtocolMessageType(
    "BatchInput",
    (_message.Message,),
    dict(
        DESCRIPTOR=_BATCHINPUT,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.BatchInput)
    ),
)
_sym_db.RegisterMessage(BatchInput)

BatchOutput = _reflection.GeneratedProtocolMessageType(
    "BatchOutput",
    (_message.Message,),
    dict(
        DESCRIPTOR=_BATCHOUTPUT,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.BatchOutput)
    ),
)
_sym_db.RegisterMessage(BatchOutput)

ModelVersionPolicy = _reflection.GeneratedProtocolMessageType(
    "ModelVersionPolicy",
    (_message.Message,),
    dict(
        Latest=_reflection.GeneratedProtocolMessageType(
            "Latest",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELVERSIONPOLICY_LATEST,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelVersionPolicy.Latest)
            ),
        ),
        All=_reflection.GeneratedProtocolMessageType(
            "All",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELVERSIONPOLICY_ALL,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelVersionPolicy.All)
            ),
        ),
        Specific=_reflection.GeneratedProtocolMessageType(
            "Specific",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELVERSIONPOLICY_SPECIFIC,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelVersionPolicy.Specific)
            ),
        ),
        DESCRIPTOR=_MODELVERSIONPOLICY,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelVersionPolicy)
    ),
)
_sym_db.RegisterMessage(ModelVersionPolicy)
_sym_db.RegisterMessage(ModelVersionPolicy.Latest)
_sym_db.RegisterMessage(ModelVersionPolicy.All)
_sym_db.RegisterMessage(ModelVersionPolicy.Specific)

ModelOptimizationPolicy = _reflection.GeneratedProtocolMessageType(
    "ModelOptimizationPolicy",
    (_message.Message,),
    dict(
        Graph=_reflection.GeneratedProtocolMessageType(
            "Graph",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELOPTIMIZATIONPOLICY_GRAPH,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.Graph)
            ),
        ),
        Cuda=_reflection.GeneratedProtocolMessageType(
            "Cuda",
            (_message.Message,),
            dict(
                GraphSpec=_reflection.GeneratedProtocolMessageType(
                    "GraphSpec",
                    (_message.Message,),
                    dict(
                        Shape=_reflection.GeneratedProtocolMessageType(
                            "Shape",
                            (_message.Message,),
                            dict(
                                DESCRIPTOR=_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_SHAPE,
                                __module__="model_config_pb2"
                                # @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.Cuda.GraphSpec.Shape)
                            ),
                        ),
                        LowerBound=_reflection.GeneratedProtocolMessageType(
                            "LowerBound",
                            (_message.Message,),
                            dict(
                                InputEntry=_reflection.GeneratedProtocolMessageType(
                                    "InputEntry",
                                    (_message.Message,),
                                    dict(
                                        DESCRIPTOR=_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_LOWERBOUND_INPUTENTRY,
                                        __module__="model_config_pb2"
                                        # @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound.InputEntry)
                                    ),
                                ),
                                DESCRIPTOR=_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_LOWERBOUND,
                                __module__="model_config_pb2"
                                # @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound)
                            ),
                        ),
                        InputEntry=_reflection.GeneratedProtocolMessageType(
                            "InputEntry",
                            (_message.Message,),
                            dict(
                                DESCRIPTOR=_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_INPUTENTRY,
                                __module__="model_config_pb2"
                                # @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.Cuda.GraphSpec.InputEntry)
                            ),
                        ),
                        DESCRIPTOR=_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC,
                        __module__="model_config_pb2"
                        # @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.Cuda.GraphSpec)
                    ),
                ),
                DESCRIPTOR=_MODELOPTIMIZATIONPOLICY_CUDA,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.Cuda)
            ),
        ),
        ExecutionAccelerators=_reflection.GeneratedProtocolMessageType(
            "ExecutionAccelerators",
            (_message.Message,),
            dict(
                Accelerator=_reflection.GeneratedProtocolMessageType(
                    "Accelerator",
                    (_message.Message,),
                    dict(
                        ParametersEntry=_reflection.GeneratedProtocolMessageType(
                            "ParametersEntry",
                            (_message.Message,),
                            dict(
                                DESCRIPTOR=_MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS_ACCELERATOR_PARAMETERSENTRY,
                                __module__="model_config_pb2"
                                # @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.ParametersEntry)
                            ),
                        ),
                        DESCRIPTOR=_MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS_ACCELERATOR,
                        __module__="model_config_pb2"
                        # @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator)
                    ),
                ),
                DESCRIPTOR=_MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.ExecutionAccelerators)
            ),
        ),
        PinnedMemoryBuffer=_reflection.GeneratedProtocolMessageType(
            "PinnedMemoryBuffer",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELOPTIMIZATIONPOLICY_PINNEDMEMORYBUFFER,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.PinnedMemoryBuffer)
            ),
        ),
        DESCRIPTOR=_MODELOPTIMIZATIONPOLICY,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy)
    ),
)
_sym_db.RegisterMessage(ModelOptimizationPolicy)
_sym_db.RegisterMessage(ModelOptimizationPolicy.Graph)
_sym_db.RegisterMessage(ModelOptimizationPolicy.Cuda)
_sym_db.RegisterMessage(ModelOptimizationPolicy.Cuda.GraphSpec)
_sym_db.RegisterMessage(ModelOptimizationPolicy.Cuda.GraphSpec.Shape)
_sym_db.RegisterMessage(ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound)
_sym_db.RegisterMessage(ModelOptimizationPolicy.Cuda.GraphSpec.LowerBound.InputEntry)
_sym_db.RegisterMessage(ModelOptimizationPolicy.Cuda.GraphSpec.InputEntry)
_sym_db.RegisterMessage(ModelOptimizationPolicy.ExecutionAccelerators)
_sym_db.RegisterMessage(ModelOptimizationPolicy.ExecutionAccelerators.Accelerator)
_sym_db.RegisterMessage(ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.ParametersEntry)
_sym_db.RegisterMessage(ModelOptimizationPolicy.PinnedMemoryBuffer)

ModelQueuePolicy = _reflection.GeneratedProtocolMessageType(
    "ModelQueuePolicy",
    (_message.Message,),
    dict(
        DESCRIPTOR=_MODELQUEUEPOLICY,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelQueuePolicy)
    ),
)
_sym_db.RegisterMessage(ModelQueuePolicy)

ModelDynamicBatching = _reflection.GeneratedProtocolMessageType(
    "ModelDynamicBatching",
    (_message.Message,),
    dict(
        PriorityQueuePolicyEntry=_reflection.GeneratedProtocolMessageType(
            "PriorityQueuePolicyEntry",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELDYNAMICBATCHING_PRIORITYQUEUEPOLICYENTRY,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelDynamicBatching.PriorityQueuePolicyEntry)
            ),
        ),
        DESCRIPTOR=_MODELDYNAMICBATCHING,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelDynamicBatching)
    ),
)
_sym_db.RegisterMessage(ModelDynamicBatching)
_sym_db.RegisterMessage(ModelDynamicBatching.PriorityQueuePolicyEntry)

ModelSequenceBatching = _reflection.GeneratedProtocolMessageType(
    "ModelSequenceBatching",
    (_message.Message,),
    dict(
        Control=_reflection.GeneratedProtocolMessageType(
            "Control",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELSEQUENCEBATCHING_CONTROL,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelSequenceBatching.Control)
            ),
        ),
        ControlInput=_reflection.GeneratedProtocolMessageType(
            "ControlInput",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELSEQUENCEBATCHING_CONTROLINPUT,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelSequenceBatching.ControlInput)
            ),
        ),
        StrategyDirect=_reflection.GeneratedProtocolMessageType(
            "StrategyDirect",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELSEQUENCEBATCHING_STRATEGYDIRECT,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelSequenceBatching.StrategyDirect)
            ),
        ),
        StrategyOldest=_reflection.GeneratedProtocolMessageType(
            "StrategyOldest",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELSEQUENCEBATCHING_STRATEGYOLDEST,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelSequenceBatching.StrategyOldest)
            ),
        ),
        DESCRIPTOR=_MODELSEQUENCEBATCHING,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelSequenceBatching)
    ),
)
_sym_db.RegisterMessage(ModelSequenceBatching)
_sym_db.RegisterMessage(ModelSequenceBatching.Control)
_sym_db.RegisterMessage(ModelSequenceBatching.ControlInput)
_sym_db.RegisterMessage(ModelSequenceBatching.StrategyDirect)
_sym_db.RegisterMessage(ModelSequenceBatching.StrategyOldest)

ModelEnsembling = _reflection.GeneratedProtocolMessageType(
    "ModelEnsembling",
    (_message.Message,),
    dict(
        Step=_reflection.GeneratedProtocolMessageType(
            "Step",
            (_message.Message,),
            dict(
                InputMapEntry=_reflection.GeneratedProtocolMessageType(
                    "InputMapEntry",
                    (_message.Message,),
                    dict(
                        DESCRIPTOR=_MODELENSEMBLING_STEP_INPUTMAPENTRY,
                        __module__="model_config_pb2"
                        # @@protoc_insertion_point(class_scope:inference.ModelEnsembling.Step.InputMapEntry)
                    ),
                ),
                OutputMapEntry=_reflection.GeneratedProtocolMessageType(
                    "OutputMapEntry",
                    (_message.Message,),
                    dict(
                        DESCRIPTOR=_MODELENSEMBLING_STEP_OUTPUTMAPENTRY,
                        __module__="model_config_pb2"
                        # @@protoc_insertion_point(class_scope:inference.ModelEnsembling.Step.OutputMapEntry)
                    ),
                ),
                DESCRIPTOR=_MODELENSEMBLING_STEP,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelEnsembling.Step)
            ),
        ),
        DESCRIPTOR=_MODELENSEMBLING,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelEnsembling)
    ),
)
_sym_db.RegisterMessage(ModelEnsembling)
_sym_db.RegisterMessage(ModelEnsembling.Step)
_sym_db.RegisterMessage(ModelEnsembling.Step.InputMapEntry)
_sym_db.RegisterMessage(ModelEnsembling.Step.OutputMapEntry)

ModelParameter = _reflection.GeneratedProtocolMessageType(
    "ModelParameter",
    (_message.Message,),
    dict(
        DESCRIPTOR=_MODELPARAMETER,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelParameter)
    ),
)
_sym_db.RegisterMessage(ModelParameter)

ModelWarmup = _reflection.GeneratedProtocolMessageType(
    "ModelWarmup",
    (_message.Message,),
    dict(
        Input=_reflection.GeneratedProtocolMessageType(
            "Input",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELWARMUP_INPUT,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelWarmup.Input)
            ),
        ),
        InputsEntry=_reflection.GeneratedProtocolMessageType(
            "InputsEntry",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELWARMUP_INPUTSENTRY,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelWarmup.InputsEntry)
            ),
        ),
        DESCRIPTOR=_MODELWARMUP,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelWarmup)
    ),
)
_sym_db.RegisterMessage(ModelWarmup)
_sym_db.RegisterMessage(ModelWarmup.Input)
_sym_db.RegisterMessage(ModelWarmup.InputsEntry)

ModelOperations = _reflection.GeneratedProtocolMessageType(
    "ModelOperations",
    (_message.Message,),
    dict(
        DESCRIPTOR=_MODELOPERATIONS,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelOperations)
    ),
)
_sym_db.RegisterMessage(ModelOperations)

ModelTransactionPolicy = _reflection.GeneratedProtocolMessageType(
    "ModelTransactionPolicy",
    (_message.Message,),
    dict(
        DESCRIPTOR=_MODELTRANSACTIONPOLICY,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelTransactionPolicy)
    ),
)
_sym_db.RegisterMessage(ModelTransactionPolicy)

ModelConfig = _reflection.GeneratedProtocolMessageType(
    "ModelConfig",
    (_message.Message,),
    dict(
        CcModelFilenamesEntry=_reflection.GeneratedProtocolMessageType(
            "CcModelFilenamesEntry",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELCONFIG_CCMODELFILENAMESENTRY,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelConfig.CcModelFilenamesEntry)
            ),
        ),
        MetricTagsEntry=_reflection.GeneratedProtocolMessageType(
            "MetricTagsEntry",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELCONFIG_METRICTAGSENTRY,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelConfig.MetricTagsEntry)
            ),
        ),
        ParametersEntry=_reflection.GeneratedProtocolMessageType(
            "ParametersEntry",
            (_message.Message,),
            dict(
                DESCRIPTOR=_MODELCONFIG_PARAMETERSENTRY,
                __module__="model_config_pb2"
                # @@protoc_insertion_point(class_scope:inference.ModelConfig.ParametersEntry)
            ),
        ),
        DESCRIPTOR=_MODELCONFIG,
        __module__="model_config_pb2"
        # @@protoc_insertion_point(class_scope:inference.ModelConfig)
    ),
)
_sym_db.RegisterMessage(ModelConfig)
_sym_db.RegisterMessage(ModelConfig.CcModelFilenamesEntry)
_sym_db.RegisterMessage(ModelConfig.MetricTagsEntry)
_sym_db.RegisterMessage(ModelConfig.ParametersEntry)


_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_LOWERBOUND_INPUTENTRY._options = None
_MODELOPTIMIZATIONPOLICY_CUDA_GRAPHSPEC_INPUTENTRY._options = None
_MODELOPTIMIZATIONPOLICY_EXECUTIONACCELERATORS_ACCELERATOR_PARAMETERSENTRY._options = None
_MODELDYNAMICBATCHING_PRIORITYQUEUEPOLICYENTRY._options = None
_MODELENSEMBLING_STEP_INPUTMAPENTRY._options = None
_MODELENSEMBLING_STEP_OUTPUTMAPENTRY._options = None
_MODELWARMUP_INPUTSENTRY._options = None
_MODELCONFIG_CCMODELFILENAMESENTRY._options = None
_MODELCONFIG_METRICTAGSENTRY._options = None
_MODELCONFIG_PARAMETERSENTRY._options = None
# @@protoc_insertion_point(module_scope)
