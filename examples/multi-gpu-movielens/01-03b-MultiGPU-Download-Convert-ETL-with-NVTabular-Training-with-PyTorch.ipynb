{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27bb85bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3120f66",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Multi-GPU with MovieLens: ETL and Training \n",
    "\n",
    "## Overview\n",
    "\n",
    "NVIDIA Merlin is a open source framework to accelerate and scale end-to-end recommender system pipelines on GPU. In this notebook, we use NVTabular, Merlin’s ETL component, to scale feature engineering and pre-processing to multiple GPUs and then perform data-parallel distributed training of a neural network on multiple GPUs with PyTorch, [Horovod](https://horovod.readthedocs.io/en/stable/), and [NCCL](https://developer.nvidia.com/nccl).\n",
    "\n",
    "The pre-requisites for this notebook are to be familiar with NVTabular and its API:\n",
    "- You can read more about NVTabular, its API and specialized dataloaders in [Getting Started with Movielens notebooks](../getting-started-movielens).\n",
    "- You can read more about scaling NVTabular ETL in [Scaling Criteo notebooks](../scaling-criteo).\n",
    "\n",
    "**In this notebook, we will focus only on the new information related to multi-GPU training, so please check out the other notebooks first (if you haven’t already.)**\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "In this notebook, we learn how to scale ETL and deep learning taining to multiple GPUs\n",
    "- Learn to use larger than GPU/host memory datasets for ETL and training\n",
    "- Use multi-GPU or multi node for ETL with NVTabular\n",
    "- Use NVTabular dataloader to accelerate PyTorch pipelines\n",
    "- Scale PyTorch training with Horovod\n",
    "\n",
    "### Dataset\n",
    "\n",
    "In this notebook, we use the [MovieLens25M](https://grouplens.org/datasets/movielens/25m/) dataset. It is popular for recommender systems and is used in academic publications. The dataset contains 25M movie ratings for 62,000 movies given by 162,000 users. Many projects use only the user/item/rating information of MovieLens, but the original dataset provides metadata for the movies, as well.\n",
    "\n",
    "Note: We are using the MovieLens 25M dataset in this example for simplicity, although the dataset is not large enough to require multi-GPU training. However, the functionality demonstrated in this notebook can be easily extended to scale recommender pipelines for larger datasets in the same way.\n",
    "\n",
    "### Tools\n",
    "\n",
    "- [Horovod](https://horovod.readthedocs.io/en/stable/) is a distributed deep learning framework that provides tools for multi-GPU optimization.\n",
    "- The [NVIDIA Collective Communication Library (NCCL)](https://developer.nvidia.com/nccl) provides the underlying GPU-based implementations of the [allgather](https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/usage/operations.html#allgather) and [allreduce](https://docs.nvidia.com/deeplearning/nccl/user-guide/docs/usage/operations.html#allreduce) cross-GPU communication operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d934b",
   "metadata": {},
   "source": [
    "## Download and Convert\n",
    "\n",
    "First, we will download and convert the dataset to Parquet. This section is based on [01-Download-Convert.ipynb](../getting-started-movielens/01-Download-Convert.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff780d1",
   "metadata": {},
   "source": [
    "#### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e21689a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External dependencies\n",
    "import cudf                 # cuDF is an implementation of Pandas-like Dataframe on GPU\n",
    "import time\n",
    "import gc\n",
    "import pathlib\n",
    "import zipfile\n",
    "\n",
    "from urllib import request\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BASE_DIR = './data'\n",
    "\n",
    "zip_path = pathlib.Path(BASE_DIR, 'ml-25m.zip')\n",
    "\n",
    "if not zip_path.exists():\n",
    "    zip_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    request.urlretrieve(\"http://files.grouplens.org/datasets/movielens/ml-25m.zip\", str(zip_path))\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path,\"r\") as zip_ref:\n",
    "        zip_ref.extractall(BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b7d64b",
   "metadata": {},
   "source": [
    "#### Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f83f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = cudf.read_csv(pathlib.Path(BASE_DIR, 'ml-25m', 'movies.csv'))\n",
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "movies = movies.drop('title', axis=1)\n",
    "movies.to_parquet(pathlib.Path(BASE_DIR, 'ml-25m', \"movies_converted.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2eb063",
   "metadata": {},
   "source": [
    "#### Split into train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1b7997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = cudf.read_csv(pathlib.Path(BASE_DIR, 'ml-25m', 'ratings.csv'))\n",
    "ratings = ratings.drop('timestamp', axis=1)\n",
    "train, valid = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "train.to_parquet(pathlib.Path(BASE_DIR, \"train.parquet\"))\n",
    "valid.to_parquet(pathlib.Path(BASE_DIR, \"valid.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a58ea8",
   "metadata": {},
   "source": [
    "## ETL with NVTabular\n",
    "\n",
    "We finished downloading and converting the dataset. We will preprocess and engineer features with NVTabular on multiple GPUs. You can read more\n",
    "- about NVTabular's features and API in [getting-started-movielens/02-ETL-with-NVTabular.ipynb](../getting-started-movielens/02-ETL-with-NVTabular.ipynb).\n",
    "- scaling NVTabular ETL to multiple GPUs [scaling-criteo/02-ETL-with-NVTabular.ipynb](../scaling-criteo/02-ETL-with-NVTabular.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87756fb",
   "metadata": {},
   "source": [
    "#### Deploy a Distributed-Dask Cluster\n",
    "\n",
    "This section is based on [scaling-criteo/02-ETL-with-NVTabular.ipynb](../scaling-criteo/02-ETL-with-NVTabular.ipynb) and [multi-gpu-toy-example/multi-gpu_dask.ipynb](../multi-gpu-toy-example/multi-gpu_dask.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59cdcdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# External Dependencies\n",
    "import cupy as cp\n",
    "import cudf\n",
    "import dask_cudf\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "from dask.utils import parse_bytes\n",
    "from dask.delayed import delayed\n",
    "import rmm\n",
    "\n",
    "# NVTabular\n",
    "import nvtabular as nvt\n",
    "import nvtabular.ops as ops\n",
    "from nvtabular.io import Shuffle\n",
    "from nvtabular.utils import device_mem_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4727271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some information about where to get our data\n",
    "input_path = pathlib.Path(BASE_DIR, \"converted\", \"movielens\")\n",
    "dask_workdir = pathlib.Path(BASE_DIR, \"test_dask\", \"workdir\")\n",
    "output_path = pathlib.Path(BASE_DIR, \"test_dask\", \"output\")\n",
    "stats_path = pathlib.Path(BASE_DIR, \"test_dask\", \"stats\")\n",
    "\n",
    "# Make sure we have a clean worker space for Dask\n",
    "if pathlib.Path.is_dir(dask_workdir):\n",
    "    shutil.rmtree(dask_workdir)\n",
    "dask_workdir.mkdir(parents=True)\n",
    "\n",
    "# Make sure we have a clean stats space for Dask\n",
    "if pathlib.Path.is_dir(stats_path):\n",
    "    shutil.rmtree(stats_path)\n",
    "stats_path.mkdir(parents=True)\n",
    "         \n",
    "# Make sure we have a clean output path\n",
    "if pathlib.Path.is_dir(output_path):\n",
    "    shutil.rmtree(output_path)\n",
    "output_path.mkdir(parents=True)\n",
    "\n",
    "# Get device memory capacity\n",
    "capacity = device_mem_size(kind=\"total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2520125c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:44217</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>125.82 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:44217' processes=2 threads=2, memory=125.82 GiB>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deploy a Single-Machine Multi-GPU Cluster\n",
    "protocol = \"tcp\"             # \"tcp\" or \"ucx\"\n",
    "visible_devices = \"0,1\"      # Delect devices to place workers\n",
    "device_spill_frac = 0.5      # Spill GPU-Worker memory to host at this limit.\n",
    "                             # Reduce if spilling fails to prevent\n",
    "                             # device memory errors.\n",
    "cluster = None               # (Optional) Specify existing scheduler port\n",
    "if cluster is None:\n",
    "    cluster = LocalCUDACluster(\n",
    "        protocol = protocol,\n",
    "        CUDA_VISIBLE_DEVICES = visible_devices,\n",
    "        local_directory = dask_workdir,\n",
    "        device_memory_limit = capacity * device_spill_frac,\n",
    "    )\n",
    "\n",
    "# Create the distributed client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8897caaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tcp://127.0.0.1:35297': None, 'tcp://127.0.0.1:36901': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize RMM pool on ALL workers\n",
    "def _rmm_pool():\n",
    "    rmm.reinitialize(\n",
    "        pool_allocator=True,\n",
    "        initial_pool_size=None, # Use default size\n",
    "    )\n",
    "    \n",
    "client.run(_rmm_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68600ce4",
   "metadata": {},
   "source": [
    "#### Defining our Preprocessing Pipeline\n",
    "\n",
    "This subsection is based on [getting-started-movielens/02-ETL-with-NVTabular.ipynb](../getting-started-movielens/02-ETL-with-NVTabular.ipynb). The only difference is that we initialize the NVTabular workflow using the LocalCUDACluster client with `nvt.Workflow(output, client=client)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e490f957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/envs/merlin/lib/python3.8/site-packages/distributed/worker.py:3560: UserWarning: Large object of size 1.90 MiB detected in task graph: \n",
      "  (\"('read-parquet-322a7f02a9ed43406a0eb4f7826bb419' ... eb4f7826bb419')\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "movies= cudf.read_parquet(pathlib.Path(BASE_DIR, \"ml-25m\", \"movies_converted.parquet\"))\n",
    "joined = (\n",
    "    ['userId', 'movieId'] >> \n",
    "    nvt.ops.JoinExternal(movies, on=['movieId'])\n",
    ")\n",
    "cat_features = joined >> nvt.ops.Categorify()\n",
    "ratings = nvt.ColumnGroup(['rating']) >> (lambda col: (col>3).astype('int8'))\n",
    "output = cat_features+ratings\n",
    "# USE client in NVTabular workfow\n",
    "workflow = nvt.Workflow(output, client=client)\n",
    "!rm -rf $BASE_DIR/train\n",
    "!rm -rf $BASE_DIR/valid\n",
    "train_iter = nvt.Dataset([str(pathlib.Path(BASE_DIR, \"train.parquet\"))], part_size=\"100MB\")\n",
    "valid_iter = nvt.Dataset([str(pathlib.Path(BASE_DIR, \"valid.parquet\"))], part_size=\"100MB\")\n",
    "workflow.fit(train_iter)\n",
    "workflow.save(pathlib.Path(BASE_DIR, \"workflow\"))\n",
    "shuffle = Shuffle.PER_WORKER  # Shuffle algorithm\n",
    "out_files_per_proc = 4        # Number of output files per worker\n",
    "workflow.transform(train_iter).to_parquet(\n",
    "    output_path=pathlib.Path(BASE_DIR, \"train\"),\n",
    "    shuffle=shuffle,\n",
    "    out_files_per_proc=out_files_per_proc,\n",
    ")\n",
    "workflow.transform(valid_iter).to_parquet(\n",
    "    output_path=pathlib.Path(BASE_DIR, \"valid\"),\n",
    "    shuffle=shuffle,\n",
    "    out_files_per_proc=out_files_per_proc,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c405d4",
   "metadata": {},
   "source": [
    "## Training with PyTorch on multiGPUs\n",
    "\n",
    "In this section, we will train a PyTorch model with multi-GPU support. In the NVTabular v0.5 release, we added multi-GPU support for NVTabular dataloaders. We will modify the [getting-started-movielens/03a-Training-with-PyTorch.ipynb](../getting-started-movielens/03a-Training-with-PyTorch.ipynb) to use multiple GPUs. Please review that notebook, if you have questions about the general functionality of the NVTabular dataloaders or the neural network architecture.\n",
    "\n",
    "#### NVTabular dataloader for PyTorch\n",
    "\n",
    "We’ve identified that the dataloader is one bottleneck in deep learning recommender systems when training pipelines with PyTorch. The normal PyTorch dataloaders cannot prepare the next training batches fast enough and therefore, the GPU is not fully utilized. \n",
    "\n",
    "We developed a highly customized tabular dataloader for accelerating existing pipelines in PyTorch. In our experiments, we see a speed-up by 9x of the same training workflow with NVTabular dataloader. NVTabular dataloader’s features are:\n",
    "- removing bottleneck of item-by-item dataloading\n",
    "- enabling larger than memory dataset by streaming from disk\n",
    "- reading data directly into GPU memory and remove CPU-GPU communication\n",
    "- preparing batch asynchronously in GPU to avoid CPU-GPU communication\n",
    "- supporting commonly used .parquet format\n",
    "- easy integration into existing PyTorch pipelines by using similar API\n",
    "- **supporting multi-GPU training with Horovod**\n",
    "\n",
    "You can find more information on the dataloaders in our [blogpost](https://medium.com/nvidia-merlin/training-deep-learning-based-recommender-systems-9x-faster-with-PyTorch-cc5a2572ea49)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ef4df7",
   "metadata": {},
   "source": [
    "#### Using Horovod with PyTorch and NVTabular\n",
    "\n",
    "The training script below is based on [getting-started-movielens/03a-Training-with-PyTorch.ipynb](../getting-started-movielens/03a-Training-with-PyTorch.ipynb), with a few important changes:\n",
    "\n",
    "- We provide several additional parameters to the `KerasSequenceLoader` class, including the total number of workers `hvd.size()`, the current worker's id number `hvd.rank()`, and a function for generating random seeds `seed_fn()`. \n",
    "\n",
    "```python\n",
    "    train_dataset_torch = KerasSequenceLoader(\n",
    "        ...\n",
    "        global_size=hvd.size(),\n",
    "        global_rank=hvd.rank(),\n",
    "        seed_fn=seed_fn,\n",
    "    )\n",
    "\n",
    "```\n",
    "- The seed function uses Horovod to collectively generate a random seed that's shared by all workers so that they can each shuffle the dataset in a consistent way and select partitions to work on without overlap. The seed function is called by the dataloader during the shuffling process at the beginning of each epoch:\n",
    "\n",
    "```python\n",
    "    def seed_fn():\n",
    "        min_int, max_int = torch.int32.limits\n",
    "        max_rand = max_int // hvd.size()\n",
    "\n",
    "        # Generate a seed fragment on each worker\n",
    "        seed_fragment = cupy.random.randint(0, max_rand).get()\n",
    "\n",
    "        # Aggregate seed fragments from all Horovod workers\n",
    "        seed_tensor = torch.constant(seed_fragment)\n",
    "        reduced_seed = hvd.allreduce(seed_tensor, name=\"shuffle_seed\", op=hvd.mpi_ops.Sum) \n",
    "\n",
    "        return reduced_seed % max_rand\n",
    "```\n",
    "\n",
    "- We wrap the PyTorch optimizer with Horovod's `DistributedOptimizer` class and scale the learning rate by the number of workers:\n",
    "\n",
    "```python\n",
    "    opt = torch.keras.optimizers.SGD(0.01 * hvd.size())\n",
    "    opt = hvd.DistributedOptimizer(opt)\n",
    "```\n",
    "\n",
    "- We wrap the PyTorch gradient tape with Horovod's `DistributedGradientTape` class:\n",
    "\n",
    "```python\n",
    "    with torch.GradientTape() as tape:\n",
    "        ...\n",
    "    tape = hvd.DistributedGradientTape(tape, sparse_as_dense=True)\n",
    "```\n",
    "\n",
    "- After the first batch, we broadcast the model and optimizer parameters to all workers with Horovod:\n",
    "\n",
    "```python\n",
    "    # Note: broadcast should be done after the first gradient step to\n",
    "    # ensure optimizer initialization.\n",
    "    if first_batch:\n",
    "        hvd.broadcast_variables(model.variables, root_rank=0)\n",
    "        hvd.broadcast_variables(opt.variables(), root_rank=0)\n",
    "```\n",
    "\n",
    "- We only save checkpoints from the first worker to avoid multiple workers trying to write to the same files:\n",
    "\n",
    "```python\n",
    "    if hvd.rank() == 0:\n",
    "        checkpoint.save(checkpoint_dir)\n",
    "```\n",
    "\n",
    "The rest of the script is the same as the MovieLens example in [getting-started-movielens/03a-Training-with-PyTorch.ipynb](../getting-started-movielens/03a-Training-with-PyTorch.ipynb). In order to run it with Horovod, we first need to write it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35bd70b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile './trainer.py'\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "import cupy\n",
    "import torch\n",
    "\n",
    "import nvtabular as nvt\n",
    "from nvtabular.framework_utils.torch.models import Model\n",
    "from nvtabular.framework_utils.torch.utils import process_epoch\n",
    "from nvtabular.loader.torch import DLDataLoader, TorchAsyncItr\n",
    "\n",
    "# Horovod must be the last import to avoid conflicts\n",
    "import horovod.torch as hvd  # noqa: E402, isort:skip\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Train a multi-gpu model with Torch and Horovod\")\n",
    "parser.add_argument(\"--dir_in\", default=None, help=\"Input directory\")\n",
    "parser.add_argument(\"--batch_size\", default=None, help=\"Batch size\")\n",
    "parser.add_argument(\"--cats\", default=None, help=\"Categorical columns\")\n",
    "parser.add_argument(\"--cats_mh\", default=None, help=\"Categorical multihot columns\")\n",
    "parser.add_argument(\"--conts\", default=None, help=\"Continuous columns\")\n",
    "parser.add_argument(\"--labels\", default=None, help=\"Label columns\")\n",
    "parser.add_argument(\"--epochs\", default=1, help=\"Training epochs\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "hvd.init()\n",
    "\n",
    "gpu_to_use = hvd.local_rank()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(gpu_to_use)\n",
    "\n",
    "\n",
    "BASE_DIR = os.path.expanduser(args.dir_in or \"./data/\")\n",
    "BATCH_SIZE = int(args.batch_size or 16384)  # Batch Size\n",
    "CATEGORICAL_COLUMNS = args.cats or [\"movieId\", \"userId\"]  # Single-hot\n",
    "CATEGORICAL_MH_COLUMNS = args.cats_mh or [\"genres\"]  # Multi-hot\n",
    "NUMERIC_COLUMNS = args.conts or []\n",
    "\n",
    "# Output from ETL-with-NVTabular\n",
    "TRAIN_PATHS = sorted(glob.glob(os.path.join(BASE_DIR, \"train\", \"*.parquet\")))\n",
    "\n",
    "proc = nvt.Workflow.load(os.path.join(BASE_DIR, \"workflow/\"))\n",
    "\n",
    "EMBEDDING_TABLE_SHAPES = nvt.ops.get_embedding_sizes(proc)\n",
    "\n",
    "\n",
    "# TensorItrDataset returns a single batch of x_cat, x_cont, y.\n",
    "def collate_fn(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "# Seed with system randomness (or a static seed)\n",
    "cupy.random.seed(None)\n",
    "\n",
    "\n",
    "def seed_fn():\n",
    "    \"\"\"\n",
    "    Generate consistent dataloader shuffle seeds across workers\n",
    "\n",
    "    Reseeds each worker's dataloader each epoch to get fresh a shuffle\n",
    "    that's consistent across workers.\n",
    "    \"\"\"\n",
    "\n",
    "    max_rand = torch.iinfo(torch.int).max // hvd.size()\n",
    "\n",
    "    # Generate a seed fragment\n",
    "    seed_fragment = cupy.random.randint(0, max_rand)\n",
    "\n",
    "    # Aggregate seed fragments from all Horovod workers\n",
    "    seed_tensor = torch.tensor(seed_fragment)\n",
    "    reduced_seed = hvd.allreduce(seed_tensor, name=\"shuffle_seed\", op=hvd.mpi_ops.Sum) % max_rand\n",
    "\n",
    "    return reduced_seed\n",
    "\n",
    "\n",
    "train_dataset = TorchAsyncItr(\n",
    "    nvt.Dataset(TRAIN_PATHS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    cats=CATEGORICAL_COLUMNS + CATEGORICAL_MH_COLUMNS,\n",
    "    conts=NUMERIC_COLUMNS,\n",
    "    labels=[\"rating\"],\n",
    "    device=gpu_to_use,\n",
    "    global_size=hvd.size(),\n",
    "    global_rank=hvd.rank(),\n",
    "    shuffle=True,\n",
    "    seed_fn=seed_fn,\n",
    ")\n",
    "train_loader = DLDataLoader(\n",
    "    train_dataset, batch_size=None, collate_fn=collate_fn, pin_memory=False, num_workers=0\n",
    ")\n",
    "\n",
    "\n",
    "EMBEDDING_TABLE_SHAPES_TUPLE = (\n",
    "    {\n",
    "        CATEGORICAL_COLUMNS[0]: EMBEDDING_TABLE_SHAPES[CATEGORICAL_COLUMNS[0]],\n",
    "        CATEGORICAL_COLUMNS[1]: EMBEDDING_TABLE_SHAPES[CATEGORICAL_COLUMNS[1]],\n",
    "    },\n",
    "    {CATEGORICAL_MH_COLUMNS[0]: EMBEDDING_TABLE_SHAPES[CATEGORICAL_MH_COLUMNS[0]]},\n",
    ")\n",
    "\n",
    "model = Model(\n",
    "    embedding_table_shapes=EMBEDDING_TABLE_SHAPES_TUPLE,\n",
    "    num_continuous=0,\n",
    "    emb_dropout=0.0,\n",
    "    layer_hidden_dims=[128, 128, 128],\n",
    "    layer_dropout_rates=[0.0, 0.0, 0.0],\n",
    ").cuda()\n",
    "\n",
    "lr_scaler = hvd.size()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01 * lr_scaler)\n",
    "\n",
    "hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n",
    "hvd.broadcast_optimizer_state(optimizer, root_rank=0)\n",
    "\n",
    "optimizer = hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters())\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    start = time()\n",
    "    print(f\"Training epoch {epoch}\")\n",
    "    train_loss, y_pred, y = process_epoch(train_loader, model, train=True, optimizer=optimizer)\n",
    "    hvd.join(gpu_to_use)\n",
    "    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n",
    "    print(f\"Epoch {epoch:02d}. Train loss: {train_loss:.4f}.\")\n",
    "    hvd.join(gpu_to_use)\n",
    "    t_final = time() - start\n",
    "    total_rows = train_dataset.num_rows_processed\n",
    "    print(\n",
    "        f\"run_time: {t_final} - rows: {total_rows} - \"\n",
    "        f\"epochs: {epoch} - dl_thru: {total_rows / t_final}\"\n",
    "    )\n",
    "\n",
    "\n",
    "hvd.join(gpu_to_use)\n",
    "if hvd.local_rank() == 0:\n",
    "    print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "320e3500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,0]<stderr>:Traceback (most recent call last):\n",
      "[1,0]<stderr>:  File \"trainer.py\", line 118, in <module>\n",
      "[1,0]<stderr>:    hvd.broadcast_optimizer_state(optimizer, root_rank=0)\n",
      "[1,0]<stderr>:  File \"/conda/envs/merlin/lib/python3.8/site-packages/horovod/torch/functions.py\", line 94, in broadcast_optimizer_state\n",
      "[1,0]<stderr>:    optimizer.step()\n",
      "[1,0]<stderr>:  File \"/conda/envs/merlin/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 89, in wrapper\n",
      "[1,0]<stderr>:    return func(*args, **kwargs)\n",
      "[1,0]<stderr>:  File \"/conda/envs/merlin/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "[1,0]<stderr>:    return func(*args, **kwargs)\n",
      "[1,0]<stderr>:  File \"/conda/envs/merlin/lib/python3.8/site-packages/torch/optim/adam.py\", line 108, in step\n",
      "[1,0]<stderr>:    F.adam(params_with_grad,\n",
      "[1,0]<stderr>:  File \"/conda/envs/merlin/lib/python3.8/site-packages/torch/optim/_functional.py\", line 92, in adam\n",
      "[1,0]<stderr>:    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n",
      "[1,0]<stderr>:RuntimeError: CUDA out of memory. Tried to allocate 318.00 MiB (GPU 0; 10.92 GiB total capacity; 1.78 GiB already allocated; 200.31 MiB free; 1.79 GiB reserved in total by PyTorch)\n",
      "[1,1]<stderr>:Traceback (most recent call last):\n",
      "[1,1]<stderr>:  File \"/conda/envs/merlin/lib/python3.8/site-packages/horovod/torch/mpi_ops.py\", line 847, in synchronize\n",
      "[1,1]<stderr>:    mpi_lib.horovod_torch_wait_and_clear(handle)\n",
      "[1,1]<stderr>:RuntimeError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\n",
      "[1,1]<stderr>:\n",
      "[1,1]<stderr>:During handling of the above exception, another exception occurred:\n",
      "[1,1]<stderr>:\n",
      "[1,1]<stderr>:Traceback (most recent call last):\n",
      "[1,1]<stderr>:  File \"trainer.py\", line 118, in <module>\n",
      "[1,1]<stderr>:    hvd.broadcast_optimizer_state(optimizer, root_rank=0)\n",
      "[1,1]<stderr>:  File \"/conda/envs/merlin/lib/python3.8/site-packages/horovod/torch/functions.py\", line 179, in broadcast_optimizer_state\n",
      "[1,1]<stderr>:    broadcast_parameters(params, root_rank)\n",
      "[1,1]<stderr>:  File \"/conda/envs/merlin/lib/python3.8/site-packages/horovod/torch/functions.py\", line 58, in broadcast_parameters\n",
      "[1,1]<stderr>:    synchronize(handle)\n",
      "[1,1]<stderr>:  File \"/conda/envs/merlin/lib/python3.8/site-packages/horovod/torch/mpi_ops.py\", line 851, in synchronize\n",
      "[1,1]<stderr>:    raise HorovodInternalError(e)\n",
      "[1,1]<stderr>:horovod.common.exceptions.HorovodInternalError: Horovod has been shut down. This was caused by an exception on one of the ranks or an attempt to allreduce, allgather or broadcast a tensor after one of the ranks finished execution. If the shutdown was caused by an exception, you should see the exception in the log before the first shutdown message.\n",
      "--------------------------------------------------------------------------\n",
      "Primary job  terminated normally, but 1 process returned\n",
      "a non-zero exit code. Per user-direction, the job has been aborted.\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "mpirun detected that one or more processes exited with non-zero status, thus causing\n",
      "the job to be terminated. The first process to do so was:\n",
      "\n",
      "  Process name: [[32166,1],0]\n",
      "  Exit code:    1\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np 2 python trainer.py --dir_in $BASE_DIR --batch_size 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d0e25-963c-49a0-a1fc-28d552006e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
