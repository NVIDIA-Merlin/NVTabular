{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "jewish-gentleman",
   "metadata": {},
   "source": [
    "### From Multi-GPU Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comic-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# External Dependencies\n",
    "import cupy as cp\n",
    "import cudf\n",
    "import dask_cudf\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "from dask.utils import parse_bytes\n",
    "from dask.delayed import delayed\n",
    "import rmm\n",
    "\n",
    "# NVTabular\n",
    "import nvtabular as nvt\n",
    "import nvtabular.ops as ops\n",
    "from nvtabular.io import Shuffle\n",
    "from nvtabular.utils import device_mem_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "voluntary-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a \"fast\" root directory for this example\n",
    "BASE_DIR = os.environ.get(\"BASE_DIR\", \"./basedir\")\n",
    "\n",
    "# Define and clean our worker/output directories\n",
    "dask_workdir = os.path.join(BASE_DIR, \"workdir\")\n",
    "demo_output_path = os.path.join(BASE_DIR, \"demo_output\")\n",
    "demo_dataset_path = os.path.join(BASE_DIR, \"demo_dataset\")\n",
    "\n",
    "# Ensure BASE_DIR exists\n",
    "if not os.path.isdir(BASE_DIR):\n",
    "    os.mkdir(BASE_DIR)\n",
    "\n",
    "# Make sure we have a clean worker space for Dask\n",
    "if os.path.isdir(dask_workdir):\n",
    "    shutil.rmtree(dask_workdir)\n",
    "os.mkdir(dask_workdir)\n",
    "\n",
    "# Make sure we have a clean output path\n",
    "if os.path.isdir(demo_output_path):\n",
    "    shutil.rmtree(demo_output_path)\n",
    "os.mkdir(demo_output_path)\n",
    "\n",
    "# Get device memory capacity\n",
    "capacity = device_mem_size(kind=\"total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "environmental-equation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:38039</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>3</li>\n",
       "  <li><b>Memory: </b>135.10 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:38039' processes=3 threads=3, memory=135.10 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deploy a Single-Machine Multi-GPU Cluster\n",
    "protocol = \"tcp\"             # \"tcp\" or \"ucx\"\n",
    "visible_devices = \"0,1,2\"  # Delect devices to place workers\n",
    "device_spill_frac = 0.5      # Spill GPU-Worker memory to host at this limit.\n",
    "                             # Reduce if spilling fails to prevent\n",
    "                             # device memory errors.\n",
    "cluster = None               # (Optional) Specify existing scheduler port\n",
    "if cluster is None:\n",
    "    cluster = LocalCUDACluster(\n",
    "        protocol = protocol,\n",
    "        CUDA_VISIBLE_DEVICES = visible_devices,\n",
    "        local_directory = dask_workdir,\n",
    "        device_memory_limit = capacity * device_spill_frac,\n",
    "    )\n",
    "\n",
    "# Create the distributed client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thorough-operation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tcp://127.0.0.1:33157': None,\n",
       " 'tcp://127.0.0.1:37955': None,\n",
       " 'tcp://127.0.0.1:38567': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize RMM pool on ALL workers\n",
    "def _rmm_pool():\n",
    "    rmm.reinitialize(\n",
    "        pool_allocator=True,\n",
    "        initial_pool_size=None, # Use default size\n",
    "    )\n",
    "    \n",
    "client.run(_rmm_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-chase",
   "metadata": {},
   "source": [
    "### From Getting Started MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-coach",
   "metadata": {},
   "source": [
    "#### Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "psychological-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External dependencies\n",
    "import os\n",
    "import cudf                 # cuDF is an implementation of Pandas-like Dataframe on GPU\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cubic-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collect-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.exists(BASE_DIR + 'ml-25m'):\n",
    "    os.makedirs(BASE_DIR, exist_ok=True)\n",
    "    zip_path = os.path.join(BASE_DIR, 'ml-25m.zip')\n",
    "    if not path.exists(zip_path):\n",
    "        os.system(\"mkdir -p \" + BASE_DIR)\n",
    "        os.system(\"wget http://files.grouplens.org/datasets/movielens/ml-25m.zip\")\n",
    "        os.system(\"mv ml-25m.zip \" + BASE_DIR)\n",
    "    \n",
    "    os.system(\"unzip \" + zip_path + \" -d \" + BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-pendant",
   "metadata": {},
   "source": [
    "#### Convert the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "earned-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = cudf.read_csv(os.path.join(BASE_DIR, 'ml-25m/movies.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "educational-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "movies = movies.drop('title', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "discrete-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.to_parquet(os.path.join(BASE_DIR, \"ml-25m\", \"movies_converted.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-tuesday",
   "metadata": {},
   "source": [
    "#### Splitting into train and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "common-handling",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = cudf.read_csv(os.path.join(BASE_DIR, \"ml-25m\", \"ratings.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "necessary-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.drop('timestamp', axis=1)\n",
    "train, valid = train_test_split(ratings, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "least-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = (\n",
    "    ['userId', 'movieId'] >> \n",
    "    nvt.ops.JoinExternal(movies, on=['movieId'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "painted-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(os.path.join(BASE_DIR, \"train.parquet\"))\n",
    "valid.to_parquet(os.path.join(BASE_DIR, \"valid.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-supplier",
   "metadata": {},
   "source": [
    "### ETL with NVTabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "novel-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies= cudf.read_parquet(os.path.join(BASE_DIR, \"ml-25m\", \"movies_converted.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-society",
   "metadata": {},
   "source": [
    "#### Defining our Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "resistant-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = joined >> nvt.ops.Categorify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "black-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = nvt.ColumnGroup(['rating']) >> (lambda col: (col>3).astype('int8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "threatened-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cat_features+ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "improving-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL NOW USES THE DASK CLUSTER CLIENT CREATED ABOVE\n",
    "workflow = nvt.Workflow(output, client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-boston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "first-effectiveness",
   "metadata": {},
   "source": [
    "#### Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pretty-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r $BASE_DIR/train\n",
    "!rm -r $BASE_DIR/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "incredible-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = nvt.Dataset([os.path.join(BASE_DIR, \"train.parquet\")], part_size=\"100MB\")\n",
    "valid_iter = nvt.Dataset([os.path.join(BASE_DIR, \"valid.parquet\")], part_size=\"100MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "damaged-siemens",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/distributed/worker.py:3451: UserWarning: Large object of size 1.99 MB detected in task graph: \n",
      "  (\"('read-parquet-b80b0101737ef3ff0711e012e3b2445e' ... 1e012e3b2445e')\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "workflow.fit(train_iter)\n",
    "workflow.save(os.path.join(BASE_DIR, \"workflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "nuclear-punch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 182 ms, sys: 27.9 ms, total: 210 ms\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "shuffle = Shuffle.PER_WORKER  # Shuffle algorithm\n",
    "out_files_per_proc = 4        # Number of output files per worker\n",
    "workflow.transform(train_iter).to_parquet(\n",
    "    output_path=os.path.join(BASE_DIR, \"train\"),\n",
    "    shuffle=shuffle,\n",
    "    out_files_per_proc=out_files_per_proc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "injured-undergraduate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 106 ms, sys: 1.02 ms, total: 107 ms\n",
      "Wall time: 711 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "shuffle = Shuffle.PER_WORKER  # Shuffle algorithm\n",
    "out_files_per_proc = 4        # Number of output files per worker\n",
    "workflow.transform(valid_iter).to_parquet(\n",
    "    output_path=os.path.join(BASE_DIR, \"valid\"),\n",
    "    shuffle=shuffle,\n",
    "    out_files_per_proc=out_files_per_proc,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-evaluation",
   "metadata": {},
   "source": [
    "#### Checking the pre-processing outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "settled-proof",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['./data/train/0.2d58cf8e6f434baeb73e20752c94bd89.parquet',\n",
       "  './data/train/0.3b7a7e47f6d74a08a5de89a0afea9a7b.parquet',\n",
       "  './data/train/0.57b1368959eb4f4aa2ebc4bdca44c9f5.parquet',\n",
       "  './data/train/1.7f3b8d62b89d4febb2111ac02c288b85.parquet',\n",
       "  './data/train/1.c1b2cb626efa469db9050ffd6ab0b0e3.parquet',\n",
       "  './data/train/1.eef1ad42f18c4831840b6d941ed8f5d4.parquet',\n",
       "  './data/train/2.1b403fb26dbd43569caecdf4cb8c1ce8.parquet',\n",
       "  './data/train/2.28615e85225e42108965df9632839f9a.parquet',\n",
       "  './data/train/2.dd843a4d1aa44c0791f0321962401f06.parquet',\n",
       "  './data/train/3.56a83f9bf947441a99d12374c2a0087f.parquet',\n",
       "  './data/train/3.78e4e1c853c645f798c94062040d1e55.parquet',\n",
       "  './data/train/3.e7990c31c17e4cef967988f40bacb254.parquet'],\n",
       " ['./data/valid/0.40eb916137194b0583c69b653c87cb67.parquet',\n",
       "  './data/valid/0.630a271d81cc4c15980a96029c48714d.parquet',\n",
       "  './data/valid/1.174b8b6418ec44fcb9283cf44b4add68.parquet',\n",
       "  './data/valid/1.c844640f238947dbaf747a9ad3c32e2a.parquet',\n",
       "  './data/valid/2.5610b4751ade40c4ad4a1f8dac59a80e.parquet',\n",
       "  './data/valid/2.b60f958edecd42258fcec703d64b90d8.parquet',\n",
       "  './data/valid/3.1efa4004c2f64359b0390731964ec8ff.parquet',\n",
       "  './data/valid/3.f0dc1febbf16439296b13fe07e35a0e9.parquet'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "TRAIN_PATHS = sorted(glob.glob(os.path.join(BASE_DIR, \"train\", \"*.parquet\")))\n",
    "VALID_PATHS = sorted(glob.glob(os.path.join(BASE_DIR, \"valid\", \"*.parquet\")))\n",
    "TRAIN_PATHS, VALID_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "beneficial-large",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105207</td>\n",
       "      <td>5844</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51304</td>\n",
       "      <td>2677</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13068</td>\n",
       "      <td>3923</td>\n",
       "      <td>[3, 6, 7]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43489</td>\n",
       "      <td>14022</td>\n",
       "      <td>[3, 4, 5, 6, 17]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73912</td>\n",
       "      <td>1172</td>\n",
       "      <td>[2, 3, 20]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId            genres  rating\n",
       "0  105207     5844            [7, 9]       0\n",
       "1   51304     2677            [7, 9]       0\n",
       "2   13068     3923         [3, 6, 7]       1\n",
       "3   43489    14022  [3, 4, 5, 6, 17]       0\n",
       "4   73912     1172        [2, 3, 20]       1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cudf.read_parquet(TRAIN_PATHS[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-opposition",
   "metadata": {},
   "source": [
    "### From Tensorflow Multi-GPU Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "female-whale",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./hvd_wrapper.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile './hvd_wrapper.sh'\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "## Get local process ID from OpenMPI or alternatively from SLURM\n",
    "if [ -z \"${CUDA_VISIBLE_DEVICES:-}\" ]; then\n",
    "    if [ -n \"${OMPI_COMM_WORLD_LOCAL_RANK:-}\" ]; then\n",
    "        LOCAL_RANK=\"${OMPI_COMM_WORLD_LOCAL_RANK}\"\n",
    "    elif [ -n \"${SLURM_LOCALID:-}\" ]; then\n",
    "        LOCAL_RANK=\"${SLURM_LOCALID}\"\n",
    "    fi\n",
    "    export CUDA_VISIBLE_DEVICES=${LOCAL_RANK}\n",
    "fi\n",
    "\n",
    "exec \"$@\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "revised-motion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile './trainer.py'\n",
    "\n",
    "# External dependencies\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cupy\n",
    "\n",
    "# we can control how much memory to give tensorflow with this environment variable\n",
    "# IMPORTANT: make sure you do this before you initialize TF's runtime, otherwise\n",
    "# TF will have claimed all free GPU memory\n",
    "os.environ[\"TF_MEMORY_ALLOCATION\"] = \"0.3\"  # fraction of free memory\n",
    "import horovod.tensorflow as hvd  # noqa: E402\n",
    "import tensorflow as tf  # noqa: E402\n",
    "\n",
    "import nvtabular as nvt  # noqa: E402\n",
    "from nvtabular.framework_utils.tensorflow import layers  # noqa: E402\n",
    "from nvtabular.loader.tensorflow import KerasSequenceLoader  # noqa: E402\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Process some integers.\")\n",
    "parser.add_argument(\"--dir_in\", default=None, help=\"Input directory\")\n",
    "parser.add_argument(\"--b_size\", default=None, help=\"batch size\")\n",
    "parser.add_argument(\"--cats\", default=None, help=\"categorical columns\")\n",
    "parser.add_argument(\"--cats_mh\", default=None, help=\"categorical multihot columns\")\n",
    "parser.add_argument(\"--conts\", default=None, help=\"continuous columns\")\n",
    "parser.add_argument(\"--labels\", default=None, help=\"continuous columns\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "BASE_DIR = args.dir_in or \"./data/\"\n",
    "BATCH_SIZE = args.b_size or 16384  # Batch Size\n",
    "CATEGORICAL_COLUMNS = args.cats or [\"movieId\", \"userId\"]  # Single-hot\n",
    "CATEGORICAL_MH_COLUMNS = args.cats_mh or [\"genres\"]  # Multi-hot\n",
    "NUMERIC_COLUMNS = args.conts or []\n",
    "TRAIN_PATHS = sorted(\n",
    "    glob.glob(os.path.join(BASE_DIR, \"train/*.parquet\"))\n",
    ")  # Output from ETL-with-NVTabular\n",
    "hvd.init()\n",
    "\n",
    "# Seed with system randomness (or a static seed)\n",
    "cupy.random.seed(None)\n",
    "\n",
    "\n",
    "def seed_fn():\n",
    "    \"\"\"\n",
    "    Generate consistent dataloader shuffle seeds across workers\n",
    "\n",
    "    Reseeds each worker's dataloader each epoch to get fresh a shuffle\n",
    "    that's consistent across workers.\n",
    "    \"\"\"\n",
    "    min_int, max_int = tf.int32.limits\n",
    "    max_rand = max_int // hvd.size()\n",
    "\n",
    "    # Generate a seed fragment\n",
    "    seed_fragment = cupy.random.randint(0, max_rand).get()\n",
    "\n",
    "    # Aggregate seed fragments from all Horovod workers\n",
    "    seed_tensor = tf.constant(seed_fragment)\n",
    "    reduced_seed = hvd.allreduce(seed_tensor, name=\"shuffle_seed\", op=hvd.mpi_ops.Sum) % max_rand\n",
    "\n",
    "    return reduced_seed\n",
    "\n",
    "\n",
    "proc = nvt.Workflow.load(os.path.join(BASE_DIR, \"workflow/\"))\n",
    "EMBEDDING_TABLE_SHAPES = nvt.ops.get_embedding_sizes(proc)\n",
    "\n",
    "train_dataset_tf = KerasSequenceLoader(\n",
    "    TRAIN_PATHS,  # you could also use a glob pattern\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_names=[\"rating\"],\n",
    "    cat_names=CATEGORICAL_COLUMNS + CATEGORICAL_MH_COLUMNS,\n",
    "    cont_names=NUMERIC_COLUMNS,\n",
    "    engine=\"parquet\",\n",
    "    shuffle=True,\n",
    "    seed_fn=seed_fn,\n",
    "    buffer_size=0.06,  # how many batches to load at once\n",
    "    parts_per_chunk=1,\n",
    "    global_size=hvd.size(),\n",
    "    global_rank=hvd.rank(),\n",
    ")\n",
    "inputs = {}  # tf.keras.Input placeholders for each feature to be used\n",
    "emb_layers = []  # output of all embedding layers, which will be concatenated\n",
    "for col in CATEGORICAL_COLUMNS:\n",
    "    inputs[col] = tf.keras.Input(name=col, dtype=tf.int32, shape=(1,))\n",
    "# Note that we need two input tensors for multi-hot categorical features\n",
    "for col in CATEGORICAL_MH_COLUMNS:\n",
    "    inputs[col + \"__values\"] = tf.keras.Input(name=f\"{col}__values\", dtype=tf.int64, shape=(1,))\n",
    "    inputs[col + \"__nnzs\"] = tf.keras.Input(name=f\"{col}__nnzs\", dtype=tf.int64, shape=(1,))\n",
    "for col in CATEGORICAL_COLUMNS + CATEGORICAL_MH_COLUMNS:\n",
    "    emb_layers.append(\n",
    "        tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\n",
    "                col, EMBEDDING_TABLE_SHAPES[col][0]  # Input dimension (vocab size)\n",
    "            ),\n",
    "            EMBEDDING_TABLE_SHAPES[col][1],  # Embedding output dimension\n",
    "        )\n",
    "    )\n",
    "emb_layer = layers.DenseFeatures(emb_layers)\n",
    "x_emb_output = emb_layer(inputs)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x_emb_output)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.SGD(0.01 * hvd.size())\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "checkpoint = tf.train.Checkpoint(model=model, optimizer=opt)\n",
    "\n",
    "\n",
    "@tf.function(experimental_relax_shapes=True)\n",
    "def training_step(examples, labels, first_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        probs = model(examples, training=True)\n",
    "        loss_value = loss(labels, probs)\n",
    "    # Horovod: add Horovod Distributed GradientTape.\n",
    "    tape = hvd.DistributedGradientTape(tape, sparse_as_dense=True)\n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n",
    "    # This is necessary to ensure consistent initialization of all workers when\n",
    "    # training is started with random weights or restored from a checkpoint.\n",
    "    #\n",
    "    # Note: broadcast should be done after the first gradient step to ensure optimizer\n",
    "    # initialization.\n",
    "    if first_batch:\n",
    "        hvd.broadcast_variables(model.variables, root_rank=0)\n",
    "        hvd.broadcast_variables(opt.variables(), root_rank=0)\n",
    "    return loss_value\n",
    "\n",
    "\n",
    "# Horovod: adjust number of steps based on number of GPUs.\n",
    "for batch, (examples, labels) in enumerate(train_dataset_tf):\n",
    "    loss_value = training_step(examples, labels, batch == 0)\n",
    "    if batch % 10 == 0 and hvd.local_rank() == 0:\n",
    "        print(\"Step #%d\\tLoss: %.6f\" % (batch, loss_value))\n",
    "hvd.join()\n",
    "# Horovod: save checkpoints only on worker 0 to prevent other workers from\n",
    "# corrupting it.\n",
    "if hvd.rank() == 0:\n",
    "    checkpoint.save(checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "desperate-rebel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-01 20:21:54.254145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,1]<stderr>:2021-04-01 20:21:56.271981: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,0]<stderr>:2021-04-01 20:21:56.291559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,2]<stderr>:2021-04-01 20:21:56.291559: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,1]<stderr>:2021-04-01 20:21:58.752873: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "[1,1]<stderr>:2021-04-01 20:21:58.753069: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "[1,1]<stderr>:2021-04-01 20:21:58.755666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "[1,1]<stderr>:pciBusID: 0000:41:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,1]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,1]<stderr>:2021-04-01 20:21:58.755710: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,1]<stderr>:2021-04-01 20:21:58.755832: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "[1,1]<stderr>:2021-04-01 20:21:58.755884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "[1,1]<stderr>:2021-04-01 20:21:58.755947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "[1,1]<stderr>:2021-04-01 20:21:58.755995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "[1,1]<stderr>:2021-04-01 20:21:58.756045: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "[1,1]<stderr>:2021-04-01 20:21:58.756092: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "[1,1]<stderr>:2021-04-01 20:21:58.756141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "[1,1]<stderr>:2021-04-01 20:21:58.759794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "[1,0]<stderr>:2021-04-01 20:21:58.879096: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "[1,0]<stderr>:2021-04-01 20:21:58.879275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "[1,0]<stderr>:2021-04-01 20:21:58.880134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "[1,0]<stderr>:pciBusID: 0000:09:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,0]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,0]<stderr>:2021-04-01 20:21:58.880170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,0]<stderr>:2021-04-01 20:21:58.880312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "[1,0]<stderr>:2021-04-01 20:21:58.880360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "[1,0]<stderr>:2021-04-01 20:21:58.880417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "[1,0]<stderr>:2021-04-01 20:21:58.880478: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "[1,0]<stderr>:2021-04-01 20:21:58.880528: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "[1,0]<stderr>:2021-04-01 20:21:58.880572: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "[1,0]<stderr>:2021-04-01 20:21:58.880616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "[1,0]<stderr>:2021-04-01 20:21:58.881966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "[1,2]<stderr>:2021-04-01 20:21:58.897271: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "[1,2]<stderr>:2021-04-01 20:21:58.897408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "[1,2]<stderr>:2021-04-01 20:21:58.898140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "[1,2]<stderr>:pciBusID: 0000:42:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,2]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,2]<stderr>:2021-04-01 20:21:58.898169: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,2]<stderr>:2021-04-01 20:21:58.898274: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "[1,2]<stderr>:2021-04-01 20:21:58.898312: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "[1,2]<stderr>:2021-04-01 20:21:58.898358: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "[1,2]<stderr>:2021-04-01 20:21:58.898393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "[1,2]<stderr>:2021-04-01 20:21:58.898428: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "[1,2]<stderr>:2021-04-01 20:21:58.898462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "[1,2]<stderr>:2021-04-01 20:21:58.898497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "[1,2]<stderr>:2021-04-01 20:21:58.899648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.979010: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.979692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "[1,0]<stderr>:pciBusID: 0000:09:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,0]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.979736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.979748: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.979758: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.979777: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.979788: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.979796: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.979805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.979815: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.980704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.980753: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.980886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.980901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "[1,0]<stderr>:2021-04-01 20:22:00.980908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "[1,0]<stderr>:2021-04-01 20:22:00.982327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5589 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.986666: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 5.46G (5860491264 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.987352: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 4.91G (5274442240 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.988041: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 4.42G (4746997760 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.988902: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 3.98G (4272297984 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.989512: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 3.58G (3845068032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.990146: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 3.22G (3460561152 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "[1,0]<stderr>:2021-04-01 20:22:00.990812: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 2.90G (3114504960 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.014403: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.015250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "[1,2]<stderr>:pciBusID: 0000:42:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,2]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.015308: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.015321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.015331: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.015355: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.015365: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.015373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.015381: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.015391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.016359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.016408: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.016578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.016595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "[1,2]<stderr>:2021-04-01 20:22:01.016602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "[1,2]<stderr>:2021-04-01 20:22:01.018125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5589 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:42:00.0, compute capability: 6.1)\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.024744: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 5.46G (5860491264 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "[1,2]<stderr>:2021-04-01 20:22:01.025521: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 4.91G (5274442240 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.154786: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.155521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "[1,1]<stderr>:pciBusID: 0000:41:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,1]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.155580: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.155604: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.155615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.155635: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.155647: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.155654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.155663: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.155672: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.156581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.156621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.156757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.156773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "[1,1]<stderr>:2021-04-01 20:22:01.156780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "[1,1]<stderr>:2021-04-01 20:22:01.158155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5589 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:41:00.0, compute capability: 6.1)\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.162268: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 5.46G (5860491264 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "[1,1]<stderr>:2021-04-01 20:22:01.162988: I tensorflow/stream_executor/cuda/cuda_driver.cc:789] failed to allocate 4.91G (5274442240 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "[1,0]<stderr>:Traceback (most recent call last):\n",
      "[1,0]<stderr>:  File \"trainer.py\", line 135, in <module>\n",
      "[1,0]<stderr>:    for batch, (examples, labels) in enumerate(train_dataset_tf):\n",
      "[1,0]<stderr>:  File \"/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 483, in __iter__\n",
      "[1,0]<stderr>:    for item in (self[i] for i in range(len(self))):\n",
      "[1,0]<stderr>:  File \"/nvtabular/nvtabular/loader/tensorflow.py\", line 241, in __len__\n",
      "[1,0]<stderr>:    return DataLoader.__len__(self)\n",
      "[1,0]<stderr>:  File \"/nvtabular/nvtabular/loader/backend.py\", line 205, in __len__\n",
      "[1,0]<stderr>:    return _num_steps(len(self._buff), self.batch_size)\n",
      "[1,0]<stderr>:  File \"/nvtabular/nvtabular/loader/backend.py\", line 63, in __len__\n",
      "[1,0]<stderr>:    return len(self.itr)\n",
      "[1,0]<stderr>:  File \"/nvtabular/nvtabular/io/dataset.py\", line 879, in __len__\n",
      "[1,0]<stderr>:    return len(self._ddf.partitions[self.indices])\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/dataframe/core.py\", line 3656, in __len__\n",
      "[1,0]<stderr>:    return len(s)\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/dataframe/core.py\", line 557, in __len__\n",
      "[1,0]<stderr>:    return self.reduction(\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/base.py\", line 283, in compute\n",
      "[1,0]<stderr>:    (result,) = compute(self, traverse=False, **kwargs)\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/base.py\", line 565, in compute\n",
      "[1,0]<stderr>:    results = schedule(dsk, keys, **kwargs)\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/threaded.py\", line 76, in get\n",
      "[1,0]<stderr>:    results = get_async(\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/local.py\", line 487, in get_async\n",
      "[1,0]<stderr>:    raise_exception(exc, tb)\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/local.py\", line 317, in reraise\n",
      "[1,0]<stderr>:    raise exc\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/local.py\", line 222, in execute_task\n",
      "[1,0]<stderr>:    result = _execute_task(task, data)\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in _execute_task\n",
      "[1,0]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in <genexpr>\n",
      "[1,0]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 115, in _execute_task\n",
      "[1,0]<stderr>:    return [_execute_task(a, cache) for a in arg]\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 115, in <listcomp>\n",
      "[1,0]<stderr>:    return [_execute_task(a, cache) for a in arg]\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in _execute_task\n",
      "[1,0]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in <genexpr>\n",
      "[1,0]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in _execute_task\n",
      "[1,0]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 383, in read_parquet_part\n",
      "[1,0]<stderr>:    dfs = [\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 384, in <listcomp>\n",
      "[1,0]<stderr>:    func(fs, rg, columns.copy(), index, **toolz.merge(kwargs, kw))\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask_cudf/io/parquet.py\", line 61, in read_partition\n",
      "[1,0]<stderr>:    df = cudf.read_parquet(\n",
      "[1,0]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/io/parquet.py\", line 251, in read_parquet\n",
      "[1,0]<stderr>:    return libparquet.read_parquet(\n",
      "[1,0]<stderr>:  File \"cudf/_lib/parquet.pyx\", line 107, in cudf._lib.parquet.read_parquet\n",
      "[1,0]<stderr>:  File \"cudf/_lib/parquet.pyx\", line 157, in cudf._lib.parquet.read_parquet\n",
      "[1,0]<stderr>:MemoryError: std::bad_alloc: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory\n",
      "[1,2]<stderr>:Traceback (most recent call last):\n",
      "[1,2]<stderr>:  File \"trainer.py\", line 135, in <module>\n",
      "[1,2]<stderr>:    for batch, (examples, labels) in enumerate(train_dataset_tf):\n",
      "[1,2]<stderr>:  File \"/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 483, in __iter__\n",
      "[1,2]<stderr>:    for item in (self[i] for i in range(len(self))):\n",
      "[1,2]<stderr>:  File \"/nvtabular/nvtabular/loader/tensorflow.py\", line 241, in __len__\n",
      "[1,2]<stderr>:    return DataLoader.__len__(self)\n",
      "[1,2]<stderr>:  File \"/nvtabular/nvtabular/loader/backend.py\", line 205, in __len__\n",
      "[1,2]<stderr>:    return _num_steps(len(self._buff), self.batch_size)\n",
      "[1,2]<stderr>:  File \"/nvtabular/nvtabular/loader/backend.py\", line 63, in __len__\n",
      "[1,2]<stderr>:    return len(self.itr)\n",
      "[1,2]<stderr>:  File \"/nvtabular/nvtabular/io/dataset.py\", line 879, in __len__\n",
      "[1,2]<stderr>:    return len(self._ddf.partitions[self.indices])\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/dataframe/core.py\", line 3656, in __len__\n",
      "[1,2]<stderr>:    return len(s)\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/dataframe/core.py\", line 557, in __len__\n",
      "[1,2]<stderr>:    return self.reduction(\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/base.py\", line 283, in compute\n",
      "[1,2]<stderr>:    (result,) = compute(self, traverse=False, **kwargs)\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/base.py\", line 565, in compute\n",
      "[1,2]<stderr>:    results = schedule(dsk, keys, **kwargs)\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/threaded.py\", line 76, in get\n",
      "[1,2]<stderr>:    results = get_async(\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/local.py\", line 487, in get_async\n",
      "[1,2]<stderr>:    raise_exception(exc, tb)\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/local.py\", line 317, in reraise\n",
      "[1,2]<stderr>:    raise exc\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/local.py\", line 222, in execute_task\n",
      "[1,2]<stderr>:    result = _execute_task(task, data)\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in _execute_task\n",
      "[1,2]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in <genexpr>\n",
      "[1,2]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 115, in _execute_task\n",
      "[1,2]<stderr>:    return [_execute_task(a, cache) for a in arg]\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 115, in <listcomp>\n",
      "[1,2]<stderr>:    return [_execute_task(a, cache) for a in arg]\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in _execute_task\n",
      "[1,2]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in <genexpr>\n",
      "[1,2]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in _execute_task\n",
      "[1,2]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 383, in read_parquet_part\n",
      "[1,2]<stderr>:    dfs = [\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 384, in <listcomp>\n",
      "[1,2]<stderr>:    func(fs, rg, columns.copy(), index, **toolz.merge(kwargs, kw))\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask_cudf/io/parquet.py\", line 61, in read_partition\n",
      "[1,2]<stderr>:    df = cudf.read_parquet(\n",
      "[1,2]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/io/parquet.py\", line 251, in read_parquet\n",
      "[1,2]<stderr>:    return libparquet.read_parquet(\n",
      "[1,2]<stderr>:  File \"cudf/_lib/parquet.pyx\", line 107, in cudf._lib.parquet.read_parquet\n",
      "[1,2]<stderr>:  File \"cudf/_lib/parquet.pyx\", line 157, in cudf._lib.parquet.read_parquet\n",
      "[1,2]<stderr>:MemoryError: std::bad_alloc: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory\n",
      "[1,1]<stderr>:Traceback (most recent call last):\n",
      "[1,1]<stderr>:  File \"trainer.py\", line 135, in <module>\n",
      "[1,1]<stderr>:    for batch, (examples, labels) in enumerate(train_dataset_tf):\n",
      "[1,1]<stderr>:  File \"/opt/conda/lib/python3.8/site-packages/tensorflow/python/keras/utils/data_utils.py\", line 483, in __iter__\n",
      "[1,1]<stderr>:    for item in (self[i] for i in range(len(self))):\n",
      "[1,1]<stderr>:  File \"/nvtabular/nvtabular/loader/tensorflow.py\", line 241, in __len__\n",
      "[1,1]<stderr>:    return DataLoader.__len__(self)\n",
      "[1,1]<stderr>:  File \"/nvtabular/nvtabular/loader/backend.py\", line 205, in __len__\n",
      "[1,1]<stderr>:    return _num_steps(len(self._buff), self.batch_size)\n",
      "[1,1]<stderr>:  File \"/nvtabular/nvtabular/loader/backend.py\", line 63, in __len__\n",
      "[1,1]<stderr>:    return len(self.itr)\n",
      "[1,1]<stderr>:  File \"/nvtabular/nvtabular/io/dataset.py\", line 879, in __len__\n",
      "[1,1]<stderr>:    return len(self._ddf.partitions[self.indices])\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/dataframe/core.py\", line 3656, in __len__\n",
      "[1,1]<stderr>:    return len(s)\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/dataframe/core.py\", line 557, in __len__\n",
      "[1,1]<stderr>:    return self.reduction(\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/base.py\", line 283, in compute\n",
      "[1,1]<stderr>:    (result,) = compute(self, traverse=False, **kwargs)\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/base.py\", line 565, in compute\n",
      "[1,1]<stderr>:    results = schedule(dsk, keys, **kwargs)\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/threaded.py\", line 76, in get\n",
      "[1,1]<stderr>:    results = get_async(\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/local.py\", line 487, in get_async\n",
      "[1,1]<stderr>:    raise_exception(exc, tb)\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/local.py\", line 317, in reraise\n",
      "[1,1]<stderr>:    raise exc\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/local.py\", line 222, in execute_task\n",
      "[1,1]<stderr>:    result = _execute_task(task, data)\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in _execute_task\n",
      "[1,1]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in <genexpr>\n",
      "[1,1]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 115, in _execute_task\n",
      "[1,1]<stderr>:    return [_execute_task(a, cache) for a in arg]\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 115, in <listcomp>\n",
      "[1,1]<stderr>:    return [_execute_task(a, cache) for a in arg]\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in _execute_task\n",
      "[1,1]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in <genexpr>\n",
      "[1,1]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/core.py\", line 121, in _execute_task\n",
      "[1,1]<stderr>:    return func(*(_execute_task(a, cache) for a in args))\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 383, in read_parquet_part\n",
      "[1,1]<stderr>:    dfs = [\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 384, in <listcomp>\n",
      "[1,1]<stderr>:    func(fs, rg, columns.copy(), index, **toolz.merge(kwargs, kw))\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/dask_cudf/io/parquet.py\", line 61, in read_partition\n",
      "[1,1]<stderr>:    df = cudf.read_parquet(\n",
      "[1,1]<stderr>:  File \"/opt/conda/envs/rapids/lib/python3.8/site-packages/cudf/io/parquet.py\", line 251, in read_parquet\n",
      "[1,1]<stderr>:    return libparquet.read_parquet(\n",
      "[1,1]<stderr>:  File \"cudf/_lib/parquet.pyx\", line 107, in cudf._lib.parquet.read_parquet\n",
      "[1,1]<stderr>:  File \"cudf/_lib/parquet.pyx\", line 157, in cudf._lib.parquet.read_parquet\n",
      "[1,1]<stderr>:MemoryError: std::bad_alloc: CUDA error at: /opt/conda/envs/rapids/include/rmm/mr/device/cuda_memory_resource.hpp:69: cudaErrorMemoryAllocation out of memory\n",
      "--------------------------------------------------------------------------\n",
      "Primary job  terminated normally, but 1 process returned\n",
      "a non-zero exit code. Per user-direction, the job has been aborted.\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "mpirun detected that one or more processes exited with non-zero status, thus causing\n",
      "the job to be terminated. The first process to do so was:\n",
      "\n",
      "  Process name: [[23076,1],0]\n",
      "  Exit code:    1\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np 3 sh hvd_wrapper.sh python trainer.py --dir_in $BASE_DIR --b_size 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-enforcement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
