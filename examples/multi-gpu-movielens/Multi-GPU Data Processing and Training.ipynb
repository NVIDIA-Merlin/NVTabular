{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "educated-rubber",
   "metadata": {},
   "source": [
    "### From Multi-GPU Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "behavioral-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# External Dependencies\n",
    "import cupy as cp\n",
    "import cudf\n",
    "import dask_cudf\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "from dask.utils import parse_bytes\n",
    "from dask.delayed import delayed\n",
    "import rmm\n",
    "\n",
    "# NVTabular\n",
    "import nvtabular as nvt\n",
    "import nvtabular.ops as ops\n",
    "from nvtabular.io import Shuffle\n",
    "from nvtabular.utils import device_mem_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "capital-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a \"fast\" root directory for this example\n",
    "BASE_DIR = os.environ.get(\"BASE_DIR\", \"./basedir\")\n",
    "\n",
    "# Define and clean our worker/output directories\n",
    "dask_workdir = os.path.join(BASE_DIR, \"workdir\")\n",
    "demo_output_path = os.path.join(BASE_DIR, \"demo_output\")\n",
    "demo_dataset_path = os.path.join(BASE_DIR, \"demo_dataset\")\n",
    "\n",
    "# Ensure BASE_DIR exists\n",
    "if not os.path.isdir(BASE_DIR):\n",
    "    os.mkdir(BASE_DIR)\n",
    "\n",
    "# Make sure we have a clean worker space for Dask\n",
    "if os.path.isdir(dask_workdir):\n",
    "    shutil.rmtree(dask_workdir)\n",
    "os.mkdir(dask_workdir)\n",
    "\n",
    "# Make sure we have a clean output path\n",
    "if os.path.isdir(demo_output_path):\n",
    "    shutil.rmtree(demo_output_path)\n",
    "os.mkdir(demo_output_path)\n",
    "\n",
    "# Get device memory capacity\n",
    "capacity = device_mem_size(kind=\"total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adjustable-diesel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:39879</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>3</li>\n",
       "  <li><b>Memory: </b>135.10 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:39879' processes=3 threads=3, memory=135.10 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deploy a Single-Machine Multi-GPU Cluster\n",
    "protocol = \"tcp\"             # \"tcp\" or \"ucx\"\n",
    "visible_devices = \"0,1,2\"  # Delect devices to place workers\n",
    "device_spill_frac = 0.9      # Spill GPU-Worker memory to host at this limit.\n",
    "                             # Reduce if spilling fails to prevent\n",
    "                             # device memory errors.\n",
    "cluster = None               # (Optional) Specify existing scheduler port\n",
    "if cluster is None:\n",
    "    cluster = LocalCUDACluster(\n",
    "        protocol = protocol,\n",
    "        CUDA_VISIBLE_DEVICES = visible_devices,\n",
    "        local_directory = dask_workdir,\n",
    "        device_memory_limit = capacity * device_spill_frac,\n",
    "    )\n",
    "\n",
    "# Create the distributed client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coupled-driving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tcp://127.0.0.1:40151': None,\n",
       " 'tcp://127.0.0.1:40517': None,\n",
       " 'tcp://127.0.0.1:41995': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize RMM pool on ALL workers\n",
    "def _rmm_pool():\n",
    "    rmm.reinitialize(\n",
    "        pool_allocator=True,\n",
    "        initial_pool_size=None, # Use default size\n",
    "    )\n",
    "    \n",
    "client.run(_rmm_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-humidity",
   "metadata": {},
   "source": [
    "### From Getting Started MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "manufactured-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External dependencies\n",
    "import os\n",
    "import cudf                 # cuDF is an implementation of Pandas-like Dataframe on GPU\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aware-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "inside-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.exists(BASE_DIR + 'ml-25m'):\n",
    "    os.makedirs(BASE_DIR, exist_ok=True)\n",
    "    zip_path = os.path.join(BASE_DIR, 'ml-25m.zip')\n",
    "    if not path.exists(zip_path):\n",
    "        os.system(\"mkdir -p \" + BASE_DIR)\n",
    "        os.system(\"wget http://files.grouplens.org/datasets/movielens/ml-25m.zip\")\n",
    "        os.system(\"mv ml-25m.zip \" + BASE_DIR)\n",
    "    \n",
    "    os.system(\"unzip \" + zip_path + \" -d \" + BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "consolidated-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = cudf.read_csv(os.path.join(BASE_DIR, 'ml-25m/movies.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "downtown-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "movies = movies.drop('title', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "about-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.to_parquet(os.path.join(BASE_DIR, \"ml-25m\", \"movies_converted.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "victorian-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = cudf.read_csv(os.path.join(BASE_DIR, \"ml-25m\", \"ratings.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "nearby-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.drop('timestamp', axis=1)\n",
    "train, valid = train_test_split(ratings, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "blank-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = (\n",
    "    ['userId', 'movieId'] >> \n",
    "    nvt.ops.JoinExternal(movies, on=['movieId'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "colored-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(os.path.join(BASE_DIR, \"train.parquet\"))\n",
    "valid.to_parquet(os.path.join(BASE_DIR, \"valid.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hundred-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies= cudf.read_parquet(os.path.join(BASE_DIR, \"ml-25m\", \"movies_converted.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "union-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = joined >> nvt.ops.Categorify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "driven-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = nvt.ColumnGroup(['rating']) >> (lambda col: (col>3).astype('int8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "relevant-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cat_features+ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "injured-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = nvt.Workflow(output, client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "durable-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.save(os.path.join(BASE_DIR, \"workflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "detected-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r $BASE_DIR/train\n",
    "!rm -r $BASE_DIR/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "general-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = nvt.Dataset([os.path.join(BASE_DIR, \"train.parquet\")], part_size=\"100MB\")\n",
    "valid_iter = nvt.Dataset([os.path.join(BASE_DIR, \"valid.parquet\")], part_size=\"100MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "proprietary-folder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/distributed/worker.py:3451: UserWarning: Large object of size 1.99 MB detected in task graph: \n",
      "  (\"('read-parquet-6a1aed58e3b1e22d8a56519b714c1841' ... 6519b714c1841')\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 639 ms, sys: 163 ms, total: 802 ms\n",
      "Wall time: 5.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "shuffle = Shuffle.PER_WORKER  # Shuffle algorithm\n",
    "out_files_per_proc = 8        # Number of output files per worker\n",
    "workflow.fit_transform(train_iter).to_parquet(\n",
    "    output_path=os.path.join(BASE_DIR, \"train\"),\n",
    "    shuffle=shuffle,\n",
    "    out_files_per_proc=out_files_per_proc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "civic-thought",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 246 ms, sys: 54 ms, total: 300 ms\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "shuffle = Shuffle.PER_WORKER  # Shuffle algorithm\n",
    "out_files_per_proc = 8        # Number of output files per worker\n",
    "workflow.fit_transform(valid_iter).to_parquet(\n",
    "    output_path=os.path.join(BASE_DIR, \"valid\"),\n",
    "    shuffle=shuffle,\n",
    "    out_files_per_proc=out_files_per_proc,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-hometown",
   "metadata": {},
   "source": [
    "### From Tensorflow Multi-GPU Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "furnished-thomson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile './trainer.py'\n",
    "\n",
    "# External dependencies\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cupy\n",
    "\n",
    "# we can control how much memory to give tensorflow with this environment variable\n",
    "# IMPORTANT: make sure you do this before you initialize TF's runtime, otherwise\n",
    "# TF will have claimed all free GPU memory\n",
    "os.environ[\"TF_MEMORY_ALLOCATION\"] = \"0.3\"  # fraction of free memory\n",
    "import horovod.tensorflow as hvd  # noqa: E402\n",
    "import tensorflow as tf  # noqa: E402\n",
    "\n",
    "import nvtabular as nvt  # noqa: E402\n",
    "from nvtabular.framework_utils.tensorflow import layers  # noqa: E402\n",
    "from nvtabular.loader.tensorflow import KerasSequenceLoader  # noqa: E402\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Process some integers.\")\n",
    "parser.add_argument(\"--dir_in\", default=None, help=\"Input directory\")\n",
    "parser.add_argument(\"--b_size\", default=None, help=\"batch size\")\n",
    "parser.add_argument(\"--cats\", default=None, help=\"categorical columns\")\n",
    "parser.add_argument(\"--cats_mh\", default=None, help=\"categorical multihot columns\")\n",
    "parser.add_argument(\"--conts\", default=None, help=\"continuous columns\")\n",
    "parser.add_argument(\"--labels\", default=None, help=\"continuous columns\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "BASE_DIR = args.dir_in or \"./data/\"\n",
    "BATCH_SIZE = args.b_size or 16384  # Batch Size\n",
    "CATEGORICAL_COLUMNS = args.cats or [\"movieId\", \"userId\"]  # Single-hot\n",
    "CATEGORICAL_MH_COLUMNS = args.cats_mh or [\"genres\"]  # Multi-hot\n",
    "NUMERIC_COLUMNS = args.conts or []\n",
    "TRAIN_PATHS = sorted(\n",
    "    glob.glob(os.path.join(BASE_DIR, \"train/*.parquet\"))\n",
    ")  # Output from ETL-with-NVTabular\n",
    "hvd.init()\n",
    "\n",
    "# Seed with system randomness (or a static seed)\n",
    "cupy.random.seed(None)\n",
    "\n",
    "\n",
    "def seed_fn():\n",
    "    \"\"\"\n",
    "    Generate consistent dataloader shuffle seeds across workers\n",
    "\n",
    "    Reseeds each worker's dataloader each epoch to get fresh a shuffle\n",
    "    that's consistent across workers.\n",
    "    \"\"\"\n",
    "    min_int, max_int = tf.int32.limits\n",
    "    max_rand = max_int // hvd.size()\n",
    "\n",
    "    # Generate a seed fragment\n",
    "    seed_fragment = cupy.random.randint(0, max_rand).get()\n",
    "\n",
    "    # Aggregate seed fragments from all Horovod workers\n",
    "    seed_tensor = tf.constant(seed_fragment)\n",
    "    reduced_seed = hvd.allreduce(seed_tensor, name=\"shuffle_seed\", op=hvd.mpi_ops.Sum) % max_rand\n",
    "\n",
    "    return reduced_seed\n",
    "\n",
    "\n",
    "proc = nvt.Workflow.load(os.path.join(BASE_DIR, \"workflow/\"))\n",
    "EMBEDDING_TABLE_SHAPES = nvt.ops.get_embedding_sizes(proc)\n",
    "\n",
    "train_dataset_tf = KerasSequenceLoader(\n",
    "    TRAIN_PATHS,  # you could also use a glob pattern\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_names=[\"rating\"],\n",
    "    cat_names=CATEGORICAL_COLUMNS + CATEGORICAL_MH_COLUMNS,\n",
    "    cont_names=NUMERIC_COLUMNS,\n",
    "    engine=\"parquet\",\n",
    "    shuffle=True,\n",
    "    seed_fn=seed_fn,\n",
    "    buffer_size=0.06,  # how many batches to load at once\n",
    "    parts_per_chunk=1,\n",
    "    global_size=hvd.size(),\n",
    "    global_rank=hvd.rank(),\n",
    ")\n",
    "inputs = {}  # tf.keras.Input placeholders for each feature to be used\n",
    "emb_layers = []  # output of all embedding layers, which will be concatenated\n",
    "for col in CATEGORICAL_COLUMNS:\n",
    "    inputs[col] = tf.keras.Input(name=col, dtype=tf.int32, shape=(1,))\n",
    "# Note that we need two input tensors for multi-hot categorical features\n",
    "for col in CATEGORICAL_MH_COLUMNS:\n",
    "    inputs[col + \"__values\"] = tf.keras.Input(name=f\"{col}__values\", dtype=tf.int64, shape=(1,))\n",
    "    inputs[col + \"__nnzs\"] = tf.keras.Input(name=f\"{col}__nnzs\", dtype=tf.int64, shape=(1,))\n",
    "for col in CATEGORICAL_COLUMNS + CATEGORICAL_MH_COLUMNS:\n",
    "    emb_layers.append(\n",
    "        tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\n",
    "                col, EMBEDDING_TABLE_SHAPES[col][0]  # Input dimension (vocab size)\n",
    "            ),\n",
    "            EMBEDDING_TABLE_SHAPES[col][1],  # Embedding output dimension\n",
    "        )\n",
    "    )\n",
    "emb_layer = layers.DenseFeatures(emb_layers)\n",
    "x_emb_output = emb_layer(inputs)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x_emb_output)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.SGD(0.01 * hvd.size())\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "checkpoint = tf.train.Checkpoint(model=model, optimizer=opt)\n",
    "\n",
    "\n",
    "@tf.function(experimental_relax_shapes=True)\n",
    "def training_step(examples, labels, first_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        probs = model(examples, training=True)\n",
    "        loss_value = loss(labels, probs)\n",
    "    # Horovod: add Horovod Distributed GradientTape.\n",
    "    tape = hvd.DistributedGradientTape(tape, sparse_as_dense=True)\n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n",
    "    # This is necessary to ensure consistent initialization of all workers when\n",
    "    # training is started with random weights or restored from a checkpoint.\n",
    "    #\n",
    "    # Note: broadcast should be done after the first gradient step to ensure optimizer\n",
    "    # initialization.\n",
    "    if first_batch:\n",
    "        hvd.broadcast_variables(model.variables, root_rank=0)\n",
    "        hvd.broadcast_variables(opt.variables(), root_rank=0)\n",
    "    return loss_value\n",
    "\n",
    "\n",
    "# Horovod: adjust number of steps based on number of GPUs.\n",
    "for batch, (examples, labels) in enumerate(train_dataset_tf):\n",
    "    loss_value = training_step(examples, labels, batch == 0)\n",
    "    if batch % 10 == 0 and hvd.local_rank() == 0:\n",
    "        print(\"Step #%d\\tLoss: %.6f\" % (batch, loss_value))\n",
    "hvd.join()\n",
    "# Horovod: save checkpoints only on worker 0 to prevent other workers from\n",
    "# corrupting it.\n",
    "if hvd.rank() == 0:\n",
    "    checkpoint.save(checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "naval-professional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-01 19:18:34.901561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,2]<stderr>:2021-04-01 19:18:36.988226: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,0]<stderr>:2021-04-01 19:18:37.022548: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,1]<stderr>:2021-04-01 19:18:37.051911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,2]<stderr>:2021-04-01 19:18:39.250527: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "[1,2]<stderr>:2021-04-01 19:18:39.250646: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "[1,2]<stderr>:2021-04-01 19:18:39.251473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "[1,2]<stderr>:pciBusID: 0000:09:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,2]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,2]<stderr>:2021-04-01 19:18:39.252112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "[1,2]<stderr>:pciBusID: 0000:41:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,2]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,2]<stderr>:2021-04-01 19:18:39.252756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "[1,2]<stderr>:pciBusID: 0000:42:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,2]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,2]<stderr>:2021-04-01 19:18:39.252786: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,2]<stderr>:2021-04-01 19:18:39.252880: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "[1,2]<stderr>:2021-04-01 19:18:39.252918: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "[1,2]<stderr>:2021-04-01 19:18:39.252962: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "[1,2]<stderr>:2021-04-01 19:18:39.253000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "[1,2]<stderr>:2021-04-01 19:18:39.253038: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "[1,2]<stderr>:2021-04-01 19:18:39.253073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "[1,2]<stderr>:2021-04-01 19:18:39.253109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "[1,2]<stderr>:2021-04-01 19:18:39.256487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2\n",
      "[1,0]<stderr>:2021-04-01 19:18:39.453574: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "[1,0]<stderr>:2021-04-01 19:18:39.453668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "[1,0]<stderr>:2021-04-01 19:18:39.454354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "[1,0]<stderr>:pciBusID: 0000:09:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,0]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,0]<stderr>:2021-04-01 19:18:39.454985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "[1,0]<stderr>:pciBusID: 0000:41:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,0]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,0]<stderr>:2021-04-01 19:18:39.455615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "[1,0]<stderr>:pciBusID: 0000:42:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,0]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,0]<stderr>:2021-04-01 19:18:39.455643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,0]<stderr>:2021-04-01 19:18:39.455739: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "[1,0]<stderr>:2021-04-01 19:18:39.455778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "[1,0]<stderr>:2021-04-01 19:18:39.455822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "[1,0]<stderr>:2021-04-01 19:18:39.455859: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "[1,0]<stderr>:2021-04-01 19:18:39.455896: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "[1,0]<stderr>:2021-04-01 19:18:39.455930: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "[1,0]<stderr>:2021-04-01 19:18:39.455965: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "[1,0]<stderr>:2021-04-01 19:18:39.459270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2\n",
      "[1,1]<stderr>:2021-04-01 19:18:39.598902: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "[1,1]<stderr>:2021-04-01 19:18:39.599008: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "[1,1]<stderr>:2021-04-01 19:18:39.599666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "[1,1]<stderr>:pciBusID: 0000:09:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,1]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,1]<stderr>:2021-04-01 19:18:39.600296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties: \n",
      "[1,1]<stderr>:pciBusID: 0000:41:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,1]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,1]<stderr>:2021-04-01 19:18:39.600979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 2 with properties: \n",
      "[1,1]<stderr>:pciBusID: 0000:42:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "[1,1]<stderr>:coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "[1,1]<stderr>:2021-04-01 19:18:39.601010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "[1,1]<stderr>:2021-04-01 19:18:39.601110: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "[1,1]<stderr>:2021-04-01 19:18:39.601150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
      "[1,1]<stderr>:2021-04-01 19:18:39.601196: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "[1,1]<stderr>:2021-04-01 19:18:39.601233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "[1,1]<stderr>:2021-04-01 19:18:39.601269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "[1,1]<stderr>:2021-04-01 19:18:39.601304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "[1,1]<stderr>:2021-04-01 19:18:39.601339: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "[1,1]<stderr>:2021-04-01 19:18:39.604814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1, 2\n",
      "[1,1]<stderr>:Traceback (most recent call last):\n",
      "[1,1]<stderr>:  File \"trainer.py\", line 92, in <module>\n",
      "[1,1]<stderr>:    tf.feature_column.categorical_column_with_identity(\n",
      "[1,1]<stderr>:  File \"/opt/conda/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 1569, in categorical_column_with_identity\n",
      "[1,1]<stderr>:    raise ValueError(\n",
      "[1,1]<stderr>:ValueError: num_buckets 0 < 1, column_name movieId\n",
      "[1,2]<stderr>:Traceback (most recent call last):\n",
      "[1,2]<stderr>:  File \"trainer.py\", line 92, in <module>\n",
      "[1,2]<stderr>:    tf.feature_column.categorical_column_with_identity(\n",
      "[1,2]<stderr>:  File \"/opt/conda/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 1569, in categorical_column_with_identity\n",
      "[1,2]<stderr>:    raise ValueError(\n",
      "[1,2]<stderr>:ValueError: num_buckets 0 < 1, column_name movieId\n",
      "[1,0]<stderr>:Traceback (most recent call last):\n",
      "[1,0]<stderr>:  File \"trainer.py\", line 92, in <module>\n",
      "[1,0]<stderr>:    tf.feature_column.categorical_column_with_identity(\n",
      "[1,0]<stderr>:  File \"/opt/conda/lib/python3.8/site-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 1569, in categorical_column_with_identity\n",
      "[1,0]<stderr>:    raise ValueError(\n",
      "[1,0]<stderr>:ValueError: num_buckets 0 < 1, column_name movieId\n",
      "--------------------------------------------------------------------------\n",
      "Primary job  terminated normally, but 1 process returned\n",
      "a non-zero exit code. Per user-direction, the job has been aborted.\n",
      "--------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------\n",
      "mpirun detected that one or more processes exited with non-zero status, thus causing\n",
      "the job to be terminated. The first process to do so was:\n",
      "\n",
      "  Process name: [[4234,1],1]\n",
      "  Exit code:    1\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!horovodrun -np 3 python trainer.py --dir_in $BASE_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-dealing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
