{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conscious-appreciation",
   "metadata": {},
   "source": [
    "### From Multi-GPU Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conceptual-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# External Dependencies\n",
    "import cupy as cp\n",
    "import cudf\n",
    "import dask_cudf\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "from dask.utils import parse_bytes\n",
    "from dask.delayed import delayed\n",
    "import rmm\n",
    "\n",
    "# NVTabular\n",
    "import nvtabular as nvt\n",
    "import nvtabular.ops as ops\n",
    "from nvtabular.io import Shuffle\n",
    "from nvtabular.utils import device_mem_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "close-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a \"fast\" root directory for this example\n",
    "BASE_DIR = os.environ.get(\"BASE_DIR\", \"./basedir\")\n",
    "\n",
    "# Define and clean our worker/output directories\n",
    "dask_workdir = os.path.join(BASE_DIR, \"workdir\")\n",
    "demo_output_path = os.path.join(BASE_DIR, \"demo_output\")\n",
    "demo_dataset_path = os.path.join(BASE_DIR, \"demo_dataset\")\n",
    "\n",
    "# Ensure BASE_DIR exists\n",
    "if not os.path.isdir(BASE_DIR):\n",
    "    os.mkdir(BASE_DIR)\n",
    "\n",
    "# Make sure we have a clean worker space for Dask\n",
    "if os.path.isdir(dask_workdir):\n",
    "    shutil.rmtree(dask_workdir)\n",
    "os.mkdir(dask_workdir)\n",
    "\n",
    "# Make sure we have a clean output path\n",
    "if os.path.isdir(demo_output_path):\n",
    "    shutil.rmtree(demo_output_path)\n",
    "os.mkdir(demo_output_path)\n",
    "\n",
    "# Get device memory capacity\n",
    "capacity = device_mem_size(kind=\"total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tired-treatment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:37797</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>3</li>\n",
       "  <li><b>Memory: </b>135.10 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:37797' processes=3 threads=3, memory=135.10 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deploy a Single-Machine Multi-GPU Cluster\n",
    "protocol = \"tcp\"             # \"tcp\" or \"ucx\"\n",
    "visible_devices = \"0,1,2\"  # Delect devices to place workers\n",
    "device_spill_frac = 0.5      # Spill GPU-Worker memory to host at this limit.\n",
    "                             # Reduce if spilling fails to prevent\n",
    "                             # device memory errors.\n",
    "cluster = None               # (Optional) Specify existing scheduler port\n",
    "if cluster is None:\n",
    "    cluster = LocalCUDACluster(\n",
    "        protocol = protocol,\n",
    "        CUDA_VISIBLE_DEVICES = visible_devices,\n",
    "        local_directory = dask_workdir,\n",
    "        device_memory_limit = capacity * device_spill_frac,\n",
    "    )\n",
    "\n",
    "# Create the distributed client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "monthly-delaware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tcp://127.0.0.1:33417': None,\n",
       " 'tcp://127.0.0.1:36923': None,\n",
       " 'tcp://127.0.0.1:38047': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize RMM pool on ALL workers\n",
    "def _rmm_pool():\n",
    "    rmm.reinitialize(\n",
    "        pool_allocator=True,\n",
    "        initial_pool_size=None, # Use default size\n",
    "    )\n",
    "    \n",
    "client.run(_rmm_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-alexander",
   "metadata": {},
   "source": [
    "### From Getting Started MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-lloyd",
   "metadata": {},
   "source": [
    "#### Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "focused-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External dependencies\n",
    "import os\n",
    "import cudf                 # cuDF is an implementation of Pandas-like Dataframe on GPU\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "marked-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "invisible-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.exists(BASE_DIR + 'ml-25m'):\n",
    "    os.makedirs(BASE_DIR, exist_ok=True)\n",
    "    zip_path = os.path.join(BASE_DIR, 'ml-25m.zip')\n",
    "    if not path.exists(zip_path):\n",
    "        os.system(\"mkdir -p \" + BASE_DIR)\n",
    "        os.system(\"wget http://files.grouplens.org/datasets/movielens/ml-25m.zip\")\n",
    "        os.system(\"mv ml-25m.zip \" + BASE_DIR)\n",
    "    \n",
    "    os.system(\"unzip \" + zip_path + \" -d \" + BASE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-turtle",
   "metadata": {},
   "source": [
    "#### Convert the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "approved-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = cudf.read_csv(os.path.join(BASE_DIR, 'ml-25m/movies.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "renewable-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "movies = movies.drop('title', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adult-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.to_parquet(os.path.join(BASE_DIR, \"ml-25m\", \"movies_converted.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-blame",
   "metadata": {},
   "source": [
    "#### Splitting into train and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "electronic-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = cudf.read_csv(os.path.join(BASE_DIR, \"ml-25m\", \"ratings.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "textile-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.drop('timestamp', axis=1)\n",
    "train, valid = train_test_split(ratings, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "expired-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = (\n",
    "    ['userId', 'movieId'] >> \n",
    "    nvt.ops.JoinExternal(movies, on=['movieId'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecological-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet(os.path.join(BASE_DIR, \"train.parquet\"))\n",
    "valid.to_parquet(os.path.join(BASE_DIR, \"valid.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-bench",
   "metadata": {},
   "source": [
    "### ETL with NVTabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "floating-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies= cudf.read_parquet(os.path.join(BASE_DIR, \"ml-25m\", \"movies_converted.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-surgery",
   "metadata": {},
   "source": [
    "#### Defining our Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "effective-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = joined >> nvt.ops.Categorify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "religious-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = nvt.ColumnGroup(['rating']) >> (lambda col: (col>3).astype('int8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ranking-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cat_features+ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "purple-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL NOW USES THE DASK CLUSTER CLIENT CREATED ABOVE\n",
    "workflow = nvt.Workflow(output, client=client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-bride",
   "metadata": {},
   "source": [
    "#### Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pregnant-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r $BASE_DIR/train\n",
    "!rm -r $BASE_DIR/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beautiful-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = nvt.Dataset([os.path.join(BASE_DIR, \"train.parquet\")], part_size=\"100MB\")\n",
    "valid_iter = nvt.Dataset([os.path.join(BASE_DIR, \"valid.parquet\")], part_size=\"100MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "liquid-plane",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/distributed/worker.py:3451: UserWarning: Large object of size 1.99 MB detected in task graph: \n",
      "  (\"('read-parquet-713577a749c799e4ce4c8a2a23dd50ac' ... c8a2a23dd50ac')\n",
      "Consider scattering large objects ahead of time\n",
      "with client.scatter to reduce scheduler burden and \n",
      "keep data on workers\n",
      "\n",
      "    future = client.submit(func, big_data)    # bad\n",
      "\n",
      "    big_future = client.scatter(big_data)     # good\n",
      "    future = client.submit(func, big_future)  # good\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "workflow.fit(train_iter)\n",
    "workflow.save(os.path.join(BASE_DIR, \"workflow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-stand",
   "metadata": {},
   "source": [
    "Here we're shuffling the dataset on each worker and writing out 4 files from each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "square-communication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 183 ms, sys: 32.5 ms, total: 216 ms\n",
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "shuffle = Shuffle.PER_WORKER  # Shuffle algorithm\n",
    "out_files_per_proc = 4        # Number of output files per worker\n",
    "workflow.transform(train_iter).to_parquet(\n",
    "    output_path=os.path.join(BASE_DIR, \"train\"),\n",
    "    shuffle=shuffle,\n",
    "    out_files_per_proc=out_files_per_proc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "light-living",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 97.8 ms, sys: 1.27 ms, total: 99 ms\n",
      "Wall time: 708 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "shuffle = Shuffle.PER_WORKER  # Shuffle algorithm\n",
    "out_files_per_proc = 4        # Number of output files per worker\n",
    "workflow.transform(valid_iter).to_parquet(\n",
    "    output_path=os.path.join(BASE_DIR, \"valid\"),\n",
    "    shuffle=shuffle,\n",
    "    out_files_per_proc=out_files_per_proc,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rental-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutting down the Dask cluster gives back GPU memory and avoids OOMs during training\n",
    "client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-clark",
   "metadata": {},
   "source": [
    "#### Checking the pre-processing outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "affected-father",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['./data/train/0.71f5b4f3543c40fb916e2f789b8982e3.parquet',\n",
       "  './data/train/0.7973a97631e74e199dd7e4cf1abb3506.parquet',\n",
       "  './data/train/0.ed9dee3c56fc49e089603d8284fcf59b.parquet',\n",
       "  './data/train/1.1f3e72d527514af4bd66b9a2774c52a2.parquet',\n",
       "  './data/train/1.2952b738e4f44a5ab7b21f739408a1c2.parquet',\n",
       "  './data/train/1.d204b6fcf3454af08b931987960f45fe.parquet',\n",
       "  './data/train/2.4186a95a8e2f4e2faf60e1491968fb35.parquet',\n",
       "  './data/train/2.4bbf9cbb08914d0a98304cac27d0f10a.parquet',\n",
       "  './data/train/2.cc165bbb45dd467696382945c84af5c5.parquet',\n",
       "  './data/train/3.4b54b48ed61448c2bc7a1d232dddcc11.parquet',\n",
       "  './data/train/3.9b79be9734e74070bba1d8a40ae89779.parquet',\n",
       "  './data/train/3.ba4c640ef7584b9da9c52157d421dc60.parquet'],\n",
       " ['./data/valid/0.3cbfacf4b93145b392e2e0d55de3e6e1.parquet',\n",
       "  './data/valid/0.54e639be9bae4c519edad2b247d10b89.parquet',\n",
       "  './data/valid/1.185e5e29e5734d6ab3325db25c01b1b1.parquet',\n",
       "  './data/valid/1.ee4e1f59b653499c8069851c7da20f6e.parquet',\n",
       "  './data/valid/2.24911d2b400c4772b4eb797849a1ac00.parquet',\n",
       "  './data/valid/2.3c231a520c284c5aa07204f43f53f8d0.parquet',\n",
       "  './data/valid/3.33b83014b39a4e11b631e4f2e440eef2.parquet',\n",
       "  './data/valid/3.3e76c7391f40456bae0e263be09c9676.parquet'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "TRAIN_PATHS = sorted(glob.glob(os.path.join(BASE_DIR, \"train\", \"*.parquet\")))\n",
    "VALID_PATHS = sorted(glob.glob(os.path.join(BASE_DIR, \"valid\", \"*.parquet\")))\n",
    "TRAIN_PATHS, VALID_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "favorite-chick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35215</td>\n",
       "      <td>6091</td>\n",
       "      <td>[6]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84783</td>\n",
       "      <td>1528</td>\n",
       "      <td>[9, 17]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50882</td>\n",
       "      <td>1834</td>\n",
       "      <td>[6, 16]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16797</td>\n",
       "      <td>582</td>\n",
       "      <td>[2, 17]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95436</td>\n",
       "      <td>1184</td>\n",
       "      <td>[12, 17]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId    genres  rating\n",
       "0   35215     6091       [6]       0\n",
       "1   84783     1528   [9, 17]       1\n",
       "2   50882     1834   [6, 16]       0\n",
       "3   16797      582   [2, 17]       0\n",
       "4   95436     1184  [12, 17]       1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cudf.read_parquet(TRAIN_PATHS[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-dating",
   "metadata": {},
   "source": [
    "### From Tensorflow Multi-GPU Training Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-blade",
   "metadata": {},
   "source": [
    "This small wrapper script checks environment variables set by OpenMPI (or Slurm) to see which MPI local rank we'll be assigned, in order to set CUDA_VISIBLE_DEVICES properly for each worker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "corporate-ownership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./hvd_wrapper.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile './hvd_wrapper.sh'\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "## Get local process ID from OpenMPI or alternatively from SLURM\n",
    "if [ -z \"${CUDA_VISIBLE_DEVICES:-}\" ]; then\n",
    "    if [ -n \"${OMPI_COMM_WORLD_LOCAL_RANK:-}\" ]; then\n",
    "        LOCAL_RANK=\"${OMPI_COMM_WORLD_LOCAL_RANK}\"\n",
    "    elif [ -n \"${SLURM_LOCALID:-}\" ]; then\n",
    "        LOCAL_RANK=\"${SLURM_LOCALID}\"\n",
    "    fi\n",
    "    export CUDA_VISIBLE_DEVICES=${LOCAL_RANK}\n",
    "fi\n",
    "\n",
    "exec \"$@\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "stylish-anchor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile './trainer.py'\n",
    "\n",
    "# External dependencies\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cupy\n",
    "\n",
    "# we can control how much memory to give tensorflow with this environment variable\n",
    "# IMPORTANT: make sure you do this before you initialize TF's runtime, otherwise\n",
    "# TF will have claimed all free GPU memory\n",
    "os.environ[\"TF_MEMORY_ALLOCATION\"] = \"0.3\"  # fraction of free memory\n",
    "import horovod.tensorflow as hvd  # noqa: E402\n",
    "import tensorflow as tf  # noqa: E402\n",
    "\n",
    "import nvtabular as nvt  # noqa: E402\n",
    "from nvtabular.framework_utils.tensorflow import layers  # noqa: E402\n",
    "from nvtabular.loader.tensorflow import KerasSequenceLoader  # noqa: E402\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Process some integers.\")\n",
    "parser.add_argument(\"--dir_in\", default=None, help=\"Input directory\")\n",
    "parser.add_argument(\"--b_size\", default=None, help=\"batch size\")\n",
    "parser.add_argument(\"--cats\", default=None, help=\"categorical columns\")\n",
    "parser.add_argument(\"--cats_mh\", default=None, help=\"categorical multihot columns\")\n",
    "parser.add_argument(\"--conts\", default=None, help=\"continuous columns\")\n",
    "parser.add_argument(\"--labels\", default=None, help=\"continuous columns\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "BASE_DIR = args.dir_in or \"./data/\"\n",
    "BATCH_SIZE = int(args.b_size) or 16384  # Batch Size\n",
    "CATEGORICAL_COLUMNS = args.cats or [\"movieId\", \"userId\"]  # Single-hot\n",
    "CATEGORICAL_MH_COLUMNS = args.cats_mh or [\"genres\"]  # Multi-hot\n",
    "NUMERIC_COLUMNS = args.conts or []\n",
    "TRAIN_PATHS = sorted(\n",
    "    glob.glob(os.path.join(BASE_DIR, \"train/*.parquet\"))\n",
    ")  # Output from ETL-with-NVTabular\n",
    "hvd.init()\n",
    "\n",
    "# Seed with system randomness (or a static seed)\n",
    "cupy.random.seed(None)\n",
    "\n",
    "\n",
    "def seed_fn():\n",
    "    \"\"\"\n",
    "    Generate consistent dataloader shuffle seeds across workers\n",
    "\n",
    "    Reseeds each worker's dataloader each epoch to get fresh a shuffle\n",
    "    that's consistent across workers.\n",
    "    \"\"\"\n",
    "    min_int, max_int = tf.int32.limits\n",
    "    max_rand = max_int // hvd.size()\n",
    "\n",
    "    # Generate a seed fragment\n",
    "    seed_fragment = cupy.random.randint(0, max_rand).get()\n",
    "\n",
    "    # Aggregate seed fragments from all Horovod workers\n",
    "    seed_tensor = tf.constant(seed_fragment)\n",
    "    reduced_seed = hvd.allreduce(seed_tensor, name=\"shuffle_seed\", op=hvd.mpi_ops.Sum) % max_rand\n",
    "\n",
    "    return reduced_seed\n",
    "\n",
    "\n",
    "proc = nvt.Workflow.load(os.path.join(BASE_DIR, \"workflow/\"))\n",
    "EMBEDDING_TABLE_SHAPES = nvt.ops.get_embedding_sizes(proc)\n",
    "\n",
    "train_dataset_tf = KerasSequenceLoader(\n",
    "    TRAIN_PATHS,  # you could also use a glob pattern\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_names=[\"rating\"],\n",
    "    cat_names=CATEGORICAL_COLUMNS + CATEGORICAL_MH_COLUMNS,\n",
    "    cont_names=NUMERIC_COLUMNS,\n",
    "    engine=\"parquet\",\n",
    "    shuffle=True,\n",
    "    seed_fn=seed_fn,\n",
    "    buffer_size=0.06,  # how many batches to load at once\n",
    "    parts_per_chunk=1,\n",
    "    global_size=hvd.size(),\n",
    "    global_rank=hvd.rank(),\n",
    ")\n",
    "inputs = {}  # tf.keras.Input placeholders for each feature to be used\n",
    "emb_layers = []  # output of all embedding layers, which will be concatenated\n",
    "for col in CATEGORICAL_COLUMNS:\n",
    "    inputs[col] = tf.keras.Input(name=col, dtype=tf.int32, shape=(1,))\n",
    "# Note that we need two input tensors for multi-hot categorical features\n",
    "for col in CATEGORICAL_MH_COLUMNS:\n",
    "    inputs[col + \"__values\"] = tf.keras.Input(name=f\"{col}__values\", dtype=tf.int64, shape=(1,))\n",
    "    inputs[col + \"__nnzs\"] = tf.keras.Input(name=f\"{col}__nnzs\", dtype=tf.int64, shape=(1,))\n",
    "for col in CATEGORICAL_COLUMNS + CATEGORICAL_MH_COLUMNS:\n",
    "    emb_layers.append(\n",
    "        tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\n",
    "                col, EMBEDDING_TABLE_SHAPES[col][0]  # Input dimension (vocab size)\n",
    "            ),\n",
    "            EMBEDDING_TABLE_SHAPES[col][1],  # Embedding output dimension\n",
    "        )\n",
    "    )\n",
    "emb_layer = layers.DenseFeatures(emb_layers)\n",
    "x_emb_output = emb_layer(inputs)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x_emb_output)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.SGD(0.01 * hvd.size())\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "checkpoint_dir = \"./checkpoints\"\n",
    "checkpoint = tf.train.Checkpoint(model=model, optimizer=opt)\n",
    "\n",
    "\n",
    "@tf.function(experimental_relax_shapes=True)\n",
    "def training_step(examples, labels, first_batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        probs = model(examples, training=True)\n",
    "        loss_value = loss(labels, probs)\n",
    "    # Horovod: add Horovod Distributed GradientTape.\n",
    "    tape = hvd.DistributedGradientTape(tape, sparse_as_dense=True)\n",
    "    grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n",
    "    # This is necessary to ensure consistent initialization of all workers when\n",
    "    # training is started with random weights or restored from a checkpoint.\n",
    "    #\n",
    "    # Note: broadcast should be done after the first gradient step to ensure optimizer\n",
    "    # initialization.\n",
    "    if first_batch:\n",
    "        hvd.broadcast_variables(model.variables, root_rank=0)\n",
    "        hvd.broadcast_variables(opt.variables(), root_rank=0)\n",
    "    return loss_value\n",
    "\n",
    "\n",
    "# Horovod: adjust number of steps based on number of GPUs.\n",
    "for batch, (examples, labels) in enumerate(train_dataset_tf):\n",
    "    loss_value = training_step(examples, labels, batch == 0)\n",
    "    if batch % 100 == 0 and hvd.local_rank() == 0:\n",
    "        print(\"Step #%d\\tLoss: %.6f\" % (batch, loss_value))\n",
    "hvd.join()\n",
    "\n",
    "# Horovod: save checkpoints only on worker 0 to prevent other workers from\n",
    "# corrupting it.\n",
    "if hvd.rank() == 0:\n",
    "    checkpoint.save(checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "!horovodrun -np 3 sh hvd_wrapper.sh python trainer.py --dir_in $BASE_DIR --b_size 1024"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
