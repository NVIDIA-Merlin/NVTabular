{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started Outbrain: Download and Convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outbrain dataset was published in [Kaggle Outbrain click prediction](https://www.kaggle.com/c/outbrain-click-prediction) competition, where the ‘Kagglers’ were challenged to predict on which ads and other forms of sponsored content its global users would click. One of  the top finishers' preprocessing and feature engineering pipeline is taken into consideration here, and this pipeline was restructured using NVTabular and cuDF. The Kaggle Outbrain click prediction challenge datasets can be downloaded from [here](https://www.kaggle.com/c/outbrain-click-prediction/data). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import cupy\n",
    "import cudf\n",
    "import rmm\n",
    "from numba import cuda\n",
    "import numpy as np\n",
    "\n",
    "import nvtabular as nvt\n",
    "from nvtabular.io import Shuffle\n",
    "from nvtabular.ops import Normalize, FillMedian, FillMissing, Categorify, LogOp, JoinExternal, Dropna, LambdaOp, JoinGroupby, HashBucket, TargetEncoding, get_embedding_sizes, Rename\n",
    "from nvtabular.ops.column_similarity import ColumnSimilarity\n",
    "\n",
    "from nvtabular import ColumnGroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set where the dataset should be saved once processed (OUTPUT_BUCKET_FOLDER), as well as where the dataset originally resides (DATA_BUCKET_FOLDER)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_BUCKET_FOLDER = os.environ.get(\"OUTPUT_DATA_DIR\", \"./preprocessed/\")\n",
    "DATA_BUCKET_FOLDER = os.environ.get(\"INPUT_DATA_DIR\", \"/datasets/outbrain/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Our Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we merge the component tables of our dataset into a single data frame, using [cuDF](https://github.com/rapidsai/cudf), which is a GPU DataFrame library for loading, joining, aggregating, filtering, and otherwise manipulating data. We do this because NVTabular applies a workflow to a single table. We also re-initialize managed memory. `rmm.reinitialize()` provides an easy way to initialize RMM (RAPIDS Memory Manager) with specific memory resource options across multiple devices. The reason we re-initialize managed memory here is to allow us to perform memory intensive merge operation. Note that dask-cudf can also be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cudf import read_csv\n",
    "\n",
    "# use managed memory for device memory allocation\n",
    "rmm.reinitialize(managed_memory=True)  \n",
    "\n",
    "# Merge all the CSV files together\n",
    "documents_meta = read_csv(DATA_BUCKET_FOLDER + 'documents_meta.csv', na_values=['\\\\N', ''])\n",
    "merged = (read_csv(DATA_BUCKET_FOLDER+'clicks_train.csv', na_values=['\\\\N', ''])\n",
    "             .merge(read_csv(DATA_BUCKET_FOLDER + 'events.csv', na_values=['\\\\N', '']), on=\"display_id\", how=\"left\", suffixes=('', '_event'))\n",
    "             .merge(read_csv(DATA_BUCKET_FOLDER+'promoted_content.csv', na_values=['\\\\N', '']), on=\"ad_id\", how=\"left\", suffixes=('', '_promo'))\n",
    "             .merge(documents_meta, on=\"document_id\", how=\"left\")\n",
    "             .merge(documents_meta, left_on=\"document_id_promo\", right_on=\"document_id\", how=\"left\", suffixes=('', \"_promo\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into train and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a time-stratified sample to create a validation set that is more recent, and save both our train and validation sets to parquet files to be read by NVTabular. Note that you should run the cell below only once, then save your `train` and `valid` data frames as parquet files. If you want to rerun this notebook you might end up with a different train-validation split each time because samples are drawn from a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a stratified split of the merged dataset into a training/validation dataset\n",
    "merged['day_event'] = (merged['timestamp'] / 1000 / 60 / 60 / 24).astype(int)\n",
    "random_state = cudf.Series(cupy.random.uniform(size=len(merged)))\n",
    "valid_set, train_set = merged.scatter_by_map(((merged.day_event <= 10) & (random_state > 0.2)).astype(int)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>display_id</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>clicked</th>\n",
       "      <th>uuid</th>\n",
       "      <th>document_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>platform</th>\n",
       "      <th>geo_location</th>\n",
       "      <th>document_id_promo</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>advertiser_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>source_id_promo</th>\n",
       "      <th>publisher_id_promo</th>\n",
       "      <th>publish_time_promo</th>\n",
       "      <th>day_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52774</td>\n",
       "      <td>99112</td>\n",
       "      <td>0</td>\n",
       "      <td>528f0b082d474d</td>\n",
       "      <td>1788099</td>\n",
       "      <td>4141173</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US&gt;TX&gt;600</td>\n",
       "      <td>1146355</td>\n",
       "      <td>12918</td>\n",
       "      <td>2722</td>\n",
       "      <td>10345.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>2016-06-13 21:00:00</td>\n",
       "      <td>3445.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64722</td>\n",
       "      <td>155559</td>\n",
       "      <td>0</td>\n",
       "      <td>c8757cadd92f60</td>\n",
       "      <td>1794963</td>\n",
       "      <td>5272727</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US&gt;CA&gt;807</td>\n",
       "      <td>1382920</td>\n",
       "      <td>79</td>\n",
       "      <td>53</td>\n",
       "      <td>1675.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>2016-06-14 00:00:00</td>\n",
       "      <td>3826.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2016-04-29 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9341</td>\n",
       "      <td>240836</td>\n",
       "      <td>0</td>\n",
       "      <td>8abc1ee256a7ae</td>\n",
       "      <td>1783066</td>\n",
       "      <td>645068</td>\n",
       "      <td>3.0</td>\n",
       "      <td>US&gt;MN&gt;702</td>\n",
       "      <td>747296</td>\n",
       "      <td>25854</td>\n",
       "      <td>1809</td>\n",
       "      <td>105.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>2016-06-13 19:00:00</td>\n",
       "      <td>6523.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2015-06-19 09:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11810</td>\n",
       "      <td>137369</td>\n",
       "      <td>0</td>\n",
       "      <td>cdad8696ea0329</td>\n",
       "      <td>1764997</td>\n",
       "      <td>821919</td>\n",
       "      <td>2.0</td>\n",
       "      <td>IN&gt;25</td>\n",
       "      <td>1225363</td>\n",
       "      <td>17657</td>\n",
       "      <td>2988</td>\n",
       "      <td>482.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2016-06-13 12:00:00</td>\n",
       "      <td>11604.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60146</td>\n",
       "      <td>211592</td>\n",
       "      <td>0</td>\n",
       "      <td>cb29e30bcbcaa2</td>\n",
       "      <td>1783281</td>\n",
       "      <td>4826603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>US&gt;CA&gt;807</td>\n",
       "      <td>1535449</td>\n",
       "      <td>24176</td>\n",
       "      <td>2352</td>\n",
       "      <td>6238.0</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2016-06-18 13:00:00</td>\n",
       "      <td>11097.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   display_id   ad_id  clicked            uuid  document_id  timestamp  \\\n",
       "0       52774   99112        0  528f0b082d474d      1788099    4141173   \n",
       "1       64722  155559        0  c8757cadd92f60      1794963    5272727   \n",
       "2        9341  240836        0  8abc1ee256a7ae      1783066     645068   \n",
       "3       11810  137369        0  cdad8696ea0329      1764997     821919   \n",
       "4       60146  211592        0  cb29e30bcbcaa2      1783281    4826603   \n",
       "\n",
       "   platform geo_location  document_id_promo  campaign_id  advertiser_id  \\\n",
       "0       2.0    US>TX>600            1146355        12918           2722   \n",
       "1       2.0    US>CA>807            1382920           79             53   \n",
       "2       3.0    US>MN>702             747296        25854           1809   \n",
       "3       2.0        IN>25            1225363        17657           2988   \n",
       "4       1.0    US>CA>807            1535449        24176           2352   \n",
       "\n",
       "   source_id  publisher_id         publish_time  source_id_promo  \\\n",
       "0    10345.0         440.0  2016-06-13 21:00:00           3445.0   \n",
       "1     1675.0         236.0  2016-06-14 00:00:00           3826.0   \n",
       "2      105.0         206.0  2016-06-13 19:00:00           6523.0   \n",
       "3      482.0          65.0  2016-06-13 12:00:00          11604.0   \n",
       "4     6238.0         740.0  2016-06-18 13:00:00          11097.0   \n",
       "\n",
       "  publisher_id_promo   publish_time_promo  day_event  \n",
       "0               <NA>                 <NA>          0  \n",
       "1               <NA>  2016-04-29 00:00:00          0  \n",
       "2               <NA>  2015-06-19 09:00:00          0  \n",
       "3               <NA>                 <NA>          0  \n",
       "4               <NA>                 <NA>          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the dataset to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = os.path.join(OUTPUT_BUCKET_FOLDER, \"train_gdf.parquet\")\n",
    "valid_filename = os.path.join(OUTPUT_BUCKET_FOLDER, \"valid_gdf.parquet\")\n",
    "train_set.to_parquet(train_filename, compression=None)\n",
    "valid_set.to_parquet(valid_filename, compression=None)\n",
    "merged = train_set = valid_set= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmm.reinitialize(managed_memory=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
