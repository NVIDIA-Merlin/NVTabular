{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nvtabular'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ab4143bbf1ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnvtabular\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnvt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnvtabular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNormalize\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mCategorify\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mLogOp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFillMissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nvtabular'"
     ]
    }
   ],
   "source": [
    "# Dask\n",
    "from dask_cloudprovider.gcp import GCPCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Cloud Platform - NVTabular Criteo Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure dependencies are installed: `pip install gcsfs`, `pip install dask-cloudprovider[gcp]`\n",
    "    \n",
    "Configure credentials (`gcloud auth login`) and set project (`gcloud config set project <project>`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_config = {\n",
    "    # GCP config options\n",
    "    \"projectid\": \"merlin-295819\",\n",
    "    \"zone\": \"us-east1-c\",\n",
    "    \"machine_type\": \"n1-standard-8\",\n",
    "    \"gpu_type\": \"nvidia-tesla-v100\",\n",
    "    \"ngpus\": 1,\n",
    "    \"filesystem_size\": 10000,\n",
    "    \n",
    "    # RAPIDS config options\n",
    "    \"docker_image\": \"nvcr.io/nvidia/nvtabular:0.3\",\n",
    "    \"worker_class\": \"dask_cuda.CUDAWorker\",\n",
    "    \n",
    "    # Dask/Python options\n",
    "    \"n_workers\": 1,\n",
    "    \"env_vars\": {\"EXTRA_PIP_PACKAGES\": \"s3fs\", \"EXTRA_CONDA_PACKAGES\": \"distributed\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the cluster and wait until the 2 GPUs are ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching cluster with the following configuration: \n",
      "  Source Image: projects/ubuntu-os-cloud/global/images/ubuntu-minimal-1804-bionic-v20201014 \n",
      "  Docker Image: rapidsai/rapidsai:cuda11.0-runtime-ubuntu18.04-py3.8 \n",
      "  Machine Type: n1-standard-8 \n",
      "  Filesytsem Size: 10000 \n",
      "  N-GPU Type: 1 nvidia-tesla-v100\n",
      "  Zone: us-east1-c \n",
      "Creating scheduler instance\n",
      "dask-407e2fe8-scheduler\n",
      "\tInternal IP: 10.142.0.12\n",
      "\tExternal IP: 35.243.231.24\n",
      "Waiting for scheduler to run\n",
      "Scheduler is running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/contextlib.py:88: UserWarning: Creating your cluster is taking a surprisingly long time. This is likely due to pending resources. Hang tight! \n",
      "  next(self.gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating worker instance\n",
      "dask-407e2fe8-worker-90d99513\n",
      "\tInternal IP: 10.142.0.13\n",
      "\tExternal IP: 34.75.31.97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2713314c4034cbca8c607c728fa2e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GCPCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    .dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster = GCPCluster(**cluster_config)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/albertoa/.local/lib/python3.6/site-packages/distributed/client.py:1129: VersionMismatchWarning: Mismatched versions found\n",
      "\n",
      "+-------------+--------+-----------+---------+\n",
      "| Package     | client | scheduler | workers |\n",
      "+-------------+--------+-----------+---------+\n",
      "| distributed | 2.30.0 | 2.30.1    | None    |\n",
      "| tornado     | 6.0.4  | 6.1       | None    |\n",
      "+-------------+--------+-----------+---------+\n",
      "  warnings.warn(version_module.VersionMismatchWarning(msg[0][\"warning\"]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://35.243.231.24:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='http://35.243.231.24:8787/status' target='_blank'>http://35.243.231.24:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>1</li>\n",
       "  <li><b>Memory: </b>31.56 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.142.0.12:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(cluster)\n",
    "client.wait_for_workers(1) # because one GPU workers per node\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running NVTabular Criteo Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "concurrent.futures._base.CancelledError\n"
     ]
    }
   ],
   "source": [
    "# Input dataset located in GCS\n",
    "input_path = \"gs://merlin-datasets/crit_int_pq/\"\n",
    "# Output data paths\n",
    "BASE_DIR = \"/tmp/\"\n",
    "dask_workdir = os.path.join(BASE_DIR, \"test_dask/workdir\")\n",
    "output_path = os.path.join(BASE_DIR, \"test_dask/output\")\n",
    "stats_path = os.path.join(BASE_DIR, \"test_dask/stats\")\n",
    "\n",
    "# number of days worth of data to use for training, the rest will be used for validation\n",
    "NUM_DAYS = 24\n",
    "NUM_TRAIN_DAYS = 23\n",
    "\n",
    "# define our dataset schema\n",
    "CONTINUOUS_COLUMNS = ['I' + str(x) for x in range(1,14)]\n",
    "CATEGORICAL_COLUMNS =  ['C' + str(x) for x in range(1,27)]\n",
    "LABEL_COLUMNS = ['label']\n",
    "COLUMNS = CONTINUOUS_COLUMNS + CATEGORICAL_COLUMNS + LABEL_COLUMNS\n",
    "\n",
    "# Make sure we have a clean worker space for Dask\n",
    "if os.path.isdir(dask_workdir):\n",
    "    shutil.rmtree(dask_workdir)\n",
    "os.makedirs(dask_workdir)\n",
    "\n",
    "# Make sure we have a clean stats space for Dask\n",
    "if os.path.isdir(stats_path):\n",
    "    shutil.rmtree(stats_path)\n",
    "os.mkdir(stats_path)\n",
    "         \n",
    "# Make sure we have a clean output path\n",
    "if os.path.isdir(output_path):\n",
    "    shutil.rmtree(output_path)\n",
    "os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validation files\n",
    "fname = 'day_{}.parquet'\n",
    "train_paths = [os.path.join(input_path, fname.format(day)) for day in range(NUM_TRAIN_DAYS)]\n",
    "valid_paths = [os.path.join(input_path, fname.format(day)) for day in range(NUM_TRAIN_DAYS, NUM_DAYS)]\n",
    "print(train_paths)\n",
    "print(valid_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and run Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conts and cats operators\n",
    "cat_features = CATEGORICAL_COLUMNS >> Categorify(freq_threshold=15, out_path=OUTPUT_DATA_DIR)\n",
    "cont_features = CONTINUOUS_COLUMNS >> FillMissing() >> Clip(min_value=0) >> LogOp() >> Normalize()\n",
    "features = cat_features + cont_features + LABEL_COLUMNS\n",
    "\n",
    "# Create Workflow\n",
    "workflow = nvt.Workflow(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data iterators\n",
    "train_dataset = nvt.Dataset(train_paths, engine='parquet', part_size=part_size)\n",
    "valid_dataset = nvt.Dataset(valid_paths, engine='parquet', part_size=part_size)\n",
    "# Create output dirs\n",
    "output_train_dir = os.path.join(output_path, 'train/')\n",
    "output_valid_dir = os.path.join(output_path, 'valid/')\n",
    "! mkdir -p $output_train_dir\n",
    "! mkdir -p $output_valid_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "workflow.transform(train_dataset).to_parquet(output_path=output_train_dir,\n",
    "                                         shuffle=nvt.io.Shuffle.PER_PARTITION, \n",
    "                                         out_files_per_proc=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "workflow.transform(valid_dataset).to_parquet(output_path=output_valid_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the client and cluster so resources in GCP are releasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
