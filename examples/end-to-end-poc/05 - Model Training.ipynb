{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automatic-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cudf\n",
    "\n",
    "import nvtabular as nvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "banner-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin_models.tensorflow.models.retrieval import YouTubeDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "given-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = os.environ.get(\n",
    "    \"INPUT_DATA_DIR\", os.path.expanduser(\"~/nvt-examples/end-to-end-poc/data/\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "starting-dream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sampled_tag</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movieId</th>\n",
       "      <th>movieId_count</th>\n",
       "      <th>target_item</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>4146</th>\n",
       "      <td>[43870, 30243, 31462, 25871, 28458, 44763, 371...</td>\n",
       "      <td>[1147868053, 1147868097, 1147868414, 114786846...</td>\n",
       "      <td>[5952, 1653, 1250, 6539, 6377, 3448, 1088, 899...</td>\n",
       "      <td>52</td>\n",
       "      <td>7361</td>\n",
       "      <td>[6, 6, 3, 6, 17, 9, 16, 3, 9, 2, 3, 6, 10, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>4071</th>\n",
       "      <td>[47665, 65105, 38902, 64349, 1452, 57559, 6574...</td>\n",
       "      <td>[1141415528, 1141415566, 1141415576, 114141558...</td>\n",
       "      <td>[5952, 497, 1374, 1653, 2640, 5445, 151, 236, ...</td>\n",
       "      <td>124</td>\n",
       "      <td>2150</td>\n",
       "      <td>[6, 6, 6, 6, 6, 9, 9, 7, 9, 15, 7, 9, 2, 6, 6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>7521</th>\n",
       "      <td>[21601, 35319, 30185, 10741, 52728, 39667, 661...</td>\n",
       "      <td>[1439472199, 1439472203, 1439472211, 143947221...</td>\n",
       "      <td>[356, 593, 1270, 1, 2571, 260, 318, 1196, 527,...</td>\n",
       "      <td>178</td>\n",
       "      <td>37729</td>\n",
       "      <td>[6, 9, 16, 9, 2, 6, 7, 9, 17, 3, 4, 5, 6, 10, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7688</th>\n",
       "      <td>[28185, 51431, 45744, 50807, 67439, 56292, 467...</td>\n",
       "      <td>[1453904021, 1453904031, 1453904046, 145390404...</td>\n",
       "      <td>[1206, 1208, 44191, 32587, 40815, 36529, 45186...</td>\n",
       "      <td>9</td>\n",
       "      <td>4344</td>\n",
       "      <td>[12, 12, 18, 7, 9, 18, 7, 9, 6, 9, 1, 1, 12, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8045</th>\n",
       "      <td>[15910, 13153, 52882, 41183, 63025, 72409, 107...</td>\n",
       "      <td>[1484753654, 1484753766, 1484753808, 148475384...</td>\n",
       "      <td>[1089, 4011, 741, 778, 111, 214, 293, 1252, 33...</td>\n",
       "      <td>21</td>\n",
       "      <td>27773</td>\n",
       "      <td>[7, 9, 17, 18, 7, 9, 18, 7, 9, 9, 7, 9, 9, 18,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   sampled_tag  \\\n",
       "userId day                                                       \n",
       "1      4146  [43870, 30243, 31462, 25871, 28458, 44763, 371...   \n",
       "2      4071  [47665, 65105, 38902, 64349, 1452, 57559, 6574...   \n",
       "3      7521  [21601, 35319, 30185, 10741, 52728, 39667, 661...   \n",
       "       7688  [28185, 51431, 45744, 50807, 67439, 56292, 467...   \n",
       "       8045  [15910, 13153, 52882, 41183, 63025, 72409, 107...   \n",
       "\n",
       "                                                     timestamp  \\\n",
       "userId day                                                       \n",
       "1      4146  [1147868053, 1147868097, 1147868414, 114786846...   \n",
       "2      4071  [1141415528, 1141415566, 1141415576, 114141558...   \n",
       "3      7521  [1439472199, 1439472203, 1439472211, 143947221...   \n",
       "       7688  [1453904021, 1453904031, 1453904046, 145390404...   \n",
       "       8045  [1484753654, 1484753766, 1484753808, 148475384...   \n",
       "\n",
       "                                                       movieId  movieId_count  \\\n",
       "userId day                                                                      \n",
       "1      4146  [5952, 1653, 1250, 6539, 6377, 3448, 1088, 899...             52   \n",
       "2      4071  [5952, 497, 1374, 1653, 2640, 5445, 151, 236, ...            124   \n",
       "3      7521  [356, 593, 1270, 1, 2571, 260, 318, 1196, 527,...            178   \n",
       "       7688  [1206, 1208, 44191, 32587, 40815, 36529, 45186...              9   \n",
       "       8045  [1089, 4011, 741, 778, 111, 214, 293, 1252, 33...             21   \n",
       "\n",
       "             target_item                                              genre  \n",
       "userId day                                                                   \n",
       "1      4146         7361  [6, 6, 3, 6, 17, 9, 16, 3, 9, 2, 3, 6, 10, 3, ...  \n",
       "2      4071         2150  [6, 6, 6, 6, 6, 9, 9, 7, 9, 15, 7, 9, 2, 6, 6,...  \n",
       "3      7521        37729  [6, 9, 16, 9, 2, 6, 7, 9, 17, 3, 4, 5, 6, 10, ...  \n",
       "       7688         4344  [12, 12, 18, 7, 9, 18, 7, 9, 6, 9, 1, 1, 12, 2...  \n",
       "       8045        27773  [7, 9, 17, 18, 7, 9, 18, 7, 9, 9, 7, 9, 9, 18,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = cudf.read_parquet(os.path.join(INPUT_DATA_DIR, \"grouped_examples.parquet\"))\n",
    "examples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build feature columns for the input features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-testimony",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024  # Batch Size\n",
    "CATEGORICAL_COLUMNS = []  # Single-hot\n",
    "CATEGORICAL_MH_COLUMNS = [\"sampled_tag\", \"movieId\", \"genre\"]  # Multi-hot\n",
    "NUMERIC_COLUMNS = [\"movieId_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Sort out how to get embedding table shapes from workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow = nvt.Workflow.load(os.path.join(INPUT_DATA_DIR, \"workflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING_TABLE_SHAPES, MH_EMBEDDING_TABLE_SHAPES = nvt.ops.get_embedding_sizes(workflow)\n",
    "# EMBEDDING_TABLE_SHAPES.update(MH_EMBEDDING_TABLE_SHAPES)\n",
    "# EMBEDDING_TABLE_SHAPES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-delaware",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Construct a KSL DataLoader to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# we can control how much memory to give tensorflow with this environment variable\n",
    "# IMPORTANT: make sure you do this before you initialize TF's runtime, otherwise\n",
    "# TF will have claimed all free GPU memory\n",
    "os.environ[\"TF_MEMORY_ALLOCATION\"] = \"0.7\"  # fraction of free memory\n",
    "from nvtabular.loader.tensorflow import KerasSequenceLoader, KerasSequenceValidater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_tf = KerasSequenceLoader(\n",
    "    TRAIN_PATHS,  # you could also use a glob pattern\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_names=[\"rating\"],\n",
    "    cat_names=CATEGORICAL_COLUMNS + CATEGORICAL_MH_COLUMNS,\n",
    "    cont_names=NUMERIC_COLUMNS,\n",
    "    engine=\"parquet\",\n",
    "    shuffle=True,\n",
    "    buffer_size=0.06,  # how many batches to load at once\n",
    "    parts_per_chunk=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataset_tf))\n",
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}  # tf.keras.Input placeholders for each feature to be used\n",
    "emb_layers = []  # output of all embedding layers, which will be concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in CATEGORICAL_COLUMNS:\n",
    "    inputs[col] = tf.keras.Input(name=col, dtype=tf.int32, shape=(1,))\n",
    "# Note that we need two input tensors for multi-hot categorical features\n",
    "for col in CATEGORICAL_MH_COLUMNS:\n",
    "    inputs[col + \"__values\"] = tf.keras.Input(name=f\"{col}__values\", dtype=tf.int64, shape=(1,))\n",
    "    inputs[col + \"__nnzs\"] = tf.keras.Input(name=f\"{col}__nnzs\", dtype=tf.int64, shape=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-stuart",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in CATEGORICAL_COLUMNS + CATEGORICAL_MH_COLUMNS:\n",
    "    emb_layers.append(\n",
    "        tf.feature_column.embedding_column(\n",
    "            tf.feature_column.categorical_column_with_identity(\n",
    "                col, EMBEDDING_TABLE_SHAPES[col][0]\n",
    "            ),  # Input dimension (vocab size)\n",
    "            EMBEDDING_TABLE_SHAPES[col][1],  # Embedding output dimension\n",
    "        )\n",
    "    )\n",
    "emb_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add optimizer and other training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "model.compile(\"sgd\", \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_callback = KerasSequenceValidater(valid_dataset_tf)\n",
    "\n",
    "history = model.fit(train_dataset_tf, callbacks=[validation_callback], epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-causing",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME_TF = os.environ.get(\"MODEL_NAME_TF\", \"movielens_tf\")\n",
    "MODEL_PATH_TEMP_TF = os.path.join(MODEL_BASE_DIR, MODEL_NAME_TF, \"1/model.savedmodel\")\n",
    "\n",
    "model.save(MODEL_PATH_TEMP_TF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
