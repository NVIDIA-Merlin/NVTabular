{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4a2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da4cfc5",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# TensorFlow: Using Sparse Features with NVTabular\n",
    "\n",
    "## Sparse Features\n",
    "\n",
    "As the name indicates, `Sparse Features` is a way to represent data, which is very sparse. It means, that many values are 0. TensorFlow provides the functionality to use `tf.sparse.SparseTenors` to provide an optimized representation for deep learning training. This notebok provides an example, how to use data containing `Sparse Features` with NVTabular and TensorFlow.\n",
    "\n",
    "We are using a simple toy example to show the functionality of the workflow. This can scale to much larger examples.\n",
    "\n",
    "### Example of Sparse Features\n",
    "\n",
    "First, let's take a look on what are sparse features.<br><br>\n",
    "\n",
    "For example, the dataset is based on an ecommerce shop and we want to predict, if a customer will purchase a product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1235e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>product</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer  product  purchase\n",
       "0        a        0         0\n",
       "1        a        1         1\n",
       "2        b        0         0\n",
       "3        b        2         0\n",
       "4        c        4         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"customer\": [\"a\", \"a\", \"b\", \"b\", \"c\"], \"product\": [0, 1, 0, 2, 4], \"purchase\": [0, 1, 0, 0, 1]}\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98e8c34",
   "metadata": {},
   "source": [
    "So far, we have no sparse features in the dataset. Let's say, that we want to add an input feature, describing the historical customer rating for every product in the catalog in the last 90 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90c4b9a",
   "metadata": {},
   "source": [
    "Customer a rated product 0 with 2.5, product 4 with 4.0 and product 5 with 5.0<br>\n",
    "Customer b rated product 1 with 1.5, product 7 with 2.0, product 8 with 3.5 and product 9 with 4.0<br>\n",
    "Customer c rated product 3 with 1,0 and product 6 with 4.0\n",
    "\n",
    "This is a sparse representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f8d1712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>product</th>\n",
       "      <th>purchase</th>\n",
       "      <th>customer_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{0: 2.5, 4: 4.0, 5: 5.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 2.5, 4: 4.0, 5: 5.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{1: 1.5, 7: 2.0, 8: 3.5, 9: 4.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>{1: 1.5, 7: 2.0, 8: 3.5, 9: 4.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{3: 1.0, 6: 4.0}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer  product  purchase                  customer_ratings\n",
       "0        a        0         0          {0: 2.5, 4: 4.0, 5: 5.0}\n",
       "1        a        1         1          {0: 2.5, 4: 4.0, 5: 5.0}\n",
       "2        b        0         0  {1: 1.5, 7: 2.0, 8: 3.5, 9: 4.0}\n",
       "3        b        2         0  {1: 1.5, 7: 2.0, 8: 3.5, 9: 4.0}\n",
       "4        c        4         1                  {3: 1.0, 6: 4.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_ratings = [\n",
    "    {0: 2.5, 4: 4.0, 5: 5.0},\n",
    "    {0: 2.5, 4: 4.0, 5: 5.0},\n",
    "    {1: 1.5, 7: 2.0, 8: 3.5, 9: 4.0},\n",
    "    {1: 1.5, 7: 2.0, 8: 3.5, 9: 4.0},\n",
    "    {3: 1.0, 6: 4.0},\n",
    "]\n",
    "df[\"customer_ratings\"] = customer_ratings\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc973066",
   "metadata": {},
   "source": [
    "We can convert the sparse representation to a dense one. Thereby, we create for each example a dense vector with `(rating_1, ... rating_n)`. If a customer has no rated a product yet, we insert it as 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6cb8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>product</th>\n",
       "      <th>purchase</th>\n",
       "      <th>customer_ratings</th>\n",
       "      <th>customer_ratings_dense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{0: 2.5, 4: 4.0, 5: 5.0}</td>\n",
       "      <td>[2.5, 0.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{0: 2.5, 4: 4.0, 5: 5.0}</td>\n",
       "      <td>[2.5, 0.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{1: 1.5, 7: 2.0, 8: 3.5, 9: 4.0}</td>\n",
       "      <td>[0.0, 1.5, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>{1: 1.5, 7: 2.0, 8: 3.5, 9: 4.0}</td>\n",
       "      <td>[0.0, 1.5, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>{3: 1.0, 6: 4.0}</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer  product  purchase                  customer_ratings  \\\n",
       "0        a        0         0          {0: 2.5, 4: 4.0, 5: 5.0}   \n",
       "1        a        1         1          {0: 2.5, 4: 4.0, 5: 5.0}   \n",
       "2        b        0         0  {1: 1.5, 7: 2.0, 8: 3.5, 9: 4.0}   \n",
       "3        b        2         0  {1: 1.5, 7: 2.0, 8: 3.5, 9: 4.0}   \n",
       "4        c        4         1                  {3: 1.0, 6: 4.0}   \n",
       "\n",
       "                              customer_ratings_dense  \n",
       "0  [2.5, 0.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [2.5, 0.0, 0.0, 0.0, 4.0, 5.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 1.5, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.5, ...  \n",
       "3  [0.0, 1.5, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.5, ...  \n",
       "4  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 4.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_dense = 10\n",
    "\n",
    "\n",
    "def sparse_to_dense(x):\n",
    "    dense = np.zeros(max_dense)\n",
    "    for ind, value in zip(list(x.keys()), list(x.values())):\n",
    "        dense[ind] = value\n",
    "    return dense\n",
    "\n",
    "\n",
    "df[\"customer_ratings_dense\"] = df[\"customer_ratings\"].apply(lambda x: sparse_to_dense(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fdc2b4",
   "metadata": {},
   "source": [
    "We can see, that the dense representation is not optimial. We require much more disk space or memory, when we represent the information in a dense structure. If our product catalog has 10,000 products, then each vector has 10,000 elements. That would be a big overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "758251d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"customer_ratings_dense\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9997303f",
   "metadata": {},
   "source": [
    "We provided an example of sparse features and the need to represent it in a sparse way. We continue to use Sparse Features with NVTabular and TensorFlow.\n",
    "\n",
    "## Sparse Features with NVTabular and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c9570",
   "metadata": {},
   "source": [
    "NVTabular supports to use list columns in dataframes. We will transform the sparse feature into two columns:\n",
    "1. column: a list of the product indices\n",
    "2. column: a list of the product ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe5c5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>product</th>\n",
       "      <th>purchase</th>\n",
       "      <th>customer_ratings_index</th>\n",
       "      <th>customer_ratings_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 4, 5]</td>\n",
       "      <td>[2.5, 4.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 4, 5]</td>\n",
       "      <td>[2.5, 4.0, 5.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 7, 8, 9]</td>\n",
       "      <td>[1.5, 2.0, 3.5, 4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 7, 8, 9]</td>\n",
       "      <td>[1.5, 2.0, 3.5, 4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[3, 6]</td>\n",
       "      <td>[1.0, 4.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer  product  purchase customer_ratings_index customer_ratings_values\n",
       "0        a        0         0              [0, 4, 5]         [2.5, 4.0, 5.0]\n",
       "1        a        1         1              [0, 4, 5]         [2.5, 4.0, 5.0]\n",
       "2        b        0         0           [1, 7, 8, 9]    [1.5, 2.0, 3.5, 4.0]\n",
       "3        b        2         0           [1, 7, 8, 9]    [1.5, 2.0, 3.5, 4.0]\n",
       "4        c        4         1                 [3, 6]              [1.0, 4.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"customer_ratings_index\"] = df[\"customer_ratings\"].apply(lambda x: list(x.keys()))\n",
    "df[\"customer_ratings_values\"] = df[\"customer_ratings\"].apply(lambda x: list(x.values()))\n",
    "df = df.drop(\"customer_ratings\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554f6617",
   "metadata": {},
   "source": [
    "Our product IDs are already continuous integers in a incremental order (0, ... n). Otherwise, we could use nvt.ops.Categorify to convert the indices in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1acbcd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 15:41:30.599968: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-26 15:41:32.762881: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-10-26 15:41:32.764161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: \n",
      "pciBusID: 0000:0b:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-10-26 15:41:32.764196: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-26 15:41:32.764250: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-26 15:41:32.764284: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-26 15:41:32.764319: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-26 15:41:32.764352: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-26 15:41:32.764398: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-10-26 15:41:32.764432: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-10-26 15:41:32.764452: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-10-26 15:41:32.766611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1872] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cudf\n",
    "import tensorflow as tf\n",
    "import nvtabular as nvt\n",
    "\n",
    "# we can control how much memory to give tensorflow with this environment variable\n",
    "# IMPORTANT: make sure you do this before you initialize TF's runtime, otherwise\n",
    "# TF will have claimed all free GPU memory\n",
    "os.environ[\"TF_MEMORY_ALLOCATION\"] = \"0.7\"  # fraction of free memory\n",
    "from nvtabular.loader.tensorflow import KerasSequenceLoader\n",
    "from nvtabular.framework_utils.tensorflow import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a35b4fe",
   "metadata": {},
   "source": [
    "We initialize the NVTabular dataloader `KerasSequenceLoader` from the dataframe. As we want to show the functionality of the sparse features, we will use only the columns `customer_ratings_index`, `customer_ratings_values` and `purchase`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38de9eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_tf = KerasSequenceLoader(\n",
    "    nvt.Dataset(cudf.from_pandas(df)),  # you could also use a glob pattern\n",
    "    batch_size=5,\n",
    "    label_names=[\"purchase\"],\n",
    "    cat_names=[\"customer_ratings_index\"],\n",
    "    cont_names=[\"customer_ratings_values\"],\n",
    "    shuffle=False,\n",
    "    buffer_size=0.06,  # how many batches to load at once\n",
    "    parts_per_chunk=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fabfaed",
   "metadata": {},
   "source": [
    "Let's take a look on the structure in NVTabular data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "754bdc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 15:41:34.164278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1734] Found device 0 with properties: \n",
      "pciBusID: 0000:0b:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-10-26 15:41:34.166528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1872] Adding visible gpu devices: 0\n",
      "2021-10-26 15:41:34.166580: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-26 15:41:34.166714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-26 15:41:34.166728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-10-26 15:41:34.166735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-10-26 15:41:34.169926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22757 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0b:00.0, compute capability: 7.0)\n",
      "2021-10-26 15:41:34.187671: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 22.22G (23862444032 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-26 15:41:34.190001: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 20.00G (21476198400 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-26 15:41:34.192220: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 18.00G (19328577536 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-26 15:41:34.194474: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 16.20G (17395720192 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-26 15:41:34.196851: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 14.58G (15656147968 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-26 15:41:34.199434: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 13.12G (14090532864 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-26 15:41:34.201721: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 11.81G (12681479168 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-26 15:41:34.203955: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 10.63G (11413330944 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-26 15:41:34.206301: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 9.57G (10271997952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-10-26 15:41:34.208862: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 8.61G (9244797952 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataset_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f68173ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(16, 1), dtype=int64, numpy=\n",
       " array([[0],\n",
       "        [4],\n",
       "        [5],\n",
       "        [0],\n",
       "        [4],\n",
       "        [5],\n",
       "        [1],\n",
       "        [7],\n",
       "        [8],\n",
       "        [9],\n",
       "        [1],\n",
       "        [7],\n",
       "        [8],\n",
       "        [9],\n",
       "        [3],\n",
       "        [6]])>,\n",
       " <tf.Tensor: shape=(5, 1), dtype=int32, numpy=\n",
       " array([[3],\n",
       "        [3],\n",
       "        [4],\n",
       "        [4],\n",
       "        [2]], dtype=int32)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][\"customer_ratings_index\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32529c0a",
   "metadata": {},
   "source": [
    "The feature `customer_ratings_index` is represented as a tuple of two tensors. The first tensors contain the actual values and the second tensor are the row_lengths. As each row can contain a different number of elements in the list, we have a [RaggedTensors](https://www.tensorflow.org/api_docs/python/tf/RaggedTensor). It is an efficient representation to use two Tensors to constructed the RaggedTensor.<br><br>\n",
    "In our example,\n",
    "* the first and second row has each 3 elements\n",
    "* the third and the forth row has each 4 elemtns\n",
    "* the with row has 2 elements\n",
    "\n",
    "This is captured in the 2nd Tenors. <br><br>\n",
    "The feature `customer_ratings_values` looks equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8bc7bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(16, 1), dtype=float64, numpy=\n",
       " array([[2.5],\n",
       "        [4. ],\n",
       "        [5. ],\n",
       "        [2.5],\n",
       "        [4. ],\n",
       "        [5. ],\n",
       "        [1.5],\n",
       "        [2. ],\n",
       "        [3.5],\n",
       "        [4. ],\n",
       "        [1.5],\n",
       "        [2. ],\n",
       "        [3.5],\n",
       "        [4. ],\n",
       "        [1. ],\n",
       "        [4. ]])>,\n",
       " <tf.Tensor: shape=(5, 1), dtype=int32, numpy=\n",
       " array([[3],\n",
       "        [3],\n",
       "        [4],\n",
       "        [4],\n",
       "        [2]], dtype=int32)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][\"customer_ratings_values\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d9ce7",
   "metadata": {},
   "source": [
    "NVTabular provides custom TensorFlow layers, `nvtabular.framework_utils.tensorflow.SparseTensor`,which can handle the sparse features.<br><br>\n",
    "The `dense_dim` defines the length of the vector in a dense representation. In our example, it is `10` as the largest index is `9`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b823559a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f15106509a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = layers.SparseTensor(dense_dim=10)(\n",
    "    batch[0][\"customer_ratings_index\"][0],\n",
    "    batch[0][\"customer_ratings_index\"][1],\n",
    "    batch[0][\"customer_ratings_values\"][0],\n",
    ")\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee87a0f3",
   "metadata": {},
   "source": [
    "We can convert the TensorFlow SparseTensor to a dense representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fcc39da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float64, numpy=\n",
       "array([[2.5, 0. , 0. , 0. , 4. , 5. , 0. , 0. , 0. , 0. ],\n",
       "       [2.5, 0. , 0. , 0. , 4. , 5. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 1.5, 0. , 0. , 0. , 0. , 0. , 2. , 3.5, 4. ],\n",
       "       [0. , 1.5, 0. , 0. , 0. , 0. , 0. , 2. , 3.5, 4. ],\n",
       "       [0. , 0. , 0. , 1. , 0. , 0. , 4. , 0. , 0. , 0. ]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade0044",
   "metadata": {},
   "source": [
    "### Building a Neural Network with tf.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493a92d9",
   "metadata": {},
   "source": [
    "Let's define our neural network architecture. We create `tf.keras.input` layers to define our input layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60b0cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "col = \"customer_ratings\"\n",
    "\n",
    "inputs[col + \"_values\"] = (\n",
    "    tf.keras.Input(name=col + \"_values_values\", dtype=tf.float32, shape=(1,)),\n",
    "    tf.keras.Input(name=col + \"_values_index\", dtype=tf.int64, shape=(1,)),\n",
    ")\n",
    "inputs[col + \"_index\"] = (\n",
    "    tf.keras.Input(name=col + \"_index_values\", dtype=tf.int64, shape=(1,)),\n",
    "    tf.keras.Input(name=col + \"_index_index\", dtype=tf.int64, shape=(1,)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484a9bc5",
   "metadata": {},
   "source": [
    "We define our layers.SparseTensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35143e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sparse = layers.SparseTensor(dense_dim=10)(\n",
    "    inputs[col + \"_index\"][0], inputs[col + \"_index\"][1], inputs[col + \"_values\"][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a129b094",
   "metadata": {},
   "source": [
    "We can add a FullyConnected Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbd765db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Dense(1)(x_sparse)\n",
    "x = tf.keras.activations.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dac33f",
   "metadata": {},
   "source": [
    "We compile our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b2c5e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "model.compile(\"sgd\", \"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd282e2e",
   "metadata": {},
   "source": [
    "We can train the model with `.fit` and the NVTabular data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fc221fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 15:41:34.810963: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-26 15:41:34.834295: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2195025000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/model/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 1.5303\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.4852\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.4417\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3998\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3595\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.3207\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2834\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2474\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.2128\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1795\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1475\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.1166\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0869\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0583\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0308\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 1.0044\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9790\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9546\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9312\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9087\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8871\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8664\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8466\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8277\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8096\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7922\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7757\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7599\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7449\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7305\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7168\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7038\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6914\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6796\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6684\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6577\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6475\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6378\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6286\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6198\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6115\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6035\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5959\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5886\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5817\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5751\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5687\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5627\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5569\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5513\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5459\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5408\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5359\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5311\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5265\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5221\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5179\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5137\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5098\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5059\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5022\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4986\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4951\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4917\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4884\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4852\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4821\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4791\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4762\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4733\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4706\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4678\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4652\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4626\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4601\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4577\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4553\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4529\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4506\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4484\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4462\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4441\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4420\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4399\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4379\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4360\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4340\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4322\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4303\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4285\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4267\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4250\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4233\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4216\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4200\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4184\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4168\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4153\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4137\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f15104c0fd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset_tf, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e7b4ef",
   "metadata": {},
   "source": [
    "This is a really small toy example to show how to use Sparse Features with NVTabular and TensorFlow. It has only 5 examples and therefore, batches are pretty small. But this can scale to much larger dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
