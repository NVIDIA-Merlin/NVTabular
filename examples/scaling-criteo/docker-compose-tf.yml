# (1) Use this file for docker runtime configurations that are common to both
# development and deployment.

# `version : '2.3'` lets us use the `runtime=nvidia` configuration so that our
# containers can interact with the GPU(s).
version: '2.3'

volumes:
  models:

services:
  triton:
    command: "/bin/bash -c 'pip install grpcio-channelz && tritonserver --model-repository=/models/ --model-control-mode=explicit'"
    image: nvcr.io/nvidia/merlin/merlin-inference:21:11
    runtime: nvidia
    shm_size: "1g"
    ulimits:
      memlock: -1
      stack: 67108864
    ports:
      - 8000:8000
      - 8001:8001
      - 8002:8002
    volumes:
      - models:/models

  lab:
    runtime: nvidia
    image: nvcr.io/nvidia/merlin/merlin-tensorflow-training:21:11
    command: "/bin/bash -c 'pip install jupyterlab jupytext pydot nvidia-pyindex tritonclient geventhttpclient && apt-get update && apt-get install -y tree && python -m ipykernel install --user --name=merlin && jupyter notebook --no-browser --allow-root --port=8888 --ip=0.0.0.0 --NotebookApp.token='demotoken' --NotebookApp.allow_origin='*' --notebook-dir=/'"
    volumes:
      - models:/models
      - /raid/:/raid/
    links:
      - triton
    ports:
      - 8888:8888
