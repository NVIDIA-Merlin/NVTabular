<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Scaling Criteo: Triton Inference with TensorFlow &mdash; NVTabular 2021 documentation</title><link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/mystnb.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="../../_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Applying the Techniques to other Tabular Problems with Rossmann" href="../tabular-data-rossmann/index.html" />
    <link rel="prev" title="Scaling Criteo: Triton Inference with HugeCTR" href="04-Triton-Inference-with-HugeCTR.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> NVTabular
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../Introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../core_features.html">Core Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../training/index.html">Accelerated Training</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Example Notebooks</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#structure">Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#available-example-notebooks">Available Example Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#running-the-example-notebooks">Running the Example Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#troubleshooting">Troubleshooting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../getting-started-movielens/index.html">Getting Started with MovieLens</a></li>
<li class="toctree-l2"><a class="reference internal" href="../advanced-ops-outbrain/index.html">Advanced Ops with Outbrain</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html">Scaling to Large Datasets with Criteo</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="01-Download-Convert.html">Download and Convert</a></li>
<li class="toctree-l3"><a class="reference internal" href="02-ETL-with-NVTabular.html">ETL with NVTabular</a></li>
<li class="toctree-l3"><a class="reference internal" href="03-Training-with-HugeCTR.html">Train with HugeCTR</a></li>
<li class="toctree-l3"><a class="reference internal" href="03-Training-with-TF.html">Train with TensorFlow</a></li>
<li class="toctree-l3"><a class="reference internal" href="03-Training-with-FastAI.html">Train with FastAI</a></li>
<li class="toctree-l3"><a class="reference internal" href="04-Triton-Inference-with-HugeCTR.html">Serve a HugeCTR Model</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Serve a TensorFlow Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tabular-data-rossmann/index.html">Applying Techniques to Rossmann Stores Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../multi-gpu-movielens/index.html">Multi-GPU Example Notebooks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../winning-solution-recsys2020-twitter/01-02-04-Download-Convert-ETL-with-NVTabular-Training-with-XGBoost.html">Winning Solution of the RecSys2020 Competition</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../resources/index.html">Additional Resources</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">NVTabular</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="../index.html">NVTabular Example Notebooks</a> &raquo;</li>
          <li><a href="index.html">Scaling to Large Datasets with Criteo</a> &raquo;</li>
      <li>Scaling Criteo: Triton Inference with TensorFlow</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copyright 2021 NVIDIA Corporation. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
</pre></div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="scaling-criteo-triton-inference-with-tensorflow">
<h1>Scaling Criteo: Triton Inference with TensorFlow<a class="headerlink" href="#scaling-criteo-triton-inference-with-tensorflow" title="Permalink to this headline"></a></h1>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline"></a></h2>
<p>The last step is to deploy the ETL workflow and saved model to production. In the production setting, we want to transform the input data as during training (ETL). We need to apply the same mean/std for continuous features and use the same categorical mapping to convert the categories to continuous integer before we use the deep learning model for a prediction. Therefore, we deploy the NVTabular workflow with the TensorFlow model as an ensemble model to Triton Inference. The ensemble model garantuees that the same transformation are applied to the raw inputs.</p>
<a class="reference internal image-reference" href="../../_images/triton-tf.png"><img alt="../../_images/triton-tf.png" src="../../_images/triton-tf.png" style="width: 25%;" /></a>
<div class="section" id="learning-objectives">
<h3>Learning objectives<a class="headerlink" href="#learning-objectives" title="Permalink to this headline"></a></h3>
<p>In this notebook, we learn how to deploy our models to production</p>
<ul class="simple">
<li><p>Use <strong>NVTabular</strong> to generate config and model files for Triton Inference Server</p></li>
<li><p>Deploy an ensemble of NVTabular workflow and TensorFlow model</p></li>
<li><p>Send example request to Triton Inference Server</p></li>
</ul>
</div>
</div>
<div class="section" id="inference-with-triton-and-tensorflow">
<h2>Inference with Triton and TensorFlow<a class="headerlink" href="#inference-with-triton-and-tensorflow" title="Permalink to this headline"></a></h2>
<p>First, we need to generate the Triton Inference Server configurations and save the models in the correct format. In the previous notebooks <a class="reference internal" href="02-ETL-with-NVTabular.html"><span class="doc std std-doc">02-ETL-with-NVTabular</span></a> and <a class="reference internal" href="03-Training-with-TF.html"><span class="doc std std-doc">03-Training-with-TF</span></a> we saved the NVTabular workflow and TensorFlow model to disk. We will load them.</p>
<div class="section" id="saving-ensemble-model-for-triton-inference-server">
<h3>Saving Ensemble Model for Triton Inference Server<a class="headerlink" href="#saving-ensemble-model-for-triton-inference-server" title="Permalink to this headline"></a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">nvtabular</span> <span class="k">as</span> <span class="nn">nvt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BASE_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;BASE_DIR&quot;</span><span class="p">,</span> <span class="s2">&quot;/raid/data/criteo&quot;</span><span class="p">)</span>
<span class="n">input_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;INPUT_DATA_DIR&quot;</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s2">&quot;test_dask/output&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">workflow</span> <span class="o">=</span> <span class="n">nvt</span><span class="o">.</span><span class="n">Workflow</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">input_path</span><span class="p">,</span> <span class="s2">&quot;workflow&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">input_path</span><span class="p">,</span> <span class="s2">&quot;model.savedmodel&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>TensorFlow expect the Integer as <code class="docutils literal notranslate"><span class="pre">int32</span></code> datatype. Therefore, we need to define the NVTabular output datatypes to <code class="docutils literal notranslate"><span class="pre">int32</span></code> for categorical features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">workflow</span><span class="o">.</span><span class="n">output_dtypes</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;C&quot;</span><span class="p">):</span>
        <span class="n">workflow</span><span class="o">.</span><span class="n">output_dtypes</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;int32&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>NVTabular provides an easy function to deploy the ensemble model for Triton Inference Server.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nvtabular.inference.triton</span> <span class="kn">import</span> <span class="n">export_tensorflow_ensemble</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">export_tensorflow_ensemble</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">workflow</span><span class="p">,</span> <span class="s2">&quot;criteo&quot;</span><span class="p">,</span> <span class="s2">&quot;/tmp/model/models/&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>We can take a look on the generated files.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># !tree /model</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="loading-ensemble-model-with-triton-inference-server">
<h3>Loading Ensemble Model with Triton Inference Server<a class="headerlink" href="#loading-ensemble-model-with-triton-inference-server" title="Permalink to this headline"></a></h3>
<p>We have only saved the models for Triton Inference Server. We started Triton Inference Server in explicit mode, meaning that we need to send a request that Triton will load the ensemble model.</p>
<p>First, we restart this notebook to free the GPU memory.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import IPython</span>

<span class="c1"># app = IPython.Application.instance()</span>
<span class="c1"># app.kernel.do_shutdown(True)</span>
</pre></div>
</div>
</div>
</div>
<p>We define the BASE_DIR again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="n">BASE_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;BASE_DIR&quot;</span><span class="p">,</span> <span class="s2">&quot;/raid/data/criteo&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We connect to the Triton Inference Server.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tritonclient.grpc</span> <span class="k">as</span> <span class="nn">grpc_client</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">triton_client</span> <span class="o">=</span> <span class="n">grpc_client</span><span class="o">.</span><span class="n">InferenceServerClient</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="s2">&quot;localhost:8001&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;client created.&quot;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;channel creation failed: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>client created.
</pre></div>
</div>
</div>
</div>
<p>We deactivate warnings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We check if the server is alive.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">triton_client</span><span class="o">.</span><span class="n">is_server_live</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>is_server_live, metadata ()

live: true
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<p>We check the available models in the repositories:</p>
<ul class="simple">
<li><p>criteo: Ensemble</p></li>
<li><p>criteo_nvt: NVTabular</p></li>
<li><p>criteo_tf: TensorFlow model</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">triton_client</span><span class="o">.</span><span class="n">get_model_repository_index</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>get_model_repository_index, metadata ()

models {
  name: &quot;criteo&quot;
}
models {
  name: &quot;criteo_nvt&quot;
}
models {
  name: &quot;criteo_tf&quot;
}
models {
  name: &quot;movielens&quot;
}
models {
  name: &quot;movielens_nvt&quot;
}
models {
  name: &quot;movielens_tf&quot;
}
models {
  name: &quot;rossmann&quot;
}
models {
  name: &quot;rossmann_nvt&quot;
}
models {
  name: &quot;rossmann_tf&quot;
}
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>models {
  name: &quot;criteo&quot;
}
models {
  name: &quot;criteo_nvt&quot;
}
models {
  name: &quot;criteo_tf&quot;
}
models {
  name: &quot;movielens&quot;
}
models {
  name: &quot;movielens_nvt&quot;
}
models {
  name: &quot;movielens_tf&quot;
}
models {
  name: &quot;rossmann&quot;
}
models {
  name: &quot;rossmann_nvt&quot;
}
models {
  name: &quot;rossmann_tf&quot;
}
</pre></div>
</div>
</div>
</div>
<p>We load the ensembled model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>

<span class="n">triton_client</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;criteo&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>load_model, metadata ()
model_name: &quot;criteo&quot;
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">InferenceServerException</span><span class="g g-Whitespace">                  </span>Traceback (most recent call last)
<span class="n">File</span> <span class="o">&lt;</span><span class="n">timed</span> <span class="nb">eval</span><span class="o">&gt;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>

<span class="nn">File /usr/local/lib/python3.8/dist-packages/tritonclient/grpc/__init__.py:646,</span> in <span class="ni">InferenceServerClient.load_model</span><span class="nt">(self, model_name, headers, config)</span>
<span class="g g-Whitespace">    </span><span class="mi">644</span>         <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loaded model &#39;</span><span class="si">{}</span><span class="s2">&#39;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model_name</span><span class="p">))</span>
<span class="g g-Whitespace">    </span><span class="mi">645</span> <span class="k">except</span> <span class="n">grpc</span><span class="o">.</span><span class="n">RpcError</span> <span class="k">as</span> <span class="n">rpc_error</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">646</span>     <span class="n">raise_error_grpc</span><span class="p">(</span><span class="n">rpc_error</span><span class="p">)</span>

<span class="nn">File /usr/local/lib/python3.8/dist-packages/tritonclient/grpc/__init__.py:62,</span> in <span class="ni">raise_error_grpc</span><span class="nt">(rpc_error)</span>
<span class="g g-Whitespace">     </span><span class="mi">61</span> <span class="k">def</span> <span class="nf">raise_error_grpc</span><span class="p">(</span><span class="n">rpc_error</span><span class="p">):</span>
<span class="ne">---&gt; </span><span class="mi">62</span>     <span class="k">raise</span> <span class="n">get_error_grpc</span><span class="p">(</span><span class="n">rpc_error</span><span class="p">)</span> <span class="kn">from</span> <span class="bp">None</span>

<span class="ne">InferenceServerException</span>: [StatusCode.UNAVAILABLE] explicit model load / unload is not allowed if polling is enabled
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="example-request-to-triton-inference-server">
<h3>Example Request to Triton Inference Server<a class="headerlink" href="#example-request-to-triton-inference-server" title="Permalink to this headline"></a></h3>
<p>Now, the models are loaded and we can create a sample request. We read an example <strong>raw batch</strong> for inference.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get dataframe library - cudf or pandas</span>
<span class="kn">from</span> <span class="nn">merlin.core.dispatch</span> <span class="kn">import</span> <span class="n">get_lib</span>

<span class="n">df_lib</span> <span class="o">=</span> <span class="n">get_lib</span><span class="p">()</span>

<span class="c1"># read in the workflow (to get input/output schema to call triton with)</span>
<span class="n">batch_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">BASE_DIR</span><span class="p">,</span> <span class="s2">&quot;converted/criteo&quot;</span><span class="p">)</span>
<span class="c1"># raise(ValueError(f&quot;{batch_path}&quot;))</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">df_lib</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">batch_path</span><span class="p">,</span> <span class="s2">&quot;*.parquet&quot;</span><span class="p">),</span> <span class="n">num_rows</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">batch</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">batch</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="s2">&quot;label&quot;</span><span class="p">]]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     I1   I2    I3    I4    I5  I6  I7  I8  I9  I10  ...        C17  \
0     5  110  &lt;NA&gt;    16  &lt;NA&gt;   1   0  14   7    1  ... -771205462   
1    32    3     5  &lt;NA&gt;     1   0   0  61   5    0  ... -771205462   
2  &lt;NA&gt;  233     1   146     1   0   0  99   7    0  ... -771205462   

          C18         C19         C20         C21        C22        C23  \
0 -1206449222 -1793932789 -1014091992   351689309  632402057 -675152885   
1 -1578429167 -1793932789   -20981661 -1556988767 -924717482  391309800   
2  1653545869 -1793932789 -1014091992   351689309  632402057 -675152885   

          C24         C25         C26  
0  2091868316   809724924  -317696227  
1  1966410890 -1726799382 -1218975401  
2   883538181   -10139646  -317696227  

[3 rows x 39 columns]
</pre></div>
</div>
</div>
</div>
<p>We prepare the batch for inference by using correct column names and data types. We use the same datatypes as defined in our dataframe.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch</span><span class="o">.</span><span class="n">dtypes</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>I1     int32
I2     int32
I3     int32
I4     int32
I5     int32
I6     int32
I7     int32
I8     int32
I9     int32
I10    int32
I11    int32
I12    int32
I13    int32
C1     int32
C2     int32
C3     int32
C4     int32
C5     int32
C6     int32
C7     int32
C8     int32
C9     int32
C10    int32
C11    int32
C12    int32
C13    int32
C14    int32
C15    int32
C16    int32
C17    int32
C18    int32
C19    int32
C20    int32
C21    int32
C22    int32
C23    int32
C24    int32
C25    int32
C26    int32
dtype: object
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tritonclient.grpc</span> <span class="k">as</span> <span class="nn">httpclient</span>
<span class="kn">from</span> <span class="nn">tritonclient.utils</span> <span class="kn">import</span> <span class="n">np_to_triton_dtype</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">col_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">col_dtypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">col_names</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values_host</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">col_dtypes</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">d</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">httpclient</span><span class="o">.</span><span class="n">InferInput</span><span class="p">(</span><span class="n">col_names</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">d</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">np_to_triton_dtype</span><span class="p">(</span><span class="n">col_dtypes</span><span class="p">[</span><span class="n">i</span><span class="p">])))</span>
    <span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_data_from_numpy</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We send the request to the triton server and collect the last output.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># placeholder variables for the output</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">httpclient</span><span class="o">.</span><span class="n">InferRequestedOutput</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">)]</span>

<span class="c1"># build a client to connect to our server.</span>
<span class="c1"># This InferenceServerClient object is what we&#39;ll be using to talk to Triton.</span>
<span class="c1"># make the request with tritonclient.http.InferInput object</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">triton_client</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="s2">&quot;criteo&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">request_id</span><span class="o">=</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;predicted softmax result:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>infer, metadata ()
model_name: &quot;criteo&quot;
id: &quot;1&quot;
inputs {
  name: &quot;I1&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;I2&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;I3&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;I4&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;I5&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;I6&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;I7&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;I8&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;I9&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;I10&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;I11&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;I12&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;I13&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C1&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C2&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C3&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C4&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C5&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C6&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C7&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C8&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C9&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C10&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C11&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C12&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C13&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C14&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C15&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C16&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C17&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C18&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C19&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C20&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C21&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C22&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C23&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C24&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C25&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
inputs {
  name: &quot;C26&quot;
  datatype: &quot;INT32&quot;
  shape: 3
  shape: 1
}
outputs {
  name: &quot;output&quot;
}
raw_input_contents: &quot;\005\000\000\000 \000\000\000\000\000\000\000&quot;
raw_input_contents: &quot;n\000\000\000\003\000\000\000\351\000\000\000&quot;
raw_input_contents: &quot;\000\000\000\000\005\000\000\000\001\000\000\000&quot;
raw_input_contents: &quot;\020\000\000\000\000\000\000\000\222\000\000\000&quot;
raw_input_contents: &quot;\000\000\000\000\001\000\000\000\001\000\000\000&quot;
raw_input_contents: &quot;\001\000\000\000\000\000\000\000\000\000\000\000&quot;
raw_input_contents: &quot;\000\000\000\000\000\000\000\000\000\000\000\000&quot;
raw_input_contents: &quot;\016\000\000\000=\000\000\000c\000\000\000&quot;
raw_input_contents: &quot;\007\000\000\000\005\000\000\000\007\000\000\000&quot;
raw_input_contents: &quot;\001\000\000\000\000\000\000\000\000\000\000\000&quot;
raw_input_contents: &quot;\000\000\000\000\001\000\000\000\001\000\000\000&quot;
raw_input_contents: &quot;2\001\000\000U\014\000\000\035\014\000\000&quot;
raw_input_contents: &quot;\000\000\000\000\005\000\000\000\001\000\000\000&quot;
raw_input_contents: &quot;y\rwb\215\375\363\345y\rwb&quot;
raw_input_contents: &quot;X]\037\342\246\377\252\240\003B\230\255&quot;
raw_input_contents: &quot;/D\352\257\325\025\252o\r\306\276b&quot;
raw_input_contents: &quot;\317\177\\\224!4\212\332\356Il8&quot;
raw_input_contents: &quot;H\&#39;\2608#\237\326&lt;M\006U\347&quot;
raw_input_contents: &quot;\313m\315o\313m\315o\313m\315o&quot;
raw_input_contents: &quot;!\252\2005\201\355\026\253b\353\365\265&quot;
raw_input_contents: &quot;\003\211\200()lBC\213\314\362\321&quot;
raw_input_contents: &quot;\246\337\336FT\341\365\035\037\202N.&quot;
raw_input_contents: &quot;\301}\002.\251\300\351}\301}\002.&quot;
raw_input_contents: &quot;1B|\014d\334Rf1B|\014&quot;
raw_input_contents: &quot;\037\035\230\225\&#39;N\353\231\204aq\022&quot;
raw_input_contents: &quot;\267\377\305\000\267\377\305\000\267\377\305\000&quot;
raw_input_contents: &quot;7\345N\2767\345N\2767\345N\276&quot;
raw_input_contents: &quot;\314t\013\212\231\376\273\363\013\r\017\367&quot;
raw_input_contents: &quot;\372&gt;\334L\372&gt;\334L\372&gt;\334L&quot;
raw_input_contents: &quot;\252V\010\322\252V\010\322\252V\010\322&quot;
raw_input_contents: &quot;\272\013\027\270\021\025\353\241\215\033\217b&quot;
raw_input_contents: &quot;\013\302\022\225\013\302\022\225\013\302\022\225&quot;
raw_input_contents: &quot;(/\216\303c\330\277\376(/\216\303&quot;
raw_input_contents: &quot;]Z\366\024\241&lt;2\243]Z\366\024&quot;
raw_input_contents: &quot;\211\260\261%V\356\341\310\211\260\261%&quot;
raw_input_contents: &quot;\013\374\301\327\350\351R\027\013\374\301\327&quot;
raw_input_contents: &quot;\234`\257|\212\0145u\005\271\2514&quot;
raw_input_contents: &quot;\374kC0\352!\023\231\002He\377&quot;
raw_input_contents: &quot;\035W\020\355W\351W\267\035W\020\355&quot;
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">InferenceServerException</span><span class="g g-Whitespace">                  </span>Traceback (most recent call last)
<span class="nn">Input In [11],</span> in <span class="ni">&lt;cell line: 7&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">httpclient</span><span class="o">.</span><span class="n">InferRequestedOutput</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">)]</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="c1"># build a client to connect to our server.</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="c1"># This InferenceServerClient object is what we&#39;ll be using to talk to Triton.</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="c1"># make the request with tritonclient.http.InferInput object</span>
<span class="ne">----&gt; </span><span class="mi">7</span> <span class="n">response</span> <span class="o">=</span> <span class="n">triton_client</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="s2">&quot;criteo&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">request_id</span><span class="o">=</span><span class="s2">&quot;1&quot;</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">9</span> <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;predicted softmax result:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">response</span><span class="o">.</span><span class="n">as_numpy</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">))</span>

<span class="nn">File /usr/local/lib/python3.8/dist-packages/tritonclient/grpc/__init__.py:1295,</span> in <span class="ni">InferenceServerClient.infer</span><span class="nt">(self, model_name, inputs, model_version, outputs, request_id, sequence_id, sequence_start, sequence_end, priority, timeout, client_timeout, headers, compression_algorithm)</span>
<span class="g g-Whitespace">   </span><span class="mi">1293</span>     <span class="k">return</span> <span class="n">result</span>
<span class="g g-Whitespace">   </span><span class="mi">1294</span> <span class="k">except</span> <span class="n">grpc</span><span class="o">.</span><span class="n">RpcError</span> <span class="k">as</span> <span class="n">rpc_error</span><span class="p">:</span>
<span class="ne">-&gt; </span><span class="mi">1295</span>     <span class="n">raise_error_grpc</span><span class="p">(</span><span class="n">rpc_error</span><span class="p">)</span>

<span class="nn">File /usr/local/lib/python3.8/dist-packages/tritonclient/grpc/__init__.py:62,</span> in <span class="ni">raise_error_grpc</span><span class="nt">(rpc_error)</span>
<span class="g g-Whitespace">     </span><span class="mi">61</span> <span class="k">def</span> <span class="nf">raise_error_grpc</span><span class="p">(</span><span class="n">rpc_error</span><span class="p">):</span>
<span class="ne">---&gt; </span><span class="mi">62</span>     <span class="k">raise</span> <span class="n">get_error_grpc</span><span class="p">(</span><span class="n">rpc_error</span><span class="p">)</span> <span class="kn">from</span> <span class="bp">None</span>

<span class="ne">InferenceServerException</span>: [StatusCode.UNAVAILABLE] Request for unknown model: &#39;criteo&#39; is not found
</pre></div>
</div>
</div>
</div>
<p>Let’s unload the model. We need to unload each model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">triton_client</span><span class="o">.</span><span class="n">unload_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;criteo&quot;</span><span class="p">)</span>
<span class="n">triton_client</span><span class="o">.</span><span class="n">unload_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;criteo_nvt&quot;</span><span class="p">)</span>
<span class="n">triton_client</span><span class="o">.</span><span class="n">unload_model</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;criteo_tf&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="04-Triton-Inference-with-HugeCTR.html" class="btn btn-neutral float-left" title="Scaling Criteo: Triton Inference with HugeCTR" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../tabular-data-rossmann/index.html" class="btn btn-neutral float-right" title="Applying the Techniques to other Tabular Problems with Rossmann" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>